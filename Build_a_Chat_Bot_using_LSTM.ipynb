{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build a Chat Bot using LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIZUd6R0VyQGnRC0JZI3eT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lu1993/DeepLearning/blob/master/Build_a_Chat_Bot_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPAjMCtw8UdN",
        "colab_type": "text"
      },
      "source": [
        "## **Building a Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skp3qiin8dTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch import optim \n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sR7TBxY8t_W",
        "colab_type": "code",
        "outputId": "a4eba862-95f3-4705-ef1a-70a32af7e770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if CUDA else 'cpu')\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsS08Sr086LH",
        "colab_type": "text"
      },
      "source": [
        "#### **Part 1: Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oe8B24Z9CBp",
        "colab_type": "code",
        "outputId": "d1ee7a35-7d11-4a06-cb09-137855901957",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9125e806-7e08-431d-910f-3da3fc4423e6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9125e806-7e08-431d-910f-3da3fc4423e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cornell_movie_dialogs_corpus.zip to cornell_movie_dialogs_corpus.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKaHdI4S-SRU",
        "colab_type": "code",
        "outputId": "094b51c5-eb48-4a6b-ea85-7b2ad95179c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# unzip dataset in colab\n",
        "!mkdir ./cornell_movie_dialogs_corpus\n",
        "!unzip -q cornell_movie_dialogs_corpus.zip -d ./cornell_movie_dialogs_corpus"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.2 ms, sys: 14.9 ms, total: 31.1 ms\n",
            "Wall time: 3.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgIwzzMD-vX-",
        "colab_type": "code",
        "outputId": "fff51062-b647-4cf2-eb72-76f27e49f69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "ls ./cornell_movie_dialogs_corpus/'cornell movie-dialogs corpus'/ "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chameleons.pdf                 movie_lines.txt            README.txt\n",
            "movie_characters_metadata.txt  movie_titles_metadata.txt\n",
            "movie_conversations.txt        raw_script_urls.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgaW_5WvABk0",
        "colab_type": "code",
        "outputId": "bcb4e713-fa35-434b-d2da-09b44d825f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_dir = './cornell_movie_dialogs_corpus/'\n",
        "lines_filepath = os.path.join(dataset_dir, 'cornell movie-dialogs corpus', 'movie_lines.txt')\n",
        "conv_filepath = os.path.join(dataset_dir, 'cornell movie-dialogs corpus', 'movie_conversations.txt')\n",
        "print(lines_filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDywpIgC-h-O",
        "colab_type": "code",
        "outputId": "453424f6-64c1-4f3f-a304-be56aadbabdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# visualize some lines\n",
        "with open(lines_filepath, 'r', encoding='iso-8859-1') as file:\n",
        "  lines = file.readlines()\n",
        "for line in lines[:8]:\n",
        "  print(line.strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
            "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
            "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
            "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
            "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
            "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGJnybQjCcjO",
        "colab_type": "code",
        "outputId": "d12307ca-fccd-4190-82f6-4022c77cf33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "with open(conv_filepath, 'r', encoding='iso-8859-1') as file:\n",
        "  lines = file.readlines()\n",
        "for line in lines[:8]:\n",
        "  print(line.strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiLZNqarCfm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split each line into a dictionary of fields\n",
        "line_fields = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
        "lines = {}\n",
        "with open(lines_filepath, 'r', encoding='iso-8859-1') as f:\n",
        "  for line in f:\n",
        "    values = line.split(' +++$+++ ')\n",
        "    lineObj = {}\n",
        "    for i, field in enumerate(line_fields):\n",
        "      lineObj[field] = values[i]\n",
        "    lines[lineObj['lineID']] = lineObj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEo995pvERka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group lines into conversations\n",
        "conv_fields = ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
        "conversations = []\n",
        "with open(conv_filepath, 'r', encoding='iso-8859-1') as f:\n",
        "  for line in f:\n",
        "    values = line.split(' +++$+++ ')\n",
        "    convObj = {}\n",
        "    for i, field in enumerate(conv_fields):\n",
        "      convObj[field] = values[i]\n",
        "    lineIds = eval(convObj['utteranceIDs'])\n",
        "    convObj['lines'] = []\n",
        "    for lineId in lineIds:\n",
        "      convObj['lines'].append(lines[lineId])\n",
        "    conversations.append(convObj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B8zmKxJFePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract pairs of sentences from conversations\n",
        "qa_pairs = []\n",
        "for conversation in conversations:\n",
        "  for i in range(len(conversation['lines']) - 1):\n",
        "    inputLine = conversation['lines'][i]['text'].strip()\n",
        "    targetLine = conversation['lines'][i + 1]['text'].strip()\n",
        "    if inputLine and targetLine:\n",
        "      qa_pairs.append([inputLine, targetLine])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgBF2wgBdsdn",
        "colab_type": "code",
        "outputId": "25648f74-05f1-4edd-e076-72498652f75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "qa_pairs[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
              " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2PokXd_-xos",
        "colab_type": "code",
        "outputId": "d9fbd8b4-0bc1-42e6-f89f-c7f1991f3da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1N00X8LgSWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write transformed data to file in google drive\n",
        "datafile = './drive/My Drive/formatted_movie_lines.txt'\n",
        "delimiter = '\\t'\n",
        "delimiter = str(codecs.decode(delimiter, 'unicode_escape'))\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "  writer = csv.writer(outputfile, delimiter=delimiter)\n",
        "  for pair in qa_pairs:\n",
        "    writer.writerow(pair)\n",
        "print('Done writing to file')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfILrp3fhlcj",
        "colab_type": "code",
        "outputId": "f2168e69-4cd6-4232-fa49-2e173b413154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "# visualize some lines\n",
        "with open(datafile, 'rb') as file:\n",
        "  lines = file.readlines()\n",
        "for line in lines[:8]:\n",
        "  print(line)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
            "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
            "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
            "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\n\"\n",
            "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\n\"\n",
            "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
            "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\n\"\n",
            "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmuVgUm-ixHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the vocabulary\n",
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "class Vocabulary: \n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS'}\n",
        "    self.num_words = 3\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if self.word2index.get(word) is None:\n",
        "      self.word2index[word] = self.num_words \n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.num_words] = word\n",
        "      self.num_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1\n",
        "\n",
        "  def trim(self, min_count):\n",
        "    keep_words = []\n",
        "    for k, v in self.word2count.items():\n",
        "      if v >= min_count:\n",
        "        keep_words.append(k)\n",
        "\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS'}\n",
        "    self.num_words = 3\n",
        "    for w in keep_words:\n",
        "      self.addWord(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz3mPfQ7xLyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert a unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1dlmGmb0Iy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-z.!?]+\", r\" \", s)\n",
        "  s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUe1ET1-03Mu",
        "colab_type": "code",
        "outputId": "0f63d1b5-315e-4a16-e046-58e9a5cfa099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "normalizeString(\"aa123aa!s's  dd?\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aa aa !s s dd ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxipiAQ006Kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data from file\n",
        "# datafile = os.path.join(dataset_dir, 'cornell movie-dialogs corpus', 'formatted_movie_lines.txt')\n",
        "datafile = './drive/My Drive/formatted_movie_lines.txt'\n",
        "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
        "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
        "voc = Vocabulary('cornell movie-dialogs corpus')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2VED9xPCgNt",
        "colab_type": "code",
        "outputId": "70edaf82-83aa-49b7-91ab-8977f8fad3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "voc.num_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjjNRTbZ5-wJ",
        "colab_type": "code",
        "outputId": "16f3f14c-b21e-4116-fbbe-74724b429a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "pairs[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
              "  'well i thought we d start with pronunciation if that s okay with you .'],\n",
              " ['well i thought we d start with pronunciation if that s okay with you .',\n",
              "  'not the hacking and gagging and spitting part . please .'],\n",
              " ['not the hacking and gagging and spitting part . please .',\n",
              "  'okay . . . then how bout we try out some french cuisine . saturday ? night ?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WgsnbiP4W5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filter out sentences with longer than 10 words\n",
        "MAX_LENGTH = 10\n",
        "def filterPair(p):\n",
        "  return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(p):\n",
        "  return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h0VMXbI7S4m",
        "colab_type": "code",
        "outputId": "1bea598e-eb43-423b-a8d5-40d55077bb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pairs = [pair for pair in pairs if len(pair) > 1]\n",
        "print('There are {} pairs before filtering'.format(len(pairs)))\n",
        "pairs = filterPairs(pairs)\n",
        "print('There are {} pairs after filtering'.format(len(pairs)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 221282 pairs before filtering\n",
            "There are 64266 pairs after filtering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihWssl8Ovzan",
        "colab_type": "code",
        "outputId": "bb982738-73b1-4621-e92a-335349d4d0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# add words to vocabulary\n",
        "for pair in pairs:\n",
        "  voc.addSentence(pair[0])\n",
        "  voc.addSentence(pair[1])\n",
        "print('Counted words:', voc.num_words)\n",
        "for pair in pairs[:10]:\n",
        "  print(pair)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counted words: 18077\n",
            "['there .', 'where ?']\n",
            "['you have my word . as a gentleman', 'you re sweet .']\n",
            "['hi .', 'looks like things worked out tonight huh ?']\n",
            "['you know chastity ?', 'i believe we share an art instructor']\n",
            "['have fun tonight ?', 'tons']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['what good stuff ?', 'the real you .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO0XsJ4fCbC-",
        "colab_type": "code",
        "outputId": "14088ba4-5930-4931-f2f4-4b95942cbf66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "voc.num_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZv0-UeWwTzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trim words by count\n",
        "MIN_COUNT = 3\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "  voc.trim(MIN_COUNT)\n",
        "  keep_pairs = []\n",
        "  for pair in pairs:\n",
        "    input_sentence = pair[0]\n",
        "    output_sentence = pair[1]\n",
        "    keep_input = True\n",
        "    keep_output = True\n",
        "    for word in input_sentence.split(' '):\n",
        "      if voc.word2index.get(word) is None:\n",
        "        keep_input = False\n",
        "        break\n",
        "    for word in output_sentence.split(' '):\n",
        "      if voc.word2index.get(word) is None:\n",
        "        keep_output = False\n",
        "        break \n",
        "\n",
        "    if keep_input and keep_output:\n",
        "      keep_pairs.append(pair)\n",
        "  return keep_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-PwC8YDxN-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keep_pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Br-APzBzuY",
        "colab_type": "code",
        "outputId": "6f89ad92-9843-4319-d099-d105b4602f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('There are {} pairs after trimming words'.format(len(keep_pairs)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 53115 pairs after trimming words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjN_sRGPFesY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = keep_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68VrP0VFwzgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert sentence into numerical vector \n",
        "# output matrix size: batch_size * dynamic sequence length for each sentence\n",
        "def indexesFromSentence(voc, sentence):\n",
        "  return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LabWtpUJ0CYG",
        "colab_type": "code",
        "outputId": "90e0e3e2-3fca-41bb-8e26-8fba6b24036f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# test on some samples\n",
        "# output matrix size: batch_size * max(sequence_length)\n",
        "inp = []\n",
        "out = []\n",
        "for pair in pairs[:10]:\n",
        "  inp.append(pair[0])\n",
        "  out.append(pair[1])\n",
        "print(inp)\n",
        "indexes = [indexesFromSentence(voc, sentence) for sentence in inp]\n",
        "print(indexes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
            "[[3, 4, 2], [7, 8, 9, 10, 4, 11, 12, 13, 2], [16, 4, 2], [8, 31, 22, 6, 2], [33, 34, 4, 4, 4, 2], [35, 36, 37, 38, 7, 39, 40, 41, 4, 2], [42, 2], [47, 7, 48, 40, 45, 49, 6, 2], [50, 51, 52, 6, 2], [58, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHHZqYBvyASo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zero padding\n",
        "# output matrix size: max(sequence_length) * batch_size\n",
        "def zeroPadding(l, fillvalue = 0):\n",
        "  return list(itertools.zip_longest(*l, fillvalue = fillvalue))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DD9kp48yAVT",
        "colab_type": "code",
        "outputId": "d695f711-138f-43b9-b71a-112374a44d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "padded_indexes = zeroPadding(indexes)\n",
        "print(padded_indexes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58), (4, 8, 4, 31, 34, 36, 2, 7, 51, 2), (2, 9, 2, 22, 4, 37, 0, 48, 52, 0), (0, 10, 0, 6, 4, 38, 0, 40, 6, 0), (0, 4, 0, 2, 4, 7, 0, 45, 2, 0), (0, 11, 0, 0, 2, 39, 0, 49, 0, 0), (0, 12, 0, 0, 0, 40, 0, 6, 0, 0), (0, 13, 0, 0, 0, 41, 0, 2, 0, 0), (0, 2, 0, 0, 0, 4, 0, 0, 0, 0), (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYkjL9Xe2Fdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binaryMatrix(l):\n",
        "  m = []\n",
        "  for i, seq in enumerate(l):\n",
        "    m.append([])\n",
        "    for token in seq:\n",
        "      if token == PAD_token:\n",
        "        m[i].append(0)\n",
        "      else:\n",
        "        m[i].append(1)\n",
        "  return m "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2pueLMP2Fgh",
        "colab_type": "code",
        "outputId": "e0744e11-8a42-459c-9246-9206973625d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "binary_result = binaryMatrix(padded_indexes)\n",
        "print(binary_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 1, 1, 0], [0, 1, 0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 0, 0, 1, 1, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoQE_p1B2FpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inputVar(l, voc):\n",
        "  indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "  lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "  padList = zeroPadding(indexes_batch)\n",
        "  padVar = torch.LongTensor(padList) # (batch size, max length)\n",
        "  return padVar, lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ym4z-r2FuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outputVar(l, voc):\n",
        "  indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "  max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "  padList = zeroPadding(indexes_batch)\n",
        "  mask = binaryMatrix(padList)\n",
        "  mask = torch.ByteTensor(mask)\n",
        "  padVar = torch.LongTensor(padList) # (batch size, max length)\n",
        "  return padVar, mask, max_target_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQJCaCqZ_-2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch2TrainData(voc, pair_batch):\n",
        "  pair_batch.sort(key = lambda x: len(x[0].split(' ')), reverse=True)\n",
        "  input_batch, output_batch = [], []\n",
        "  for pair in pair_batch:\n",
        "    input_batch.append(pair[0])\n",
        "    output_batch.append(pair[1])\n",
        "  inp, lengths = inputVar(input_batch, voc)\n",
        "  output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "  return inp, lengths, output, mask, max_target_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8iGvlvc2Fb9",
        "colab_type": "code",
        "outputId": "a33ea50e-dd29-40f7-c3b4-d41e7216789a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "# test function \n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "inp, lengths, output, mask, max_target_len = batches \n",
        "print('input variables')\n",
        "print(inp)\n",
        "print('lengths')\n",
        "print(lengths)\n",
        "print('output variables')\n",
        "print(output)\n",
        "print('mask')\n",
        "print(mask)\n",
        "print('maximum output length')\n",
        "print(max_target_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input variables\n",
            "tensor([[  51,   34,   47, 5331,  625],\n",
            "        [ 180, 2981,    7, 5332,    4],\n",
            "        [7446,   27,   18,    6,    2],\n",
            "        [  66,   14,  618,    2,    0],\n",
            "        [2862,  187,    6,    0,    0],\n",
            "        [   4,    4,    2,    0,    0],\n",
            "        [   2,    2,    0,    0,    0]])\n",
            "lengths\n",
            "tensor([7, 7, 6, 4, 3])\n",
            "output variables\n",
            "tensor([[2862,   25,  177,  122,  869],\n",
            "        [7641,  118,   12,   34,  684],\n",
            "        [  66,   40,  810, 2323,    4],\n",
            "        [   2,  380,  234, 3699,    2],\n",
            "        [   0,  187,  810,   98,    0],\n",
            "        [   0,  349, 3663,  157,    0],\n",
            "        [   0,    4,    4,  573,    0],\n",
            "        [   0,    2,    4,  252,    0],\n",
            "        [   0,    0,    4,    4,    0],\n",
            "        [   0,    0,    2,    2,    0]])\n",
            "mask\n",
            "tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 0, 1, 1, 0],\n",
            "        [0, 0, 1, 1, 0]], dtype=torch.uint8)\n",
            "maximum output length\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6AfcZItBdll",
        "colab_type": "text"
      },
      "source": [
        "#### **Part 2: Defining the Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLukwFdjBR1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement encoder layer\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, embedding, n_layer = 1, dropout = 0):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.n_layer = n_layer\n",
        "    self.hidden_size = hidden_size # dimensions of RNN cells in a hidden layer\n",
        "    self.embedding = embedding\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, n_layer, dropout=(0 if n_layer == 1 else dropout), bidirectional=True)\n",
        "\n",
        "  def forward(self, input_seq, input_length, hidden = None):\n",
        "    # convert word indexes to embeddings\n",
        "    embedded = self.embedding(input_seq)\n",
        "    # pack padded sequence together to save computation power \n",
        "    packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_length)\n",
        "    outputs, hidden = self.gru(packed, hidden)\n",
        "    # unpack outputs\n",
        "    # output size: sequence * batch size * hidden size (channel * row * column)\n",
        "    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "    # add bidirectional outputs together \n",
        "    outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
        "    return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOjCuhUv_xtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement attention layer\n",
        "class Attn(torch.nn.Module):\n",
        "  def __init__(self, method, hidden_size):\n",
        "    super(Attn, self).__init__()\n",
        "    self.method = method\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "  def dot_score(self, hidden, encoder_output):\n",
        "    # element wise multiplication between current target decoder state and all encoder states\n",
        "    # dim = 2: sum up across the 2nd dimension\n",
        "    return torch.sum(hidden * encoder_output, dim = 2)\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs):\n",
        "    # shape of hidden: 1 * batch size * hidden size\n",
        "    # shape of encoder outputs: max sequence length * batch size * hidden size\n",
        "    # (1, batch size, hidden size) * (max length, batch size, hidden size) = (max length, batch size, hidden size)\n",
        "    # summing up across the 2nd dimension would give the shape of attention energies as follows: \n",
        "    # shape of attention energies: max sequence length * batch size \n",
        "    # shape of transposed attention energies: batch size * max sequence length \n",
        "    attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "    attn_energies = attn_energies.t()\n",
        "    # return softmax normalized probability score with 1 additional dimension (batch size * 1 * max length)\n",
        "    return F.softmax(attn_energies, dim = 1).unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTmtV8ay_7vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement decoder layer\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers = 1, dropout = 0.1):\n",
        "    super(LuongAttnDecoderRNN, self).__init__()\n",
        "    self.attn_model = attn_model\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.dropout = dropout\n",
        "\n",
        "    # define layers\n",
        "    self.embedding = embedding\n",
        "    self.embedding_dropout = nn.Dropout(dropout)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout = (0 if n_layers == 1 else dropout))\n",
        "    self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "  def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input_step)\n",
        "    embedded = self.embedding_dropout(embedded)\n",
        "    rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "    attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "    context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "    rnn_output = rnn_output.squeeze(0) # transform (1, batch size, hidden size) -> (batch size, hidden size)\n",
        "    context = context.squeeze(1) # transform (batch size, 1, max length) -> (batch size, max length)\n",
        "    concat_input = torch.cat((rnn_output, context), 1)\n",
        "    concat_output = torch.tanh(self.concat(concat_input))\n",
        "    output = self.out(concat_output)\n",
        "    output = F.softmax(output, dim = 1) # apply softmax normalization across each row\n",
        "    return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cna9ArC5T8_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement loss function\n",
        "def maskNLLLoss(decoder_out, target, mask):\n",
        "  nTotal = mask.sum()\n",
        "  target = target.view(-1, 1)\n",
        "  # select elements at the target position\n",
        "  # shape of decoder_out: (batch size, vocabulary size)\n",
        "  # shape of target: (batch size, 1)\n",
        "  gathered_tensor = torch.gather(decoder_out, 1, target)\n",
        "  # negative log likelihood\n",
        "  crossEntropy = -torch.log(gathered_tensor.squeeze(1))\n",
        "  # select non-zero elements\n",
        "  bool_mask = mask > 0\n",
        "  loss = crossEntropy.masked_select(bool_mask)\n",
        "  loss = loss.mean()\n",
        "  loss = loss.to(device)\n",
        "  return loss, nTotal.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I40akW5aT89Q",
        "colab_type": "code",
        "outputId": "d87a62f3-c3b2-4b51-fddd-7c1f953de48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import torch\n",
        "# decoder_out = torch.FloatTensor([[0.1, 0.8, 0.1], \n",
        "#                                 [0.9, 0.05, 0.05]])\n",
        "# target = torch.LongTensor([1, 0])\n",
        "# target = target.view(-1, 1)\n",
        "# gathered_tensor = torch.gather(decoder_out, 1, target)\n",
        "# -torch.log(gathered_tensor)\n",
        "# gathered_tensor.squeeze(1)\n",
        "# gathered_tensor.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lAvntQmZ30R",
        "colab_type": "code",
        "outputId": "4690504f-53aa-440e-e377-c3edb1be791e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# visualize model training\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches \n",
        "\n",
        "print('input_variable shape:', input_variable.shape)\n",
        "print('lengths shape:', lengths.shape)\n",
        "print('target_variabel shape', target_variable.shape)\n",
        "print('mask shape:', mask.shape)\n",
        "print('max_target_len:', max_target_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_variable shape: torch.Size([7, 5])\n",
            "lengths shape: torch.Size([5])\n",
            "target_variabel shape torch.Size([10, 5])\n",
            "mask shape: torch.Size([10, 5])\n",
            "max_target_len: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YunxxFzYfn9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_variable = input_variable.to(device)\n",
        "lengths = lengths.to(device)\n",
        "target_variable = target_variable.to(device)\n",
        "mask = mask.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34Xzs4beaHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define parameters\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "attn_model = 'dot'\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WxVI8dZerq3",
        "colab_type": "code",
        "outputId": "cfcc2015-2b56-441f-832d-33eabab7a28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# define encoder and decoder\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "encoder.train()\n",
        "decoder.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LuongAttnDecoderRNN(\n",
              "  (embedding): Embedding(7840, 500)\n",
              "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
              "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (out): Linear(in_features=500, out_features=7840, bias=True)\n",
              "  (attn): Attn()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbwKxCVefQCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize optimizers\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 0.0001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 0.0001)\n",
        "encoder_optimizer.zero_grad()\n",
        "decoder_optimizer.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OftWJgrff0us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = 0\n",
        "print_losses = []\n",
        "n_totals = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GYdhubQf726",
        "colab_type": "code",
        "outputId": "24a19ec3-54e6-4422-dc2f-afd846c37f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "print('Encoder Outputs Shape:', encoder_outputs.shape)\n",
        "print('Last Encoder Hidden Shape:', encoder_hidden.shape)\n",
        "\n",
        "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
        "decoder_input = decoder_input.to(device)\n",
        "print('Initial Decoder Input Shape:', decoder_input.shape)\n",
        "print(decoder_input)\n",
        "\n",
        "decoder_hidden = encoder_hidden[:decoder.n_layers] # shape of encoder hidden state: (number of layer * number of direction, batch size, hidden size)\n",
        "print('Initial Decoder Hidden State Shape:', decoder_hidden.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Outputs Shape: torch.Size([9, 5, 500])\n",
            "Last Encoder Hidden Shape: torch.Size([4, 5, 500])\n",
            "Initial Decoder Input Shape: torch.Size([1, 5])\n",
            "tensor([[1, 1, 1, 1, 1]], device='cuda:0')\n",
            "Initial Decoder Hidden State Shape: torch.Size([2, 5, 500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRcFHEvGjjrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Take a look at what's happening in every timestep of the GRU\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9cTc0l3jv--",
        "colab_type": "code",
        "outputId": "5de0342c-376e-483a-c016-f2d61d294098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# assume we use teacher forcing\n",
        "for t in range(max_target_len):\n",
        "  decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "  print('Decoder Output Shape:', decoder_output.shape)\n",
        "  print('Decoder Hidden Shape:', decoder_hidden.shape)\n",
        "\n",
        "  decoder_input = target_variable[t].view(1, -1)\n",
        "  print('The target variable at the current timestep before reshaping:', target_variable[t])\n",
        "  print('The target variable at the current timestep shape before reshaping:', target_variable[t].shape)\n",
        "  print('The decoder input shape (reshape the target variable):', decoder_input.shape)\n",
        "\n",
        "  print('The mask at the current timestep:', mask[t])\n",
        "  print('The mask shape at the current timestep:', mask[t].shape)\n",
        "  mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "  print('Mask loss:', mask_loss)\n",
        "  print('Total:', nTotal)\n",
        "  loss += mask_loss \n",
        "  print_losses.append(mask_loss.item() * nTotal)\n",
        "  print(print_losses)\n",
        "  n_totals += nTotal \n",
        "  print(n_totals)\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  returned_loss = sum(print_losses) / n_totals\n",
        "  print('Returned Loss:', returned_loss)\n",
        "  print('Done One Timestep')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([  25,  511,  401,  575, 1334], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "[44.67446804046631, 44.678993225097656]\n",
            "10\n",
            "Returned Loss: 8.935346126556396\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([102,   4, 159,  40,  66], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324]\n",
            "15\n",
            "Returned Loss: 8.941620508829752\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([3652,  208,    4,   70,    2], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 5\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055]\n",
            "20\n",
            "Returned Loss: 8.954282760620117\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([  53,  227,    2, 7531,    0], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 1, 1, 0], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(9.0018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 4\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055, 36.00711441040039]\n",
            "24\n",
            "Returned Loss: 8.962198734283447\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([7575,    7,    0,   34,    0], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 3\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055, 36.00711441040039, 26.905031204223633]\n",
            "27\n",
            "Returned Loss: 8.962881512112087\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([   4,   92,    0, 3508,    0], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 3\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055, 36.00711441040039, 26.905031204223633, 26.880698204040527]\n",
            "30\n",
            "Returned Loss: 8.962616634368896\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([2, 4, 0, 4, 0], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([1, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(9.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 3\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055, 36.00711441040039, 26.905031204223633, 26.880698204040527, 27.09151268005371]\n",
            "33\n",
            "Returned Loss: 8.968788233670322\n",
            "Done One Timestep\n",
            "Decoder Output Shape: torch.Size([5, 7840])\n",
            "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
            "The target variable at the current timestep before reshaping: tensor([0, 2, 0, 2, 0], device='cuda:0')\n",
            "The target variable at the current timestep shape before reshaping: torch.Size([5])\n",
            "The decoder input shape (reshape the target variable): torch.Size([1, 5])\n",
            "The mask at the current timestep: tensor([0, 1, 0, 1, 0], device='cuda:0', dtype=torch.uint8)\n",
            "The mask shape at the current timestep: torch.Size([5])\n",
            "Mask loss: tensor(8.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Total: 2\n",
            "[44.67446804046631, 44.678993225097656, 44.770846366882324, 44.961347579956055, 36.00711441040039, 26.905031204223633, 26.880698204040527, 27.09151268005371, 17.964168548583984]\n",
            "35\n",
            "Returned Loss: 8.969548007420132\n",
            "Done One Timestep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3r6TdXTsEy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Decoder Output Shape:', decoder_output.shape)\n",
        "print('Decoder Hidden Shape:', decoder_hidden.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHHiNZsm4wsa",
        "colab_type": "code",
        "outputId": "004eb4a6-1a0f-4ff7-cc9f-d7520d257ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, \n",
        "      encoder_optimizer, decoder_optimizer, batch_size, clip=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Returned Loss: 8.975261838812576\n",
            "Done One Timestep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMzme5l5p2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n",
        "# initialize\n",
        "start_iteration = 1\n",
        "print_loss = 0\n",
        "\n",
        "# training\n",
        "for iteration in range(start_iteration, n_iteration + 1):\n",
        "  training_batch = training_batches[iteration - 1]\n",
        "  input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "  loss = train(input_variable, lengths, target_variable, mask, max_target_len, \n",
        "                encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "  print_loss += loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CZoKUa1rqNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, \n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length = MAX_LENGTH):\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_variable = input_variable.to(device)\n",
        "  lengths = lengths.to(device)\n",
        "  target_variable = target_variable.to(device)\n",
        "  mask = mask.to(device)\n",
        "\n",
        "  loss = 0\n",
        "  print_losses = []\n",
        "  n_totals = 0\n",
        "\n",
        "  encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "  decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "  decoder_input = decoder_input.to(device)\n",
        "  decoder_hidden = encoder_hidden[:decoder.n_layers] \n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False \n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for t in range(max_target_len):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_input = target_variable[t].view(1, -1)\n",
        "      mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "      loss += mask_loss \n",
        "      print_losses.append(mask_loss.item() * nTotal)\n",
        "      n_totals += nTotal \n",
        "  else:\n",
        "      for t in range(max_target_len):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        _, topi = decoder_output.topk(1)\n",
        "        decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "        decoder_input = decoder_input.to(device)\n",
        "        mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "        loss += mask_loss \n",
        "        print_losses.append(mask_loss.item() * nTotal)\n",
        "        n_totals += nTotal \n",
        "\n",
        "  # perform backpropagation \n",
        "  loss.backward()\n",
        "\n",
        "  # prevent gradient from becoming too large using clipping\n",
        "  _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "  _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "  # adjust model weights\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  returned_loss = sum(print_losses) / n_totals\n",
        "  print('Returned Loss:', returned_loss)\n",
        "  print('Done One Timestep')\n",
        "  return returned_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIiqKyd0voaY",
        "colab_type": "code",
        "outputId": "c36c38f2-02ce-48f5-8380-597f5a274e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# decoder_output.topk(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([[0.0002],\n",
              "        [0.0002],\n",
              "        [0.0002],\n",
              "        [0.0002],\n",
              "        [0.0002]], device='cuda:0', grad_fn=<TopkBackward>), indices=tensor([[1771],\n",
              "        [ 358],\n",
              "        [1361],\n",
              "        [4019],\n",
              "        [ 295]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynwrISnTzIQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run n iterations of training\n",
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
        "               embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, \n",
        "               print_every, save_every, clip, corpus_name, loadFilename):\n",
        "  training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iteration)]\n",
        "  # initialize\n",
        "  start_iteration = 1\n",
        "  print_loss = 0\n",
        "  if loadFilename:\n",
        "    start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "  # training\n",
        "  for iteration in range(start_iteration, n_iteration + 1):\n",
        "    training_batch = training_batches[iteration - 1]\n",
        "    input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "    loss = train(input_variable, lengths, target_variable, mask, max_target_len, \n",
        "                 encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "    print_loss += loss\n",
        "\n",
        "    # print progress\n",
        "    if iteration % print_every == 0:\n",
        "        print_loss_avg = print_loss / print_every\n",
        "        print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "        print_loss = 0\n",
        "\n",
        "    # save checkpoint\n",
        "    if (iteration % save_every == 0):\n",
        "      directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "      if not os.path.exists(directory):\n",
        "          os.makedirs(directory)\n",
        "      torch.save({\n",
        "          'iteration': iteration,\n",
        "          'en': encoder.state_dict(),\n",
        "          'de': decoder.state_dict(),\n",
        "          'en_opt': encoder_optimizer.state_dict(),\n",
        "          'de_opt': decoder_optimizer.state_dict(),\n",
        "          'loss': loss,\n",
        "          'voc_dict': voc.__dict__,\n",
        "          'embedding': embedding.state_dict()\n",
        "      }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHFig6i54nVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply the model on sentence\n",
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtE9EVz551kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate my text\n",
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length = MAX_LENGTH):\n",
        "  # convert words to indices\n",
        "  indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "\n",
        "  # create lengths tensor\n",
        "  lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "\n",
        "  # transpose (batch size, max length) to (max length, batch size)\n",
        "  input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "  input_batch = input_batch.to(device)\n",
        "  lengths = lengths.to(device)\n",
        "\n",
        "  # decode sentence with searcher\n",
        "  tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "  \n",
        "  # covert indexes to words\n",
        "  decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "  return decoded_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxwwKQZf7krp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbJKBQ3i1p0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run model\n",
        "save_dir = './drive/My Drive/'\n",
        "corpus_name = 'cornell movie-dialogs corpus'\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUcANpl21qwl",
        "colab_type": "code",
        "outputId": "35a83dd2-0b8d-4646-ff79-b8a30a77956d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# checkpoint_iter = 4000\n",
        "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "# print(loadFilename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/cb_model/cornell movie-dialogs corpus/2-2_500/4000_checkpoint.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSg5AM2k73o_",
        "colab_type": "code",
        "outputId": "29d6fecd-63ef-4795-f923-dc6e5afbad4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Set checkpoint to load from; set to None if starting from scratch\n",
        "loadFilename = None\n",
        "checkpoint_iter = 4000\n",
        "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "\n",
        "# Load model if a loadFilename is provided\n",
        "if loadFilename:\n",
        "    # If loading on same machine the model was trained on\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcIU9UFi8AXd",
        "colab_type": "code",
        "outputId": "692bfbbc-63d8-4476-f351-5387d00886b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# run training\n",
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 4000\n",
        "print_every = 1\n",
        "save_every = 500\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# If you have cuda, configure cuda to call\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration: 2334; Percent complete: 58.4%; Average loss: 3.0051\n",
            "Returned Loss: 2.976948558909318\n",
            "Done One Timestep\n",
            "Iteration: 2335; Percent complete: 58.4%; Average loss: 2.9769\n",
            "Returned Loss: 3.445969024466357\n",
            "Done One Timestep\n",
            "Iteration: 2336; Percent complete: 58.4%; Average loss: 3.4460\n",
            "Returned Loss: 3.1500064609512743\n",
            "Done One Timestep\n",
            "Iteration: 2337; Percent complete: 58.4%; Average loss: 3.1500\n",
            "Returned Loss: 2.9226317298028897\n",
            "Done One Timestep\n",
            "Iteration: 2338; Percent complete: 58.5%; Average loss: 2.9226\n",
            "Returned Loss: 2.879020522515625\n",
            "Done One Timestep\n",
            "Iteration: 2339; Percent complete: 58.5%; Average loss: 2.8790\n",
            "Returned Loss: 3.000420889900629\n",
            "Done One Timestep\n",
            "Iteration: 2340; Percent complete: 58.5%; Average loss: 3.0004\n",
            "Returned Loss: 3.039529778227024\n",
            "Done One Timestep\n",
            "Iteration: 2341; Percent complete: 58.5%; Average loss: 3.0395\n",
            "Returned Loss: 2.776061857991678\n",
            "Done One Timestep\n",
            "Iteration: 2342; Percent complete: 58.6%; Average loss: 2.7761\n",
            "Returned Loss: 3.0793083043061005\n",
            "Done One Timestep\n",
            "Iteration: 2343; Percent complete: 58.6%; Average loss: 3.0793\n",
            "Returned Loss: 3.114095529469442\n",
            "Done One Timestep\n",
            "Iteration: 2344; Percent complete: 58.6%; Average loss: 3.1141\n",
            "Returned Loss: 3.208419981195281\n",
            "Done One Timestep\n",
            "Iteration: 2345; Percent complete: 58.6%; Average loss: 3.2084\n",
            "Returned Loss: 3.059499889043874\n",
            "Done One Timestep\n",
            "Iteration: 2346; Percent complete: 58.7%; Average loss: 3.0595\n",
            "Returned Loss: 2.8848411539032197\n",
            "Done One Timestep\n",
            "Iteration: 2347; Percent complete: 58.7%; Average loss: 2.8848\n",
            "Returned Loss: 2.74254410091526\n",
            "Done One Timestep\n",
            "Iteration: 2348; Percent complete: 58.7%; Average loss: 2.7425\n",
            "Returned Loss: 3.1586730641368255\n",
            "Done One Timestep\n",
            "Iteration: 2349; Percent complete: 58.7%; Average loss: 3.1587\n",
            "Returned Loss: 3.021968121570663\n",
            "Done One Timestep\n",
            "Iteration: 2350; Percent complete: 58.8%; Average loss: 3.0220\n",
            "Returned Loss: 3.0035632206243172\n",
            "Done One Timestep\n",
            "Iteration: 2351; Percent complete: 58.8%; Average loss: 3.0036\n",
            "Returned Loss: 3.156615000171473\n",
            "Done One Timestep\n",
            "Iteration: 2352; Percent complete: 58.8%; Average loss: 3.1566\n",
            "Returned Loss: 2.9700008100271225\n",
            "Done One Timestep\n",
            "Iteration: 2353; Percent complete: 58.8%; Average loss: 2.9700\n",
            "Returned Loss: 2.787911601116422\n",
            "Done One Timestep\n",
            "Iteration: 2354; Percent complete: 58.9%; Average loss: 2.7879\n",
            "Returned Loss: 3.2535228632539317\n",
            "Done One Timestep\n",
            "Iteration: 2355; Percent complete: 58.9%; Average loss: 3.2535\n",
            "Returned Loss: 3.0486771235998913\n",
            "Done One Timestep\n",
            "Iteration: 2356; Percent complete: 58.9%; Average loss: 3.0487\n",
            "Returned Loss: 3.3694505101609633\n",
            "Done One Timestep\n",
            "Iteration: 2357; Percent complete: 58.9%; Average loss: 3.3695\n",
            "Returned Loss: 3.085948465966229\n",
            "Done One Timestep\n",
            "Iteration: 2358; Percent complete: 59.0%; Average loss: 3.0859\n",
            "Returned Loss: 2.8052801503166465\n",
            "Done One Timestep\n",
            "Iteration: 2359; Percent complete: 59.0%; Average loss: 2.8053\n",
            "Returned Loss: 2.9820723435047065\n",
            "Done One Timestep\n",
            "Iteration: 2360; Percent complete: 59.0%; Average loss: 2.9821\n",
            "Returned Loss: 2.827297789333224\n",
            "Done One Timestep\n",
            "Iteration: 2361; Percent complete: 59.0%; Average loss: 2.8273\n",
            "Returned Loss: 2.933349539076526\n",
            "Done One Timestep\n",
            "Iteration: 2362; Percent complete: 59.1%; Average loss: 2.9333\n",
            "Returned Loss: 3.225409434124758\n",
            "Done One Timestep\n",
            "Iteration: 2363; Percent complete: 59.1%; Average loss: 3.2254\n",
            "Returned Loss: 3.2296079364982573\n",
            "Done One Timestep\n",
            "Iteration: 2364; Percent complete: 59.1%; Average loss: 3.2296\n",
            "Returned Loss: 2.9690070320797597\n",
            "Done One Timestep\n",
            "Iteration: 2365; Percent complete: 59.1%; Average loss: 2.9690\n",
            "Returned Loss: 3.0940849047251406\n",
            "Done One Timestep\n",
            "Iteration: 2366; Percent complete: 59.2%; Average loss: 3.0941\n",
            "Returned Loss: 3.0547120823155476\n",
            "Done One Timestep\n",
            "Iteration: 2367; Percent complete: 59.2%; Average loss: 3.0547\n",
            "Returned Loss: 2.895863959938288\n",
            "Done One Timestep\n",
            "Iteration: 2368; Percent complete: 59.2%; Average loss: 2.8959\n",
            "Returned Loss: 2.8167100608752573\n",
            "Done One Timestep\n",
            "Iteration: 2369; Percent complete: 59.2%; Average loss: 2.8167\n",
            "Returned Loss: 3.383860425399792\n",
            "Done One Timestep\n",
            "Iteration: 2370; Percent complete: 59.2%; Average loss: 3.3839\n",
            "Returned Loss: 2.9029062188745423\n",
            "Done One Timestep\n",
            "Iteration: 2371; Percent complete: 59.3%; Average loss: 2.9029\n",
            "Returned Loss: 2.877329825936153\n",
            "Done One Timestep\n",
            "Iteration: 2372; Percent complete: 59.3%; Average loss: 2.8773\n",
            "Returned Loss: 3.172982015336553\n",
            "Done One Timestep\n",
            "Iteration: 2373; Percent complete: 59.3%; Average loss: 3.1730\n",
            "Returned Loss: 3.057018391715056\n",
            "Done One Timestep\n",
            "Iteration: 2374; Percent complete: 59.4%; Average loss: 3.0570\n",
            "Returned Loss: 2.9264332139157854\n",
            "Done One Timestep\n",
            "Iteration: 2375; Percent complete: 59.4%; Average loss: 2.9264\n",
            "Returned Loss: 3.1212375413339872\n",
            "Done One Timestep\n",
            "Iteration: 2376; Percent complete: 59.4%; Average loss: 3.1212\n",
            "Returned Loss: 3.010849772896757\n",
            "Done One Timestep\n",
            "Iteration: 2377; Percent complete: 59.4%; Average loss: 3.0108\n",
            "Returned Loss: 3.3976810897197525\n",
            "Done One Timestep\n",
            "Iteration: 2378; Percent complete: 59.5%; Average loss: 3.3977\n",
            "Returned Loss: 2.827141345455864\n",
            "Done One Timestep\n",
            "Iteration: 2379; Percent complete: 59.5%; Average loss: 2.8271\n",
            "Returned Loss: 3.3038904514234186\n",
            "Done One Timestep\n",
            "Iteration: 2380; Percent complete: 59.5%; Average loss: 3.3039\n",
            "Returned Loss: 2.937584407674264\n",
            "Done One Timestep\n",
            "Iteration: 2381; Percent complete: 59.5%; Average loss: 2.9376\n",
            "Returned Loss: 2.984329488768095\n",
            "Done One Timestep\n",
            "Iteration: 2382; Percent complete: 59.6%; Average loss: 2.9843\n",
            "Returned Loss: 3.1938401853708585\n",
            "Done One Timestep\n",
            "Iteration: 2383; Percent complete: 59.6%; Average loss: 3.1938\n",
            "Returned Loss: 2.9585066125546913\n",
            "Done One Timestep\n",
            "Iteration: 2384; Percent complete: 59.6%; Average loss: 2.9585\n",
            "Returned Loss: 3.1682790027487844\n",
            "Done One Timestep\n",
            "Iteration: 2385; Percent complete: 59.6%; Average loss: 3.1683\n",
            "Returned Loss: 3.1250089083148147\n",
            "Done One Timestep\n",
            "Iteration: 2386; Percent complete: 59.7%; Average loss: 3.1250\n",
            "Returned Loss: 3.0669543851139505\n",
            "Done One Timestep\n",
            "Iteration: 2387; Percent complete: 59.7%; Average loss: 3.0670\n",
            "Returned Loss: 2.88285628265789\n",
            "Done One Timestep\n",
            "Iteration: 2388; Percent complete: 59.7%; Average loss: 2.8829\n",
            "Returned Loss: 2.810042153723408\n",
            "Done One Timestep\n",
            "Iteration: 2389; Percent complete: 59.7%; Average loss: 2.8100\n",
            "Returned Loss: 2.980235241475083\n",
            "Done One Timestep\n",
            "Iteration: 2390; Percent complete: 59.8%; Average loss: 2.9802\n",
            "Returned Loss: 3.069759182650976\n",
            "Done One Timestep\n",
            "Iteration: 2391; Percent complete: 59.8%; Average loss: 3.0698\n",
            "Returned Loss: 3.0569029766297784\n",
            "Done One Timestep\n",
            "Iteration: 2392; Percent complete: 59.8%; Average loss: 3.0569\n",
            "Returned Loss: 2.915909560522813\n",
            "Done One Timestep\n",
            "Iteration: 2393; Percent complete: 59.8%; Average loss: 2.9159\n",
            "Returned Loss: 3.0287149671525895\n",
            "Done One Timestep\n",
            "Iteration: 2394; Percent complete: 59.9%; Average loss: 3.0287\n",
            "Returned Loss: 3.0140651943823626\n",
            "Done One Timestep\n",
            "Iteration: 2395; Percent complete: 59.9%; Average loss: 3.0141\n",
            "Returned Loss: 3.1387845459838757\n",
            "Done One Timestep\n",
            "Iteration: 2396; Percent complete: 59.9%; Average loss: 3.1388\n",
            "Returned Loss: 2.856455102929242\n",
            "Done One Timestep\n",
            "Iteration: 2397; Percent complete: 59.9%; Average loss: 2.8565\n",
            "Returned Loss: 2.9828308320384687\n",
            "Done One Timestep\n",
            "Iteration: 2398; Percent complete: 60.0%; Average loss: 2.9828\n",
            "Returned Loss: 3.1697500511036103\n",
            "Done One Timestep\n",
            "Iteration: 2399; Percent complete: 60.0%; Average loss: 3.1698\n",
            "Returned Loss: 3.124239254185515\n",
            "Done One Timestep\n",
            "Iteration: 2400; Percent complete: 60.0%; Average loss: 3.1242\n",
            "Returned Loss: 2.95356004489872\n",
            "Done One Timestep\n",
            "Iteration: 2401; Percent complete: 60.0%; Average loss: 2.9536\n",
            "Returned Loss: 2.847634561513918\n",
            "Done One Timestep\n",
            "Iteration: 2402; Percent complete: 60.1%; Average loss: 2.8476\n",
            "Returned Loss: 3.006605198928491\n",
            "Done One Timestep\n",
            "Iteration: 2403; Percent complete: 60.1%; Average loss: 3.0066\n",
            "Returned Loss: 3.0591470994983676\n",
            "Done One Timestep\n",
            "Iteration: 2404; Percent complete: 60.1%; Average loss: 3.0591\n",
            "Returned Loss: 2.934775953624236\n",
            "Done One Timestep\n",
            "Iteration: 2405; Percent complete: 60.1%; Average loss: 2.9348\n",
            "Returned Loss: 3.063017450646562\n",
            "Done One Timestep\n",
            "Iteration: 2406; Percent complete: 60.2%; Average loss: 3.0630\n",
            "Returned Loss: 3.2293559555157323\n",
            "Done One Timestep\n",
            "Iteration: 2407; Percent complete: 60.2%; Average loss: 3.2294\n",
            "Returned Loss: 2.974229775569823\n",
            "Done One Timestep\n",
            "Iteration: 2408; Percent complete: 60.2%; Average loss: 2.9742\n",
            "Returned Loss: 3.0454492361750454\n",
            "Done One Timestep\n",
            "Iteration: 2409; Percent complete: 60.2%; Average loss: 3.0454\n",
            "Returned Loss: 2.936299170278995\n",
            "Done One Timestep\n",
            "Iteration: 2410; Percent complete: 60.2%; Average loss: 2.9363\n",
            "Returned Loss: 3.080575749635258\n",
            "Done One Timestep\n",
            "Iteration: 2411; Percent complete: 60.3%; Average loss: 3.0806\n",
            "Returned Loss: 2.8962961819331725\n",
            "Done One Timestep\n",
            "Iteration: 2412; Percent complete: 60.3%; Average loss: 2.8963\n",
            "Returned Loss: 2.9014541394263507\n",
            "Done One Timestep\n",
            "Iteration: 2413; Percent complete: 60.3%; Average loss: 2.9015\n",
            "Returned Loss: 3.184925003316749\n",
            "Done One Timestep\n",
            "Iteration: 2414; Percent complete: 60.4%; Average loss: 3.1849\n",
            "Returned Loss: 3.2940469194445376\n",
            "Done One Timestep\n",
            "Iteration: 2415; Percent complete: 60.4%; Average loss: 3.2940\n",
            "Returned Loss: 2.9614916937676212\n",
            "Done One Timestep\n",
            "Iteration: 2416; Percent complete: 60.4%; Average loss: 2.9615\n",
            "Returned Loss: 3.120193199755378\n",
            "Done One Timestep\n",
            "Iteration: 2417; Percent complete: 60.4%; Average loss: 3.1202\n",
            "Returned Loss: 3.034307093452662\n",
            "Done One Timestep\n",
            "Iteration: 2418; Percent complete: 60.5%; Average loss: 3.0343\n",
            "Returned Loss: 2.9148204019816406\n",
            "Done One Timestep\n",
            "Iteration: 2419; Percent complete: 60.5%; Average loss: 2.9148\n",
            "Returned Loss: 2.976573599571602\n",
            "Done One Timestep\n",
            "Iteration: 2420; Percent complete: 60.5%; Average loss: 2.9766\n",
            "Returned Loss: 3.137758248026862\n",
            "Done One Timestep\n",
            "Iteration: 2421; Percent complete: 60.5%; Average loss: 3.1378\n",
            "Returned Loss: 3.070578785976762\n",
            "Done One Timestep\n",
            "Iteration: 2422; Percent complete: 60.6%; Average loss: 3.0706\n",
            "Returned Loss: 2.9384980258300186\n",
            "Done One Timestep\n",
            "Iteration: 2423; Percent complete: 60.6%; Average loss: 2.9385\n",
            "Returned Loss: 3.123627004102895\n",
            "Done One Timestep\n",
            "Iteration: 2424; Percent complete: 60.6%; Average loss: 3.1236\n",
            "Returned Loss: 3.1658730415028136\n",
            "Done One Timestep\n",
            "Iteration: 2425; Percent complete: 60.6%; Average loss: 3.1659\n",
            "Returned Loss: 3.1374408767217457\n",
            "Done One Timestep\n",
            "Iteration: 2426; Percent complete: 60.7%; Average loss: 3.1374\n",
            "Returned Loss: 3.0258900475501553\n",
            "Done One Timestep\n",
            "Iteration: 2427; Percent complete: 60.7%; Average loss: 3.0259\n",
            "Returned Loss: 2.999249572287756\n",
            "Done One Timestep\n",
            "Iteration: 2428; Percent complete: 60.7%; Average loss: 2.9992\n",
            "Returned Loss: 2.9476682415758386\n",
            "Done One Timestep\n",
            "Iteration: 2429; Percent complete: 60.7%; Average loss: 2.9477\n",
            "Returned Loss: 3.2089860258120897\n",
            "Done One Timestep\n",
            "Iteration: 2430; Percent complete: 60.8%; Average loss: 3.2090\n",
            "Returned Loss: 3.0113328696875103\n",
            "Done One Timestep\n",
            "Iteration: 2431; Percent complete: 60.8%; Average loss: 3.0113\n",
            "Returned Loss: 3.117295975870228\n",
            "Done One Timestep\n",
            "Iteration: 2432; Percent complete: 60.8%; Average loss: 3.1173\n",
            "Returned Loss: 3.160455305312185\n",
            "Done One Timestep\n",
            "Iteration: 2433; Percent complete: 60.8%; Average loss: 3.1605\n",
            "Returned Loss: 3.141495881620519\n",
            "Done One Timestep\n",
            "Iteration: 2434; Percent complete: 60.9%; Average loss: 3.1415\n",
            "Returned Loss: 2.8295721417006674\n",
            "Done One Timestep\n",
            "Iteration: 2435; Percent complete: 60.9%; Average loss: 2.8296\n",
            "Returned Loss: 3.090402108650972\n",
            "Done One Timestep\n",
            "Iteration: 2436; Percent complete: 60.9%; Average loss: 3.0904\n",
            "Returned Loss: 2.9880934924182325\n",
            "Done One Timestep\n",
            "Iteration: 2437; Percent complete: 60.9%; Average loss: 2.9881\n",
            "Returned Loss: 2.99815098779357\n",
            "Done One Timestep\n",
            "Iteration: 2438; Percent complete: 61.0%; Average loss: 2.9982\n",
            "Returned Loss: 2.904608265523126\n",
            "Done One Timestep\n",
            "Iteration: 2439; Percent complete: 61.0%; Average loss: 2.9046\n",
            "Returned Loss: 2.882762522683764\n",
            "Done One Timestep\n",
            "Iteration: 2440; Percent complete: 61.0%; Average loss: 2.8828\n",
            "Returned Loss: 3.0440085160784656\n",
            "Done One Timestep\n",
            "Iteration: 2441; Percent complete: 61.0%; Average loss: 3.0440\n",
            "Returned Loss: 3.274452019629902\n",
            "Done One Timestep\n",
            "Iteration: 2442; Percent complete: 61.1%; Average loss: 3.2745\n",
            "Returned Loss: 3.140477149545443\n",
            "Done One Timestep\n",
            "Iteration: 2443; Percent complete: 61.1%; Average loss: 3.1405\n",
            "Returned Loss: 3.1900616031459936\n",
            "Done One Timestep\n",
            "Iteration: 2444; Percent complete: 61.1%; Average loss: 3.1901\n",
            "Returned Loss: 3.1015877657226105\n",
            "Done One Timestep\n",
            "Iteration: 2445; Percent complete: 61.1%; Average loss: 3.1016\n",
            "Returned Loss: 3.1354274729980216\n",
            "Done One Timestep\n",
            "Iteration: 2446; Percent complete: 61.2%; Average loss: 3.1354\n",
            "Returned Loss: 3.1524320663821817\n",
            "Done One Timestep\n",
            "Iteration: 2447; Percent complete: 61.2%; Average loss: 3.1524\n",
            "Returned Loss: 2.946909826357006\n",
            "Done One Timestep\n",
            "Iteration: 2448; Percent complete: 61.2%; Average loss: 2.9469\n",
            "Returned Loss: 3.036021253498788\n",
            "Done One Timestep\n",
            "Iteration: 2449; Percent complete: 61.2%; Average loss: 3.0360\n",
            "Returned Loss: 3.129057592853862\n",
            "Done One Timestep\n",
            "Iteration: 2450; Percent complete: 61.3%; Average loss: 3.1291\n",
            "Returned Loss: 2.973974131064606\n",
            "Done One Timestep\n",
            "Iteration: 2451; Percent complete: 61.3%; Average loss: 2.9740\n",
            "Returned Loss: 3.056732518554438\n",
            "Done One Timestep\n",
            "Iteration: 2452; Percent complete: 61.3%; Average loss: 3.0567\n",
            "Returned Loss: 2.9365064534254426\n",
            "Done One Timestep\n",
            "Iteration: 2453; Percent complete: 61.3%; Average loss: 2.9365\n",
            "Returned Loss: 3.0315777153639143\n",
            "Done One Timestep\n",
            "Iteration: 2454; Percent complete: 61.4%; Average loss: 3.0316\n",
            "Returned Loss: 2.946598733367551\n",
            "Done One Timestep\n",
            "Iteration: 2455; Percent complete: 61.4%; Average loss: 2.9466\n",
            "Returned Loss: 3.0506106226026697\n",
            "Done One Timestep\n",
            "Iteration: 2456; Percent complete: 61.4%; Average loss: 3.0506\n",
            "Returned Loss: 2.947150864845591\n",
            "Done One Timestep\n",
            "Iteration: 2457; Percent complete: 61.4%; Average loss: 2.9472\n",
            "Returned Loss: 3.019577900962414\n",
            "Done One Timestep\n",
            "Iteration: 2458; Percent complete: 61.5%; Average loss: 3.0196\n",
            "Returned Loss: 2.9767690441604686\n",
            "Done One Timestep\n",
            "Iteration: 2459; Percent complete: 61.5%; Average loss: 2.9768\n",
            "Returned Loss: 3.156211742816581\n",
            "Done One Timestep\n",
            "Iteration: 2460; Percent complete: 61.5%; Average loss: 3.1562\n",
            "Returned Loss: 3.2473107276103157\n",
            "Done One Timestep\n",
            "Iteration: 2461; Percent complete: 61.5%; Average loss: 3.2473\n",
            "Returned Loss: 2.964922124364724\n",
            "Done One Timestep\n",
            "Iteration: 2462; Percent complete: 61.6%; Average loss: 2.9649\n",
            "Returned Loss: 2.933271158917482\n",
            "Done One Timestep\n",
            "Iteration: 2463; Percent complete: 61.6%; Average loss: 2.9333\n",
            "Returned Loss: 3.343747869894073\n",
            "Done One Timestep\n",
            "Iteration: 2464; Percent complete: 61.6%; Average loss: 3.3437\n",
            "Returned Loss: 2.94753914398892\n",
            "Done One Timestep\n",
            "Iteration: 2465; Percent complete: 61.6%; Average loss: 2.9475\n",
            "Returned Loss: 3.1187734519803416\n",
            "Done One Timestep\n",
            "Iteration: 2466; Percent complete: 61.7%; Average loss: 3.1188\n",
            "Returned Loss: 2.975571186137819\n",
            "Done One Timestep\n",
            "Iteration: 2467; Percent complete: 61.7%; Average loss: 2.9756\n",
            "Returned Loss: 2.9054075698590944\n",
            "Done One Timestep\n",
            "Iteration: 2468; Percent complete: 61.7%; Average loss: 2.9054\n",
            "Returned Loss: 3.011424887970469\n",
            "Done One Timestep\n",
            "Iteration: 2469; Percent complete: 61.7%; Average loss: 3.0114\n",
            "Returned Loss: 2.898069629800987\n",
            "Done One Timestep\n",
            "Iteration: 2470; Percent complete: 61.8%; Average loss: 2.8981\n",
            "Returned Loss: 2.912731633601003\n",
            "Done One Timestep\n",
            "Iteration: 2471; Percent complete: 61.8%; Average loss: 2.9127\n",
            "Returned Loss: 3.3287166523565177\n",
            "Done One Timestep\n",
            "Iteration: 2472; Percent complete: 61.8%; Average loss: 3.3287\n",
            "Returned Loss: 3.008464510354292\n",
            "Done One Timestep\n",
            "Iteration: 2473; Percent complete: 61.8%; Average loss: 3.0085\n",
            "Returned Loss: 2.90778156183466\n",
            "Done One Timestep\n",
            "Iteration: 2474; Percent complete: 61.9%; Average loss: 2.9078\n",
            "Returned Loss: 2.8261841753285415\n",
            "Done One Timestep\n",
            "Iteration: 2475; Percent complete: 61.9%; Average loss: 2.8262\n",
            "Returned Loss: 3.0248684019696515\n",
            "Done One Timestep\n",
            "Iteration: 2476; Percent complete: 61.9%; Average loss: 3.0249\n",
            "Returned Loss: 2.936324724382173\n",
            "Done One Timestep\n",
            "Iteration: 2477; Percent complete: 61.9%; Average loss: 2.9363\n",
            "Returned Loss: 2.8012270090097684\n",
            "Done One Timestep\n",
            "Iteration: 2478; Percent complete: 62.0%; Average loss: 2.8012\n",
            "Returned Loss: 2.8421790274741237\n",
            "Done One Timestep\n",
            "Iteration: 2479; Percent complete: 62.0%; Average loss: 2.8422\n",
            "Returned Loss: 3.14641921605971\n",
            "Done One Timestep\n",
            "Iteration: 2480; Percent complete: 62.0%; Average loss: 3.1464\n",
            "Returned Loss: 2.9751427834830073\n",
            "Done One Timestep\n",
            "Iteration: 2481; Percent complete: 62.0%; Average loss: 2.9751\n",
            "Returned Loss: 3.1188965785029303\n",
            "Done One Timestep\n",
            "Iteration: 2482; Percent complete: 62.1%; Average loss: 3.1189\n",
            "Returned Loss: 2.8529558985827683\n",
            "Done One Timestep\n",
            "Iteration: 2483; Percent complete: 62.1%; Average loss: 2.8530\n",
            "Returned Loss: 2.987985799183552\n",
            "Done One Timestep\n",
            "Iteration: 2484; Percent complete: 62.1%; Average loss: 2.9880\n",
            "Returned Loss: 3.031536164109082\n",
            "Done One Timestep\n",
            "Iteration: 2485; Percent complete: 62.1%; Average loss: 3.0315\n",
            "Returned Loss: 3.107430175188746\n",
            "Done One Timestep\n",
            "Iteration: 2486; Percent complete: 62.2%; Average loss: 3.1074\n",
            "Returned Loss: 3.223490778096115\n",
            "Done One Timestep\n",
            "Iteration: 2487; Percent complete: 62.2%; Average loss: 3.2235\n",
            "Returned Loss: 3.0682353979463484\n",
            "Done One Timestep\n",
            "Iteration: 2488; Percent complete: 62.2%; Average loss: 3.0682\n",
            "Returned Loss: 2.921398678260037\n",
            "Done One Timestep\n",
            "Iteration: 2489; Percent complete: 62.2%; Average loss: 2.9214\n",
            "Returned Loss: 2.979135783247024\n",
            "Done One Timestep\n",
            "Iteration: 2490; Percent complete: 62.3%; Average loss: 2.9791\n",
            "Returned Loss: 2.930660390450752\n",
            "Done One Timestep\n",
            "Iteration: 2491; Percent complete: 62.3%; Average loss: 2.9307\n",
            "Returned Loss: 2.9901864116006442\n",
            "Done One Timestep\n",
            "Iteration: 2492; Percent complete: 62.3%; Average loss: 2.9902\n",
            "Returned Loss: 3.107948147128478\n",
            "Done One Timestep\n",
            "Iteration: 2493; Percent complete: 62.3%; Average loss: 3.1079\n",
            "Returned Loss: 3.0260456676586176\n",
            "Done One Timestep\n",
            "Iteration: 2494; Percent complete: 62.4%; Average loss: 3.0260\n",
            "Returned Loss: 3.2769963598488046\n",
            "Done One Timestep\n",
            "Iteration: 2495; Percent complete: 62.4%; Average loss: 3.2770\n",
            "Returned Loss: 2.937854860280011\n",
            "Done One Timestep\n",
            "Iteration: 2496; Percent complete: 62.4%; Average loss: 2.9379\n",
            "Returned Loss: 3.110224465807953\n",
            "Done One Timestep\n",
            "Iteration: 2497; Percent complete: 62.4%; Average loss: 3.1102\n",
            "Returned Loss: 3.2159347897791895\n",
            "Done One Timestep\n",
            "Iteration: 2498; Percent complete: 62.5%; Average loss: 3.2159\n",
            "Returned Loss: 3.1829099587944136\n",
            "Done One Timestep\n",
            "Iteration: 2499; Percent complete: 62.5%; Average loss: 3.1829\n",
            "Returned Loss: 3.1204823957711696\n",
            "Done One Timestep\n",
            "Iteration: 2500; Percent complete: 62.5%; Average loss: 3.1205\n",
            "Returned Loss: 3.0819310419068016\n",
            "Done One Timestep\n",
            "Iteration: 2501; Percent complete: 62.5%; Average loss: 3.0819\n",
            "Returned Loss: 2.9097066052643292\n",
            "Done One Timestep\n",
            "Iteration: 2502; Percent complete: 62.5%; Average loss: 2.9097\n",
            "Returned Loss: 3.1027878163216625\n",
            "Done One Timestep\n",
            "Iteration: 2503; Percent complete: 62.6%; Average loss: 3.1028\n",
            "Returned Loss: 2.846553126846661\n",
            "Done One Timestep\n",
            "Iteration: 2504; Percent complete: 62.6%; Average loss: 2.8466\n",
            "Returned Loss: 2.868088791883021\n",
            "Done One Timestep\n",
            "Iteration: 2505; Percent complete: 62.6%; Average loss: 2.8681\n",
            "Returned Loss: 3.0934732313123727\n",
            "Done One Timestep\n",
            "Iteration: 2506; Percent complete: 62.6%; Average loss: 3.0935\n",
            "Returned Loss: 2.87456331682674\n",
            "Done One Timestep\n",
            "Iteration: 2507; Percent complete: 62.7%; Average loss: 2.8746\n",
            "Returned Loss: 3.1131061330152145\n",
            "Done One Timestep\n",
            "Iteration: 2508; Percent complete: 62.7%; Average loss: 3.1131\n",
            "Returned Loss: 3.12009619038443\n",
            "Done One Timestep\n",
            "Iteration: 2509; Percent complete: 62.7%; Average loss: 3.1201\n",
            "Returned Loss: 2.7766089429665484\n",
            "Done One Timestep\n",
            "Iteration: 2510; Percent complete: 62.7%; Average loss: 2.7766\n",
            "Returned Loss: 3.063451977440565\n",
            "Done One Timestep\n",
            "Iteration: 2511; Percent complete: 62.8%; Average loss: 3.0635\n",
            "Returned Loss: 2.710203298656245\n",
            "Done One Timestep\n",
            "Iteration: 2512; Percent complete: 62.8%; Average loss: 2.7102\n",
            "Returned Loss: 3.1772904897278007\n",
            "Done One Timestep\n",
            "Iteration: 2513; Percent complete: 62.8%; Average loss: 3.1773\n",
            "Returned Loss: 2.847771416172601\n",
            "Done One Timestep\n",
            "Iteration: 2514; Percent complete: 62.8%; Average loss: 2.8478\n",
            "Returned Loss: 3.22945286844738\n",
            "Done One Timestep\n",
            "Iteration: 2515; Percent complete: 62.9%; Average loss: 3.2295\n",
            "Returned Loss: 3.0262075315751904\n",
            "Done One Timestep\n",
            "Iteration: 2516; Percent complete: 62.9%; Average loss: 3.0262\n",
            "Returned Loss: 3.004810457170936\n",
            "Done One Timestep\n",
            "Iteration: 2517; Percent complete: 62.9%; Average loss: 3.0048\n",
            "Returned Loss: 2.986649452836106\n",
            "Done One Timestep\n",
            "Iteration: 2518; Percent complete: 62.9%; Average loss: 2.9866\n",
            "Returned Loss: 2.94424198372086\n",
            "Done One Timestep\n",
            "Iteration: 2519; Percent complete: 63.0%; Average loss: 2.9442\n",
            "Returned Loss: 2.9016867442886225\n",
            "Done One Timestep\n",
            "Iteration: 2520; Percent complete: 63.0%; Average loss: 2.9017\n",
            "Returned Loss: 3.1552966524447714\n",
            "Done One Timestep\n",
            "Iteration: 2521; Percent complete: 63.0%; Average loss: 3.1553\n",
            "Returned Loss: 3.082019321669853\n",
            "Done One Timestep\n",
            "Iteration: 2522; Percent complete: 63.0%; Average loss: 3.0820\n",
            "Returned Loss: 3.009137990657345\n",
            "Done One Timestep\n",
            "Iteration: 2523; Percent complete: 63.1%; Average loss: 3.0091\n",
            "Returned Loss: 2.9908102878449876\n",
            "Done One Timestep\n",
            "Iteration: 2524; Percent complete: 63.1%; Average loss: 2.9908\n",
            "Returned Loss: 2.6789502263532983\n",
            "Done One Timestep\n",
            "Iteration: 2525; Percent complete: 63.1%; Average loss: 2.6790\n",
            "Returned Loss: 3.0852165691137605\n",
            "Done One Timestep\n",
            "Iteration: 2526; Percent complete: 63.1%; Average loss: 3.0852\n",
            "Returned Loss: 3.0946992238223627\n",
            "Done One Timestep\n",
            "Iteration: 2527; Percent complete: 63.2%; Average loss: 3.0947\n",
            "Returned Loss: 3.0759435287150354\n",
            "Done One Timestep\n",
            "Iteration: 2528; Percent complete: 63.2%; Average loss: 3.0759\n",
            "Returned Loss: 2.9965596007727426\n",
            "Done One Timestep\n",
            "Iteration: 2529; Percent complete: 63.2%; Average loss: 2.9966\n",
            "Returned Loss: 2.8456462008254406\n",
            "Done One Timestep\n",
            "Iteration: 2530; Percent complete: 63.2%; Average loss: 2.8456\n",
            "Returned Loss: 2.8535698931881828\n",
            "Done One Timestep\n",
            "Iteration: 2531; Percent complete: 63.3%; Average loss: 2.8536\n",
            "Returned Loss: 2.9815196980515286\n",
            "Done One Timestep\n",
            "Iteration: 2532; Percent complete: 63.3%; Average loss: 2.9815\n",
            "Returned Loss: 3.2528493012675064\n",
            "Done One Timestep\n",
            "Iteration: 2533; Percent complete: 63.3%; Average loss: 3.2528\n",
            "Returned Loss: 3.001266684130713\n",
            "Done One Timestep\n",
            "Iteration: 2534; Percent complete: 63.3%; Average loss: 3.0013\n",
            "Returned Loss: 2.8413219012736746\n",
            "Done One Timestep\n",
            "Iteration: 2535; Percent complete: 63.4%; Average loss: 2.8413\n",
            "Returned Loss: 3.1586356910800233\n",
            "Done One Timestep\n",
            "Iteration: 2536; Percent complete: 63.4%; Average loss: 3.1586\n",
            "Returned Loss: 3.1493744001945987\n",
            "Done One Timestep\n",
            "Iteration: 2537; Percent complete: 63.4%; Average loss: 3.1494\n",
            "Returned Loss: 3.0096428707924825\n",
            "Done One Timestep\n",
            "Iteration: 2538; Percent complete: 63.4%; Average loss: 3.0096\n",
            "Returned Loss: 2.8335112267364866\n",
            "Done One Timestep\n",
            "Iteration: 2539; Percent complete: 63.5%; Average loss: 2.8335\n",
            "Returned Loss: 2.811180792730161\n",
            "Done One Timestep\n",
            "Iteration: 2540; Percent complete: 63.5%; Average loss: 2.8112\n",
            "Returned Loss: 2.826018799934476\n",
            "Done One Timestep\n",
            "Iteration: 2541; Percent complete: 63.5%; Average loss: 2.8260\n",
            "Returned Loss: 3.085461915327023\n",
            "Done One Timestep\n",
            "Iteration: 2542; Percent complete: 63.5%; Average loss: 3.0855\n",
            "Returned Loss: 3.2678301360573148\n",
            "Done One Timestep\n",
            "Iteration: 2543; Percent complete: 63.6%; Average loss: 3.2678\n",
            "Returned Loss: 3.068641978452518\n",
            "Done One Timestep\n",
            "Iteration: 2544; Percent complete: 63.6%; Average loss: 3.0686\n",
            "Returned Loss: 3.0791015966680466\n",
            "Done One Timestep\n",
            "Iteration: 2545; Percent complete: 63.6%; Average loss: 3.0791\n",
            "Returned Loss: 2.7899290119357474\n",
            "Done One Timestep\n",
            "Iteration: 2546; Percent complete: 63.6%; Average loss: 2.7899\n",
            "Returned Loss: 3.1338533934383164\n",
            "Done One Timestep\n",
            "Iteration: 2547; Percent complete: 63.7%; Average loss: 3.1339\n",
            "Returned Loss: 2.942325500107949\n",
            "Done One Timestep\n",
            "Iteration: 2548; Percent complete: 63.7%; Average loss: 2.9423\n",
            "Returned Loss: 2.957348501237394\n",
            "Done One Timestep\n",
            "Iteration: 2549; Percent complete: 63.7%; Average loss: 2.9573\n",
            "Returned Loss: 2.966513264709559\n",
            "Done One Timestep\n",
            "Iteration: 2550; Percent complete: 63.7%; Average loss: 2.9665\n",
            "Returned Loss: 2.974429724955869\n",
            "Done One Timestep\n",
            "Iteration: 2551; Percent complete: 63.8%; Average loss: 2.9744\n",
            "Returned Loss: 3.0442997999838823\n",
            "Done One Timestep\n",
            "Iteration: 2552; Percent complete: 63.8%; Average loss: 3.0443\n",
            "Returned Loss: 3.087741348964802\n",
            "Done One Timestep\n",
            "Iteration: 2553; Percent complete: 63.8%; Average loss: 3.0877\n",
            "Returned Loss: 3.2007067405473917\n",
            "Done One Timestep\n",
            "Iteration: 2554; Percent complete: 63.8%; Average loss: 3.2007\n",
            "Returned Loss: 3.3005277780271767\n",
            "Done One Timestep\n",
            "Iteration: 2555; Percent complete: 63.9%; Average loss: 3.3005\n",
            "Returned Loss: 3.1692998263506853\n",
            "Done One Timestep\n",
            "Iteration: 2556; Percent complete: 63.9%; Average loss: 3.1693\n",
            "Returned Loss: 3.0845877708166913\n",
            "Done One Timestep\n",
            "Iteration: 2557; Percent complete: 63.9%; Average loss: 3.0846\n",
            "Returned Loss: 3.1319248270870093\n",
            "Done One Timestep\n",
            "Iteration: 2558; Percent complete: 63.9%; Average loss: 3.1319\n",
            "Returned Loss: 2.9863885248966797\n",
            "Done One Timestep\n",
            "Iteration: 2559; Percent complete: 64.0%; Average loss: 2.9864\n",
            "Returned Loss: 3.028908637340499\n",
            "Done One Timestep\n",
            "Iteration: 2560; Percent complete: 64.0%; Average loss: 3.0289\n",
            "Returned Loss: 3.175668017471887\n",
            "Done One Timestep\n",
            "Iteration: 2561; Percent complete: 64.0%; Average loss: 3.1757\n",
            "Returned Loss: 2.8420118983065956\n",
            "Done One Timestep\n",
            "Iteration: 2562; Percent complete: 64.0%; Average loss: 2.8420\n",
            "Returned Loss: 3.079953491402629\n",
            "Done One Timestep\n",
            "Iteration: 2563; Percent complete: 64.1%; Average loss: 3.0800\n",
            "Returned Loss: 2.9099186744221988\n",
            "Done One Timestep\n",
            "Iteration: 2564; Percent complete: 64.1%; Average loss: 2.9099\n",
            "Returned Loss: 2.6457035263502315\n",
            "Done One Timestep\n",
            "Iteration: 2565; Percent complete: 64.1%; Average loss: 2.6457\n",
            "Returned Loss: 2.9270567506626812\n",
            "Done One Timestep\n",
            "Iteration: 2566; Percent complete: 64.1%; Average loss: 2.9271\n",
            "Returned Loss: 3.108828624006723\n",
            "Done One Timestep\n",
            "Iteration: 2567; Percent complete: 64.2%; Average loss: 3.1088\n",
            "Returned Loss: 3.0848741857652744\n",
            "Done One Timestep\n",
            "Iteration: 2568; Percent complete: 64.2%; Average loss: 3.0849\n",
            "Returned Loss: 2.989169674565231\n",
            "Done One Timestep\n",
            "Iteration: 2569; Percent complete: 64.2%; Average loss: 2.9892\n",
            "Returned Loss: 2.884305563392214\n",
            "Done One Timestep\n",
            "Iteration: 2570; Percent complete: 64.2%; Average loss: 2.8843\n",
            "Returned Loss: 3.1142533557364143\n",
            "Done One Timestep\n",
            "Iteration: 2571; Percent complete: 64.3%; Average loss: 3.1143\n",
            "Returned Loss: 2.85071212618834\n",
            "Done One Timestep\n",
            "Iteration: 2572; Percent complete: 64.3%; Average loss: 2.8507\n",
            "Returned Loss: 3.170824215835538\n",
            "Done One Timestep\n",
            "Iteration: 2573; Percent complete: 64.3%; Average loss: 3.1708\n",
            "Returned Loss: 3.0729518495408557\n",
            "Done One Timestep\n",
            "Iteration: 2574; Percent complete: 64.3%; Average loss: 3.0730\n",
            "Returned Loss: 2.9817430986253024\n",
            "Done One Timestep\n",
            "Iteration: 2575; Percent complete: 64.4%; Average loss: 2.9817\n",
            "Returned Loss: 2.9216598903696083\n",
            "Done One Timestep\n",
            "Iteration: 2576; Percent complete: 64.4%; Average loss: 2.9217\n",
            "Returned Loss: 3.2389292677378294\n",
            "Done One Timestep\n",
            "Iteration: 2577; Percent complete: 64.4%; Average loss: 3.2389\n",
            "Returned Loss: 3.105127550027282\n",
            "Done One Timestep\n",
            "Iteration: 2578; Percent complete: 64.5%; Average loss: 3.1051\n",
            "Returned Loss: 3.0089036251319428\n",
            "Done One Timestep\n",
            "Iteration: 2579; Percent complete: 64.5%; Average loss: 3.0089\n",
            "Returned Loss: 2.905550088128935\n",
            "Done One Timestep\n",
            "Iteration: 2580; Percent complete: 64.5%; Average loss: 2.9056\n",
            "Returned Loss: 2.990933370932483\n",
            "Done One Timestep\n",
            "Iteration: 2581; Percent complete: 64.5%; Average loss: 2.9909\n",
            "Returned Loss: 2.835011847449289\n",
            "Done One Timestep\n",
            "Iteration: 2582; Percent complete: 64.5%; Average loss: 2.8350\n",
            "Returned Loss: 2.9258197317441135\n",
            "Done One Timestep\n",
            "Iteration: 2583; Percent complete: 64.6%; Average loss: 2.9258\n",
            "Returned Loss: 3.21545736339483\n",
            "Done One Timestep\n",
            "Iteration: 2584; Percent complete: 64.6%; Average loss: 3.2155\n",
            "Returned Loss: 3.1556997325824727\n",
            "Done One Timestep\n",
            "Iteration: 2585; Percent complete: 64.6%; Average loss: 3.1557\n",
            "Returned Loss: 2.95674155413783\n",
            "Done One Timestep\n",
            "Iteration: 2586; Percent complete: 64.6%; Average loss: 2.9567\n",
            "Returned Loss: 3.1373152170668948\n",
            "Done One Timestep\n",
            "Iteration: 2587; Percent complete: 64.7%; Average loss: 3.1373\n",
            "Returned Loss: 3.09429994955855\n",
            "Done One Timestep\n",
            "Iteration: 2588; Percent complete: 64.7%; Average loss: 3.0943\n",
            "Returned Loss: 3.1573731680873514\n",
            "Done One Timestep\n",
            "Iteration: 2589; Percent complete: 64.7%; Average loss: 3.1574\n",
            "Returned Loss: 2.839287041904541\n",
            "Done One Timestep\n",
            "Iteration: 2590; Percent complete: 64.8%; Average loss: 2.8393\n",
            "Returned Loss: 3.0055636099122207\n",
            "Done One Timestep\n",
            "Iteration: 2591; Percent complete: 64.8%; Average loss: 3.0056\n",
            "Returned Loss: 3.1289465862047177\n",
            "Done One Timestep\n",
            "Iteration: 2592; Percent complete: 64.8%; Average loss: 3.1289\n",
            "Returned Loss: 3.3095240329702693\n",
            "Done One Timestep\n",
            "Iteration: 2593; Percent complete: 64.8%; Average loss: 3.3095\n",
            "Returned Loss: 3.1613239990113002\n",
            "Done One Timestep\n",
            "Iteration: 2594; Percent complete: 64.8%; Average loss: 3.1613\n",
            "Returned Loss: 2.9634241181118486\n",
            "Done One Timestep\n",
            "Iteration: 2595; Percent complete: 64.9%; Average loss: 2.9634\n",
            "Returned Loss: 2.9613763462608578\n",
            "Done One Timestep\n",
            "Iteration: 2596; Percent complete: 64.9%; Average loss: 2.9614\n",
            "Returned Loss: 3.0653202470770493\n",
            "Done One Timestep\n",
            "Iteration: 2597; Percent complete: 64.9%; Average loss: 3.0653\n",
            "Returned Loss: 2.9977245548444675\n",
            "Done One Timestep\n",
            "Iteration: 2598; Percent complete: 65.0%; Average loss: 2.9977\n",
            "Returned Loss: 2.933825185220976\n",
            "Done One Timestep\n",
            "Iteration: 2599; Percent complete: 65.0%; Average loss: 2.9338\n",
            "Returned Loss: 3.0134100316713255\n",
            "Done One Timestep\n",
            "Iteration: 2600; Percent complete: 65.0%; Average loss: 3.0134\n",
            "Returned Loss: 2.9770295975394743\n",
            "Done One Timestep\n",
            "Iteration: 2601; Percent complete: 65.0%; Average loss: 2.9770\n",
            "Returned Loss: 3.1413790287689256\n",
            "Done One Timestep\n",
            "Iteration: 2602; Percent complete: 65.0%; Average loss: 3.1414\n",
            "Returned Loss: 3.165037148004776\n",
            "Done One Timestep\n",
            "Iteration: 2603; Percent complete: 65.1%; Average loss: 3.1650\n",
            "Returned Loss: 2.883280131841083\n",
            "Done One Timestep\n",
            "Iteration: 2604; Percent complete: 65.1%; Average loss: 2.8833\n",
            "Returned Loss: 3.04095441527199\n",
            "Done One Timestep\n",
            "Iteration: 2605; Percent complete: 65.1%; Average loss: 3.0410\n",
            "Returned Loss: 2.881152525992322\n",
            "Done One Timestep\n",
            "Iteration: 2606; Percent complete: 65.1%; Average loss: 2.8812\n",
            "Returned Loss: 3.031742265644765\n",
            "Done One Timestep\n",
            "Iteration: 2607; Percent complete: 65.2%; Average loss: 3.0317\n",
            "Returned Loss: 2.9006021590742432\n",
            "Done One Timestep\n",
            "Iteration: 2608; Percent complete: 65.2%; Average loss: 2.9006\n",
            "Returned Loss: 2.891562894212477\n",
            "Done One Timestep\n",
            "Iteration: 2609; Percent complete: 65.2%; Average loss: 2.8916\n",
            "Returned Loss: 2.8489973166916376\n",
            "Done One Timestep\n",
            "Iteration: 2610; Percent complete: 65.2%; Average loss: 2.8490\n",
            "Returned Loss: 2.9471141475456464\n",
            "Done One Timestep\n",
            "Iteration: 2611; Percent complete: 65.3%; Average loss: 2.9471\n",
            "Returned Loss: 3.01203397508479\n",
            "Done One Timestep\n",
            "Iteration: 2612; Percent complete: 65.3%; Average loss: 3.0120\n",
            "Returned Loss: 2.911944912322785\n",
            "Done One Timestep\n",
            "Iteration: 2613; Percent complete: 65.3%; Average loss: 2.9119\n",
            "Returned Loss: 3.0880000997601456\n",
            "Done One Timestep\n",
            "Iteration: 2614; Percent complete: 65.3%; Average loss: 3.0880\n",
            "Returned Loss: 2.8197423908953327\n",
            "Done One Timestep\n",
            "Iteration: 2615; Percent complete: 65.4%; Average loss: 2.8197\n",
            "Returned Loss: 2.9820621867434065\n",
            "Done One Timestep\n",
            "Iteration: 2616; Percent complete: 65.4%; Average loss: 2.9821\n",
            "Returned Loss: 2.8174441774502736\n",
            "Done One Timestep\n",
            "Iteration: 2617; Percent complete: 65.4%; Average loss: 2.8174\n",
            "Returned Loss: 2.832499484689455\n",
            "Done One Timestep\n",
            "Iteration: 2618; Percent complete: 65.5%; Average loss: 2.8325\n",
            "Returned Loss: 2.995246057601901\n",
            "Done One Timestep\n",
            "Iteration: 2619; Percent complete: 65.5%; Average loss: 2.9952\n",
            "Returned Loss: 3.0742255744487537\n",
            "Done One Timestep\n",
            "Iteration: 2620; Percent complete: 65.5%; Average loss: 3.0742\n",
            "Returned Loss: 3.0738244553355556\n",
            "Done One Timestep\n",
            "Iteration: 2621; Percent complete: 65.5%; Average loss: 3.0738\n",
            "Returned Loss: 2.915554926544428\n",
            "Done One Timestep\n",
            "Iteration: 2622; Percent complete: 65.5%; Average loss: 2.9156\n",
            "Returned Loss: 3.0046471695473604\n",
            "Done One Timestep\n",
            "Iteration: 2623; Percent complete: 65.6%; Average loss: 3.0046\n",
            "Returned Loss: 2.9752537832956203\n",
            "Done One Timestep\n",
            "Iteration: 2624; Percent complete: 65.6%; Average loss: 2.9753\n",
            "Returned Loss: 3.319338649752154\n",
            "Done One Timestep\n",
            "Iteration: 2625; Percent complete: 65.6%; Average loss: 3.3193\n",
            "Returned Loss: 2.772283272995126\n",
            "Done One Timestep\n",
            "Iteration: 2626; Percent complete: 65.6%; Average loss: 2.7723\n",
            "Returned Loss: 3.012295536175395\n",
            "Done One Timestep\n",
            "Iteration: 2627; Percent complete: 65.7%; Average loss: 3.0123\n",
            "Returned Loss: 2.9026060027269582\n",
            "Done One Timestep\n",
            "Iteration: 2628; Percent complete: 65.7%; Average loss: 2.9026\n",
            "Returned Loss: 2.813068925886729\n",
            "Done One Timestep\n",
            "Iteration: 2629; Percent complete: 65.7%; Average loss: 2.8131\n",
            "Returned Loss: 3.0971055586481824\n",
            "Done One Timestep\n",
            "Iteration: 2630; Percent complete: 65.8%; Average loss: 3.0971\n",
            "Returned Loss: 2.757647598314346\n",
            "Done One Timestep\n",
            "Iteration: 2631; Percent complete: 65.8%; Average loss: 2.7576\n",
            "Returned Loss: 3.1476793639526903\n",
            "Done One Timestep\n",
            "Iteration: 2632; Percent complete: 65.8%; Average loss: 3.1477\n",
            "Returned Loss: 2.8500591864677394\n",
            "Done One Timestep\n",
            "Iteration: 2633; Percent complete: 65.8%; Average loss: 2.8501\n",
            "Returned Loss: 3.230579923563162\n",
            "Done One Timestep\n",
            "Iteration: 2634; Percent complete: 65.8%; Average loss: 3.2306\n",
            "Returned Loss: 3.167203046573915\n",
            "Done One Timestep\n",
            "Iteration: 2635; Percent complete: 65.9%; Average loss: 3.1672\n",
            "Returned Loss: 2.8444409179051227\n",
            "Done One Timestep\n",
            "Iteration: 2636; Percent complete: 65.9%; Average loss: 2.8444\n",
            "Returned Loss: 3.0544007996119924\n",
            "Done One Timestep\n",
            "Iteration: 2637; Percent complete: 65.9%; Average loss: 3.0544\n",
            "Returned Loss: 2.845995692796669\n",
            "Done One Timestep\n",
            "Iteration: 2638; Percent complete: 66.0%; Average loss: 2.8460\n",
            "Returned Loss: 3.0336043416227723\n",
            "Done One Timestep\n",
            "Iteration: 2639; Percent complete: 66.0%; Average loss: 3.0336\n",
            "Returned Loss: 2.9356284927105225\n",
            "Done One Timestep\n",
            "Iteration: 2640; Percent complete: 66.0%; Average loss: 2.9356\n",
            "Returned Loss: 2.943014887056718\n",
            "Done One Timestep\n",
            "Iteration: 2641; Percent complete: 66.0%; Average loss: 2.9430\n",
            "Returned Loss: 3.111638131437405\n",
            "Done One Timestep\n",
            "Iteration: 2642; Percent complete: 66.0%; Average loss: 3.1116\n",
            "Returned Loss: 2.9836588401437716\n",
            "Done One Timestep\n",
            "Iteration: 2643; Percent complete: 66.1%; Average loss: 2.9837\n",
            "Returned Loss: 2.995289236592069\n",
            "Done One Timestep\n",
            "Iteration: 2644; Percent complete: 66.1%; Average loss: 2.9953\n",
            "Returned Loss: 2.9445119648055136\n",
            "Done One Timestep\n",
            "Iteration: 2645; Percent complete: 66.1%; Average loss: 2.9445\n",
            "Returned Loss: 2.8168937099350537\n",
            "Done One Timestep\n",
            "Iteration: 2646; Percent complete: 66.1%; Average loss: 2.8169\n",
            "Returned Loss: 2.8769915019455596\n",
            "Done One Timestep\n",
            "Iteration: 2647; Percent complete: 66.2%; Average loss: 2.8770\n",
            "Returned Loss: 3.106919771121086\n",
            "Done One Timestep\n",
            "Iteration: 2648; Percent complete: 66.2%; Average loss: 3.1069\n",
            "Returned Loss: 2.944357052652108\n",
            "Done One Timestep\n",
            "Iteration: 2649; Percent complete: 66.2%; Average loss: 2.9444\n",
            "Returned Loss: 2.742238620107926\n",
            "Done One Timestep\n",
            "Iteration: 2650; Percent complete: 66.2%; Average loss: 2.7422\n",
            "Returned Loss: 3.06509589008928\n",
            "Done One Timestep\n",
            "Iteration: 2651; Percent complete: 66.3%; Average loss: 3.0651\n",
            "Returned Loss: 3.0466964682787\n",
            "Done One Timestep\n",
            "Iteration: 2652; Percent complete: 66.3%; Average loss: 3.0467\n",
            "Returned Loss: 3.0822277097676944\n",
            "Done One Timestep\n",
            "Iteration: 2653; Percent complete: 66.3%; Average loss: 3.0822\n",
            "Returned Loss: 2.7951998614649582\n",
            "Done One Timestep\n",
            "Iteration: 2654; Percent complete: 66.3%; Average loss: 2.7952\n",
            "Returned Loss: 2.893155057556776\n",
            "Done One Timestep\n",
            "Iteration: 2655; Percent complete: 66.4%; Average loss: 2.8932\n",
            "Returned Loss: 3.0063048444115434\n",
            "Done One Timestep\n",
            "Iteration: 2656; Percent complete: 66.4%; Average loss: 3.0063\n",
            "Returned Loss: 3.0596311877382973\n",
            "Done One Timestep\n",
            "Iteration: 2657; Percent complete: 66.4%; Average loss: 3.0596\n",
            "Returned Loss: 2.8110125806644883\n",
            "Done One Timestep\n",
            "Iteration: 2658; Percent complete: 66.5%; Average loss: 2.8110\n",
            "Returned Loss: 2.9961744091160747\n",
            "Done One Timestep\n",
            "Iteration: 2659; Percent complete: 66.5%; Average loss: 2.9962\n",
            "Returned Loss: 2.9030124549210297\n",
            "Done One Timestep\n",
            "Iteration: 2660; Percent complete: 66.5%; Average loss: 2.9030\n",
            "Returned Loss: 2.913163017539173\n",
            "Done One Timestep\n",
            "Iteration: 2661; Percent complete: 66.5%; Average loss: 2.9132\n",
            "Returned Loss: 2.941755004384016\n",
            "Done One Timestep\n",
            "Iteration: 2662; Percent complete: 66.5%; Average loss: 2.9418\n",
            "Returned Loss: 2.962692391242861\n",
            "Done One Timestep\n",
            "Iteration: 2663; Percent complete: 66.6%; Average loss: 2.9627\n",
            "Returned Loss: 3.0333173670234337\n",
            "Done One Timestep\n",
            "Iteration: 2664; Percent complete: 66.6%; Average loss: 3.0333\n",
            "Returned Loss: 2.975460940340163\n",
            "Done One Timestep\n",
            "Iteration: 2665; Percent complete: 66.6%; Average loss: 2.9755\n",
            "Returned Loss: 3.40665666471069\n",
            "Done One Timestep\n",
            "Iteration: 2666; Percent complete: 66.6%; Average loss: 3.4067\n",
            "Returned Loss: 2.929324724870935\n",
            "Done One Timestep\n",
            "Iteration: 2667; Percent complete: 66.7%; Average loss: 2.9293\n",
            "Returned Loss: 2.837251205304927\n",
            "Done One Timestep\n",
            "Iteration: 2668; Percent complete: 66.7%; Average loss: 2.8373\n",
            "Returned Loss: 3.0918776640778347\n",
            "Done One Timestep\n",
            "Iteration: 2669; Percent complete: 66.7%; Average loss: 3.0919\n",
            "Returned Loss: 3.075004956609494\n",
            "Done One Timestep\n",
            "Iteration: 2670; Percent complete: 66.8%; Average loss: 3.0750\n",
            "Returned Loss: 2.928209505065889\n",
            "Done One Timestep\n",
            "Iteration: 2671; Percent complete: 66.8%; Average loss: 2.9282\n",
            "Returned Loss: 3.0007722528609717\n",
            "Done One Timestep\n",
            "Iteration: 2672; Percent complete: 66.8%; Average loss: 3.0008\n",
            "Returned Loss: 3.23124658540091\n",
            "Done One Timestep\n",
            "Iteration: 2673; Percent complete: 66.8%; Average loss: 3.2312\n",
            "Returned Loss: 3.016306330151182\n",
            "Done One Timestep\n",
            "Iteration: 2674; Percent complete: 66.8%; Average loss: 3.0163\n",
            "Returned Loss: 2.9279505963996053\n",
            "Done One Timestep\n",
            "Iteration: 2675; Percent complete: 66.9%; Average loss: 2.9280\n",
            "Returned Loss: 3.010643282240517\n",
            "Done One Timestep\n",
            "Iteration: 2676; Percent complete: 66.9%; Average loss: 3.0106\n",
            "Returned Loss: 3.1731391493649905\n",
            "Done One Timestep\n",
            "Iteration: 2677; Percent complete: 66.9%; Average loss: 3.1731\n",
            "Returned Loss: 3.1428284063742806\n",
            "Done One Timestep\n",
            "Iteration: 2678; Percent complete: 67.0%; Average loss: 3.1428\n",
            "Returned Loss: 3.125922029022213\n",
            "Done One Timestep\n",
            "Iteration: 2679; Percent complete: 67.0%; Average loss: 3.1259\n",
            "Returned Loss: 3.066779531670036\n",
            "Done One Timestep\n",
            "Iteration: 2680; Percent complete: 67.0%; Average loss: 3.0668\n",
            "Returned Loss: 2.684249192079937\n",
            "Done One Timestep\n",
            "Iteration: 2681; Percent complete: 67.0%; Average loss: 2.6842\n",
            "Returned Loss: 2.6978257201343476\n",
            "Done One Timestep\n",
            "Iteration: 2682; Percent complete: 67.0%; Average loss: 2.6978\n",
            "Returned Loss: 3.177327090495891\n",
            "Done One Timestep\n",
            "Iteration: 2683; Percent complete: 67.1%; Average loss: 3.1773\n",
            "Returned Loss: 2.6595470886107306\n",
            "Done One Timestep\n",
            "Iteration: 2684; Percent complete: 67.1%; Average loss: 2.6595\n",
            "Returned Loss: 3.1146726201508708\n",
            "Done One Timestep\n",
            "Iteration: 2685; Percent complete: 67.1%; Average loss: 3.1147\n",
            "Returned Loss: 2.9565908903071736\n",
            "Done One Timestep\n",
            "Iteration: 2686; Percent complete: 67.2%; Average loss: 2.9566\n",
            "Returned Loss: 2.8790976709002924\n",
            "Done One Timestep\n",
            "Iteration: 2687; Percent complete: 67.2%; Average loss: 2.8791\n",
            "Returned Loss: 3.2828012383447436\n",
            "Done One Timestep\n",
            "Iteration: 2688; Percent complete: 67.2%; Average loss: 3.2828\n",
            "Returned Loss: 2.9522157017068538\n",
            "Done One Timestep\n",
            "Iteration: 2689; Percent complete: 67.2%; Average loss: 2.9522\n",
            "Returned Loss: 2.885485658323086\n",
            "Done One Timestep\n",
            "Iteration: 2690; Percent complete: 67.2%; Average loss: 2.8855\n",
            "Returned Loss: 2.7175202033490296\n",
            "Done One Timestep\n",
            "Iteration: 2691; Percent complete: 67.3%; Average loss: 2.7175\n",
            "Returned Loss: 2.903543764025049\n",
            "Done One Timestep\n",
            "Iteration: 2692; Percent complete: 67.3%; Average loss: 2.9035\n",
            "Returned Loss: 2.879402322623202\n",
            "Done One Timestep\n",
            "Iteration: 2693; Percent complete: 67.3%; Average loss: 2.8794\n",
            "Returned Loss: 3.026337546081497\n",
            "Done One Timestep\n",
            "Iteration: 2694; Percent complete: 67.3%; Average loss: 3.0263\n",
            "Returned Loss: 2.839893325775241\n",
            "Done One Timestep\n",
            "Iteration: 2695; Percent complete: 67.4%; Average loss: 2.8399\n",
            "Returned Loss: 3.1126812692789523\n",
            "Done One Timestep\n",
            "Iteration: 2696; Percent complete: 67.4%; Average loss: 3.1127\n",
            "Returned Loss: 2.870803302641972\n",
            "Done One Timestep\n",
            "Iteration: 2697; Percent complete: 67.4%; Average loss: 2.8708\n",
            "Returned Loss: 2.764852639468072\n",
            "Done One Timestep\n",
            "Iteration: 2698; Percent complete: 67.5%; Average loss: 2.7649\n",
            "Returned Loss: 2.89134226921063\n",
            "Done One Timestep\n",
            "Iteration: 2699; Percent complete: 67.5%; Average loss: 2.8913\n",
            "Returned Loss: 2.941441615422567\n",
            "Done One Timestep\n",
            "Iteration: 2700; Percent complete: 67.5%; Average loss: 2.9414\n",
            "Returned Loss: 3.2418244461892978\n",
            "Done One Timestep\n",
            "Iteration: 2701; Percent complete: 67.5%; Average loss: 3.2418\n",
            "Returned Loss: 3.0738617667357127\n",
            "Done One Timestep\n",
            "Iteration: 2702; Percent complete: 67.5%; Average loss: 3.0739\n",
            "Returned Loss: 2.972866064058392\n",
            "Done One Timestep\n",
            "Iteration: 2703; Percent complete: 67.6%; Average loss: 2.9729\n",
            "Returned Loss: 2.793893365302763\n",
            "Done One Timestep\n",
            "Iteration: 2704; Percent complete: 67.6%; Average loss: 2.7939\n",
            "Returned Loss: 2.971994981760324\n",
            "Done One Timestep\n",
            "Iteration: 2705; Percent complete: 67.6%; Average loss: 2.9720\n",
            "Returned Loss: 2.8640002709545693\n",
            "Done One Timestep\n",
            "Iteration: 2706; Percent complete: 67.7%; Average loss: 2.8640\n",
            "Returned Loss: 2.943726110069983\n",
            "Done One Timestep\n",
            "Iteration: 2707; Percent complete: 67.7%; Average loss: 2.9437\n",
            "Returned Loss: 2.939623406067528\n",
            "Done One Timestep\n",
            "Iteration: 2708; Percent complete: 67.7%; Average loss: 2.9396\n",
            "Returned Loss: 3.1464630636034343\n",
            "Done One Timestep\n",
            "Iteration: 2709; Percent complete: 67.7%; Average loss: 3.1465\n",
            "Returned Loss: 3.1060684395646585\n",
            "Done One Timestep\n",
            "Iteration: 2710; Percent complete: 67.8%; Average loss: 3.1061\n",
            "Returned Loss: 3.2093524082051093\n",
            "Done One Timestep\n",
            "Iteration: 2711; Percent complete: 67.8%; Average loss: 3.2094\n",
            "Returned Loss: 3.0969729171531295\n",
            "Done One Timestep\n",
            "Iteration: 2712; Percent complete: 67.8%; Average loss: 3.0970\n",
            "Returned Loss: 3.043687451318814\n",
            "Done One Timestep\n",
            "Iteration: 2713; Percent complete: 67.8%; Average loss: 3.0437\n",
            "Returned Loss: 3.0535564665261936\n",
            "Done One Timestep\n",
            "Iteration: 2714; Percent complete: 67.8%; Average loss: 3.0536\n",
            "Returned Loss: 2.803331573486912\n",
            "Done One Timestep\n",
            "Iteration: 2715; Percent complete: 67.9%; Average loss: 2.8033\n",
            "Returned Loss: 2.888019872562124\n",
            "Done One Timestep\n",
            "Iteration: 2716; Percent complete: 67.9%; Average loss: 2.8880\n",
            "Returned Loss: 2.9200008148159013\n",
            "Done One Timestep\n",
            "Iteration: 2717; Percent complete: 67.9%; Average loss: 2.9200\n",
            "Returned Loss: 2.717670371491929\n",
            "Done One Timestep\n",
            "Iteration: 2718; Percent complete: 68.0%; Average loss: 2.7177\n",
            "Returned Loss: 2.9834261128065607\n",
            "Done One Timestep\n",
            "Iteration: 2719; Percent complete: 68.0%; Average loss: 2.9834\n",
            "Returned Loss: 2.9510253367467825\n",
            "Done One Timestep\n",
            "Iteration: 2720; Percent complete: 68.0%; Average loss: 2.9510\n",
            "Returned Loss: 3.0621069775015335\n",
            "Done One Timestep\n",
            "Iteration: 2721; Percent complete: 68.0%; Average loss: 3.0621\n",
            "Returned Loss: 3.1630919008998504\n",
            "Done One Timestep\n",
            "Iteration: 2722; Percent complete: 68.0%; Average loss: 3.1631\n",
            "Returned Loss: 2.9072157084189643\n",
            "Done One Timestep\n",
            "Iteration: 2723; Percent complete: 68.1%; Average loss: 2.9072\n",
            "Returned Loss: 3.0517586926944205\n",
            "Done One Timestep\n",
            "Iteration: 2724; Percent complete: 68.1%; Average loss: 3.0518\n",
            "Returned Loss: 2.912138283212374\n",
            "Done One Timestep\n",
            "Iteration: 2725; Percent complete: 68.1%; Average loss: 2.9121\n",
            "Returned Loss: 3.017407089770998\n",
            "Done One Timestep\n",
            "Iteration: 2726; Percent complete: 68.2%; Average loss: 3.0174\n",
            "Returned Loss: 3.158347653686536\n",
            "Done One Timestep\n",
            "Iteration: 2727; Percent complete: 68.2%; Average loss: 3.1583\n",
            "Returned Loss: 3.0066254344970496\n",
            "Done One Timestep\n",
            "Iteration: 2728; Percent complete: 68.2%; Average loss: 3.0066\n",
            "Returned Loss: 2.9071647365992805\n",
            "Done One Timestep\n",
            "Iteration: 2729; Percent complete: 68.2%; Average loss: 2.9072\n",
            "Returned Loss: 2.7988088695308218\n",
            "Done One Timestep\n",
            "Iteration: 2730; Percent complete: 68.2%; Average loss: 2.7988\n",
            "Returned Loss: 2.852910048931297\n",
            "Done One Timestep\n",
            "Iteration: 2731; Percent complete: 68.3%; Average loss: 2.8529\n",
            "Returned Loss: 2.765301381111329\n",
            "Done One Timestep\n",
            "Iteration: 2732; Percent complete: 68.3%; Average loss: 2.7653\n",
            "Returned Loss: 3.023358372005081\n",
            "Done One Timestep\n",
            "Iteration: 2733; Percent complete: 68.3%; Average loss: 3.0234\n",
            "Returned Loss: 2.9369553377172166\n",
            "Done One Timestep\n",
            "Iteration: 2734; Percent complete: 68.3%; Average loss: 2.9370\n",
            "Returned Loss: 2.963955154784335\n",
            "Done One Timestep\n",
            "Iteration: 2735; Percent complete: 68.4%; Average loss: 2.9640\n",
            "Returned Loss: 2.9929317064286427\n",
            "Done One Timestep\n",
            "Iteration: 2736; Percent complete: 68.4%; Average loss: 2.9929\n",
            "Returned Loss: 3.00025765552293\n",
            "Done One Timestep\n",
            "Iteration: 2737; Percent complete: 68.4%; Average loss: 3.0003\n",
            "Returned Loss: 2.9063525877542813\n",
            "Done One Timestep\n",
            "Iteration: 2738; Percent complete: 68.5%; Average loss: 2.9064\n",
            "Returned Loss: 3.096836666759306\n",
            "Done One Timestep\n",
            "Iteration: 2739; Percent complete: 68.5%; Average loss: 3.0968\n",
            "Returned Loss: 3.1057179504062797\n",
            "Done One Timestep\n",
            "Iteration: 2740; Percent complete: 68.5%; Average loss: 3.1057\n",
            "Returned Loss: 3.056782632070537\n",
            "Done One Timestep\n",
            "Iteration: 2741; Percent complete: 68.5%; Average loss: 3.0568\n",
            "Returned Loss: 2.9392928675993493\n",
            "Done One Timestep\n",
            "Iteration: 2742; Percent complete: 68.5%; Average loss: 2.9393\n",
            "Returned Loss: 3.066667494593368\n",
            "Done One Timestep\n",
            "Iteration: 2743; Percent complete: 68.6%; Average loss: 3.0667\n",
            "Returned Loss: 3.301006909593472\n",
            "Done One Timestep\n",
            "Iteration: 2744; Percent complete: 68.6%; Average loss: 3.3010\n",
            "Returned Loss: 3.180988222122755\n",
            "Done One Timestep\n",
            "Iteration: 2745; Percent complete: 68.6%; Average loss: 3.1810\n",
            "Returned Loss: 2.935638538245065\n",
            "Done One Timestep\n",
            "Iteration: 2746; Percent complete: 68.7%; Average loss: 2.9356\n",
            "Returned Loss: 3.171007028296323\n",
            "Done One Timestep\n",
            "Iteration: 2747; Percent complete: 68.7%; Average loss: 3.1710\n",
            "Returned Loss: 2.7680358097879987\n",
            "Done One Timestep\n",
            "Iteration: 2748; Percent complete: 68.7%; Average loss: 2.7680\n",
            "Returned Loss: 2.682954318930198\n",
            "Done One Timestep\n",
            "Iteration: 2749; Percent complete: 68.7%; Average loss: 2.6830\n",
            "Returned Loss: 2.843931394843744\n",
            "Done One Timestep\n",
            "Iteration: 2750; Percent complete: 68.8%; Average loss: 2.8439\n",
            "Returned Loss: 3.0721702498636856\n",
            "Done One Timestep\n",
            "Iteration: 2751; Percent complete: 68.8%; Average loss: 3.0722\n",
            "Returned Loss: 3.063180009995073\n",
            "Done One Timestep\n",
            "Iteration: 2752; Percent complete: 68.8%; Average loss: 3.0632\n",
            "Returned Loss: 3.116837909482607\n",
            "Done One Timestep\n",
            "Iteration: 2753; Percent complete: 68.8%; Average loss: 3.1168\n",
            "Returned Loss: 2.8476106653903845\n",
            "Done One Timestep\n",
            "Iteration: 2754; Percent complete: 68.8%; Average loss: 2.8476\n",
            "Returned Loss: 3.089505738171135\n",
            "Done One Timestep\n",
            "Iteration: 2755; Percent complete: 68.9%; Average loss: 3.0895\n",
            "Returned Loss: 2.773572918734403\n",
            "Done One Timestep\n",
            "Iteration: 2756; Percent complete: 68.9%; Average loss: 2.7736\n",
            "Returned Loss: 2.924746696805469\n",
            "Done One Timestep\n",
            "Iteration: 2757; Percent complete: 68.9%; Average loss: 2.9247\n",
            "Returned Loss: 2.8789857600473265\n",
            "Done One Timestep\n",
            "Iteration: 2758; Percent complete: 69.0%; Average loss: 2.8790\n",
            "Returned Loss: 2.8424056415574723\n",
            "Done One Timestep\n",
            "Iteration: 2759; Percent complete: 69.0%; Average loss: 2.8424\n",
            "Returned Loss: 2.9769645357860166\n",
            "Done One Timestep\n",
            "Iteration: 2760; Percent complete: 69.0%; Average loss: 2.9770\n",
            "Returned Loss: 2.5951005253509325\n",
            "Done One Timestep\n",
            "Iteration: 2761; Percent complete: 69.0%; Average loss: 2.5951\n",
            "Returned Loss: 3.04128201457769\n",
            "Done One Timestep\n",
            "Iteration: 2762; Percent complete: 69.0%; Average loss: 3.0413\n",
            "Returned Loss: 2.8320290530124783\n",
            "Done One Timestep\n",
            "Iteration: 2763; Percent complete: 69.1%; Average loss: 2.8320\n",
            "Returned Loss: 2.710833719958801\n",
            "Done One Timestep\n",
            "Iteration: 2764; Percent complete: 69.1%; Average loss: 2.7108\n",
            "Returned Loss: 2.806538533404704\n",
            "Done One Timestep\n",
            "Iteration: 2765; Percent complete: 69.1%; Average loss: 2.8065\n",
            "Returned Loss: 2.796794935261331\n",
            "Done One Timestep\n",
            "Iteration: 2766; Percent complete: 69.2%; Average loss: 2.7968\n",
            "Returned Loss: 2.766318538702989\n",
            "Done One Timestep\n",
            "Iteration: 2767; Percent complete: 69.2%; Average loss: 2.7663\n",
            "Returned Loss: 2.7978164541004578\n",
            "Done One Timestep\n",
            "Iteration: 2768; Percent complete: 69.2%; Average loss: 2.7978\n",
            "Returned Loss: 2.947220713044157\n",
            "Done One Timestep\n",
            "Iteration: 2769; Percent complete: 69.2%; Average loss: 2.9472\n",
            "Returned Loss: 2.9464989791177016\n",
            "Done One Timestep\n",
            "Iteration: 2770; Percent complete: 69.2%; Average loss: 2.9465\n",
            "Returned Loss: 2.962592377693732\n",
            "Done One Timestep\n",
            "Iteration: 2771; Percent complete: 69.3%; Average loss: 2.9626\n",
            "Returned Loss: 3.2636897908118754\n",
            "Done One Timestep\n",
            "Iteration: 2772; Percent complete: 69.3%; Average loss: 3.2637\n",
            "Returned Loss: 3.1062520254546633\n",
            "Done One Timestep\n",
            "Iteration: 2773; Percent complete: 69.3%; Average loss: 3.1063\n",
            "Returned Loss: 2.8567864843762347\n",
            "Done One Timestep\n",
            "Iteration: 2774; Percent complete: 69.3%; Average loss: 2.8568\n",
            "Returned Loss: 2.8985147069162474\n",
            "Done One Timestep\n",
            "Iteration: 2775; Percent complete: 69.4%; Average loss: 2.8985\n",
            "Returned Loss: 2.894366720349725\n",
            "Done One Timestep\n",
            "Iteration: 2776; Percent complete: 69.4%; Average loss: 2.8944\n",
            "Returned Loss: 2.947470210774694\n",
            "Done One Timestep\n",
            "Iteration: 2777; Percent complete: 69.4%; Average loss: 2.9475\n",
            "Returned Loss: 3.0787663901642928\n",
            "Done One Timestep\n",
            "Iteration: 2778; Percent complete: 69.5%; Average loss: 3.0788\n",
            "Returned Loss: 2.83593583184549\n",
            "Done One Timestep\n",
            "Iteration: 2779; Percent complete: 69.5%; Average loss: 2.8359\n",
            "Returned Loss: 3.07126405430789\n",
            "Done One Timestep\n",
            "Iteration: 2780; Percent complete: 69.5%; Average loss: 3.0713\n",
            "Returned Loss: 2.880961997394211\n",
            "Done One Timestep\n",
            "Iteration: 2781; Percent complete: 69.5%; Average loss: 2.8810\n",
            "Returned Loss: 2.88788906646079\n",
            "Done One Timestep\n",
            "Iteration: 2782; Percent complete: 69.5%; Average loss: 2.8879\n",
            "Returned Loss: 2.847798653528455\n",
            "Done One Timestep\n",
            "Iteration: 2783; Percent complete: 69.6%; Average loss: 2.8478\n",
            "Returned Loss: 2.9957545795627256\n",
            "Done One Timestep\n",
            "Iteration: 2784; Percent complete: 69.6%; Average loss: 2.9958\n",
            "Returned Loss: 2.760096062813442\n",
            "Done One Timestep\n",
            "Iteration: 2785; Percent complete: 69.6%; Average loss: 2.7601\n",
            "Returned Loss: 2.8762323129971556\n",
            "Done One Timestep\n",
            "Iteration: 2786; Percent complete: 69.7%; Average loss: 2.8762\n",
            "Returned Loss: 2.89178493835333\n",
            "Done One Timestep\n",
            "Iteration: 2787; Percent complete: 69.7%; Average loss: 2.8918\n",
            "Returned Loss: 2.8196968438513217\n",
            "Done One Timestep\n",
            "Iteration: 2788; Percent complete: 69.7%; Average loss: 2.8197\n",
            "Returned Loss: 2.806689430679467\n",
            "Done One Timestep\n",
            "Iteration: 2789; Percent complete: 69.7%; Average loss: 2.8067\n",
            "Returned Loss: 3.0203899482472076\n",
            "Done One Timestep\n",
            "Iteration: 2790; Percent complete: 69.8%; Average loss: 3.0204\n",
            "Returned Loss: 3.0557462737268697\n",
            "Done One Timestep\n",
            "Iteration: 2791; Percent complete: 69.8%; Average loss: 3.0557\n",
            "Returned Loss: 2.8791856305514347\n",
            "Done One Timestep\n",
            "Iteration: 2792; Percent complete: 69.8%; Average loss: 2.8792\n",
            "Returned Loss: 2.871646041004711\n",
            "Done One Timestep\n",
            "Iteration: 2793; Percent complete: 69.8%; Average loss: 2.8716\n",
            "Returned Loss: 3.124297462039909\n",
            "Done One Timestep\n",
            "Iteration: 2794; Percent complete: 69.8%; Average loss: 3.1243\n",
            "Returned Loss: 2.9238990833283127\n",
            "Done One Timestep\n",
            "Iteration: 2795; Percent complete: 69.9%; Average loss: 2.9239\n",
            "Returned Loss: 2.9676485584147967\n",
            "Done One Timestep\n",
            "Iteration: 2796; Percent complete: 69.9%; Average loss: 2.9676\n",
            "Returned Loss: 2.86025935170355\n",
            "Done One Timestep\n",
            "Iteration: 2797; Percent complete: 69.9%; Average loss: 2.8603\n",
            "Returned Loss: 2.8968593158113536\n",
            "Done One Timestep\n",
            "Iteration: 2798; Percent complete: 70.0%; Average loss: 2.8969\n",
            "Returned Loss: 2.962565152143039\n",
            "Done One Timestep\n",
            "Iteration: 2799; Percent complete: 70.0%; Average loss: 2.9626\n",
            "Returned Loss: 3.063059569183679\n",
            "Done One Timestep\n",
            "Iteration: 2800; Percent complete: 70.0%; Average loss: 3.0631\n",
            "Returned Loss: 2.973702826727462\n",
            "Done One Timestep\n",
            "Iteration: 2801; Percent complete: 70.0%; Average loss: 2.9737\n",
            "Returned Loss: 2.86564641214047\n",
            "Done One Timestep\n",
            "Iteration: 2802; Percent complete: 70.0%; Average loss: 2.8656\n",
            "Returned Loss: 2.936113920753459\n",
            "Done One Timestep\n",
            "Iteration: 2803; Percent complete: 70.1%; Average loss: 2.9361\n",
            "Returned Loss: 2.9125087701896955\n",
            "Done One Timestep\n",
            "Iteration: 2804; Percent complete: 70.1%; Average loss: 2.9125\n",
            "Returned Loss: 3.005633000992101\n",
            "Done One Timestep\n",
            "Iteration: 2805; Percent complete: 70.1%; Average loss: 3.0056\n",
            "Returned Loss: 2.910957047692589\n",
            "Done One Timestep\n",
            "Iteration: 2806; Percent complete: 70.2%; Average loss: 2.9110\n",
            "Returned Loss: 2.90710065747024\n",
            "Done One Timestep\n",
            "Iteration: 2807; Percent complete: 70.2%; Average loss: 2.9071\n",
            "Returned Loss: 2.7204417540397072\n",
            "Done One Timestep\n",
            "Iteration: 2808; Percent complete: 70.2%; Average loss: 2.7204\n",
            "Returned Loss: 3.0665196695626564\n",
            "Done One Timestep\n",
            "Iteration: 2809; Percent complete: 70.2%; Average loss: 3.0665\n",
            "Returned Loss: 3.065458169714971\n",
            "Done One Timestep\n",
            "Iteration: 2810; Percent complete: 70.2%; Average loss: 3.0655\n",
            "Returned Loss: 2.89197914343846\n",
            "Done One Timestep\n",
            "Iteration: 2811; Percent complete: 70.3%; Average loss: 2.8920\n",
            "Returned Loss: 2.8745276777332194\n",
            "Done One Timestep\n",
            "Iteration: 2812; Percent complete: 70.3%; Average loss: 2.8745\n",
            "Returned Loss: 2.9242812882238716\n",
            "Done One Timestep\n",
            "Iteration: 2813; Percent complete: 70.3%; Average loss: 2.9243\n",
            "Returned Loss: 3.110623193279916\n",
            "Done One Timestep\n",
            "Iteration: 2814; Percent complete: 70.3%; Average loss: 3.1106\n",
            "Returned Loss: 3.0379440385679204\n",
            "Done One Timestep\n",
            "Iteration: 2815; Percent complete: 70.4%; Average loss: 3.0379\n",
            "Returned Loss: 2.865512825221564\n",
            "Done One Timestep\n",
            "Iteration: 2816; Percent complete: 70.4%; Average loss: 2.8655\n",
            "Returned Loss: 2.8059872508935984\n",
            "Done One Timestep\n",
            "Iteration: 2817; Percent complete: 70.4%; Average loss: 2.8060\n",
            "Returned Loss: 3.102500736282701\n",
            "Done One Timestep\n",
            "Iteration: 2818; Percent complete: 70.5%; Average loss: 3.1025\n",
            "Returned Loss: 2.8340446044603227\n",
            "Done One Timestep\n",
            "Iteration: 2819; Percent complete: 70.5%; Average loss: 2.8340\n",
            "Returned Loss: 2.980289118604485\n",
            "Done One Timestep\n",
            "Iteration: 2820; Percent complete: 70.5%; Average loss: 2.9803\n",
            "Returned Loss: 3.095113013494357\n",
            "Done One Timestep\n",
            "Iteration: 2821; Percent complete: 70.5%; Average loss: 3.0951\n",
            "Returned Loss: 2.9496927272589146\n",
            "Done One Timestep\n",
            "Iteration: 2822; Percent complete: 70.5%; Average loss: 2.9497\n",
            "Returned Loss: 3.0043355413674933\n",
            "Done One Timestep\n",
            "Iteration: 2823; Percent complete: 70.6%; Average loss: 3.0043\n",
            "Returned Loss: 3.15613133518898\n",
            "Done One Timestep\n",
            "Iteration: 2824; Percent complete: 70.6%; Average loss: 3.1561\n",
            "Returned Loss: 3.0092591700207407\n",
            "Done One Timestep\n",
            "Iteration: 2825; Percent complete: 70.6%; Average loss: 3.0093\n",
            "Returned Loss: 3.108472925349127\n",
            "Done One Timestep\n",
            "Iteration: 2826; Percent complete: 70.7%; Average loss: 3.1085\n",
            "Returned Loss: 2.894207352282901\n",
            "Done One Timestep\n",
            "Iteration: 2827; Percent complete: 70.7%; Average loss: 2.8942\n",
            "Returned Loss: 2.9310465736260403\n",
            "Done One Timestep\n",
            "Iteration: 2828; Percent complete: 70.7%; Average loss: 2.9310\n",
            "Returned Loss: 2.9578217180849906\n",
            "Done One Timestep\n",
            "Iteration: 2829; Percent complete: 70.7%; Average loss: 2.9578\n",
            "Returned Loss: 2.782883157026989\n",
            "Done One Timestep\n",
            "Iteration: 2830; Percent complete: 70.8%; Average loss: 2.7829\n",
            "Returned Loss: 2.656834773067385\n",
            "Done One Timestep\n",
            "Iteration: 2831; Percent complete: 70.8%; Average loss: 2.6568\n",
            "Returned Loss: 3.034854217661613\n",
            "Done One Timestep\n",
            "Iteration: 2832; Percent complete: 70.8%; Average loss: 3.0349\n",
            "Returned Loss: 2.8729293683505617\n",
            "Done One Timestep\n",
            "Iteration: 2833; Percent complete: 70.8%; Average loss: 2.8729\n",
            "Returned Loss: 3.056397526952866\n",
            "Done One Timestep\n",
            "Iteration: 2834; Percent complete: 70.9%; Average loss: 3.0564\n",
            "Returned Loss: 3.1039342402795795\n",
            "Done One Timestep\n",
            "Iteration: 2835; Percent complete: 70.9%; Average loss: 3.1039\n",
            "Returned Loss: 3.0202598239537646\n",
            "Done One Timestep\n",
            "Iteration: 2836; Percent complete: 70.9%; Average loss: 3.0203\n",
            "Returned Loss: 2.927502176893917\n",
            "Done One Timestep\n",
            "Iteration: 2837; Percent complete: 70.9%; Average loss: 2.9275\n",
            "Returned Loss: 2.923878258784393\n",
            "Done One Timestep\n",
            "Iteration: 2838; Percent complete: 71.0%; Average loss: 2.9239\n",
            "Returned Loss: 2.838505071492638\n",
            "Done One Timestep\n",
            "Iteration: 2839; Percent complete: 71.0%; Average loss: 2.8385\n",
            "Returned Loss: 2.815933918765848\n",
            "Done One Timestep\n",
            "Iteration: 2840; Percent complete: 71.0%; Average loss: 2.8159\n",
            "Returned Loss: 2.809347696927966\n",
            "Done One Timestep\n",
            "Iteration: 2841; Percent complete: 71.0%; Average loss: 2.8093\n",
            "Returned Loss: 2.8912839979776557\n",
            "Done One Timestep\n",
            "Iteration: 2842; Percent complete: 71.0%; Average loss: 2.8913\n",
            "Returned Loss: 2.9234548963117177\n",
            "Done One Timestep\n",
            "Iteration: 2843; Percent complete: 71.1%; Average loss: 2.9235\n",
            "Returned Loss: 2.848668137113771\n",
            "Done One Timestep\n",
            "Iteration: 2844; Percent complete: 71.1%; Average loss: 2.8487\n",
            "Returned Loss: 3.0046969690529055\n",
            "Done One Timestep\n",
            "Iteration: 2845; Percent complete: 71.1%; Average loss: 3.0047\n",
            "Returned Loss: 2.7910118445999976\n",
            "Done One Timestep\n",
            "Iteration: 2846; Percent complete: 71.2%; Average loss: 2.7910\n",
            "Returned Loss: 2.8400237203248975\n",
            "Done One Timestep\n",
            "Iteration: 2847; Percent complete: 71.2%; Average loss: 2.8400\n",
            "Returned Loss: 2.943014970433267\n",
            "Done One Timestep\n",
            "Iteration: 2848; Percent complete: 71.2%; Average loss: 2.9430\n",
            "Returned Loss: 3.082958275258133\n",
            "Done One Timestep\n",
            "Iteration: 2849; Percent complete: 71.2%; Average loss: 3.0830\n",
            "Returned Loss: 2.8655406720992946\n",
            "Done One Timestep\n",
            "Iteration: 2850; Percent complete: 71.2%; Average loss: 2.8655\n",
            "Returned Loss: 3.108667315432775\n",
            "Done One Timestep\n",
            "Iteration: 2851; Percent complete: 71.3%; Average loss: 3.1087\n",
            "Returned Loss: 2.7317867396729474\n",
            "Done One Timestep\n",
            "Iteration: 2852; Percent complete: 71.3%; Average loss: 2.7318\n",
            "Returned Loss: 3.136907310657511\n",
            "Done One Timestep\n",
            "Iteration: 2853; Percent complete: 71.3%; Average loss: 3.1369\n",
            "Returned Loss: 2.9804810604484624\n",
            "Done One Timestep\n",
            "Iteration: 2854; Percent complete: 71.4%; Average loss: 2.9805\n",
            "Returned Loss: 3.1024231525645605\n",
            "Done One Timestep\n",
            "Iteration: 2855; Percent complete: 71.4%; Average loss: 3.1024\n",
            "Returned Loss: 3.2075531066840757\n",
            "Done One Timestep\n",
            "Iteration: 2856; Percent complete: 71.4%; Average loss: 3.2076\n",
            "Returned Loss: 2.8339230538898703\n",
            "Done One Timestep\n",
            "Iteration: 2857; Percent complete: 71.4%; Average loss: 2.8339\n",
            "Returned Loss: 2.9066717244916327\n",
            "Done One Timestep\n",
            "Iteration: 2858; Percent complete: 71.5%; Average loss: 2.9067\n",
            "Returned Loss: 2.7382448768095546\n",
            "Done One Timestep\n",
            "Iteration: 2859; Percent complete: 71.5%; Average loss: 2.7382\n",
            "Returned Loss: 2.748239167715296\n",
            "Done One Timestep\n",
            "Iteration: 2860; Percent complete: 71.5%; Average loss: 2.7482\n",
            "Returned Loss: 2.7661932333283836\n",
            "Done One Timestep\n",
            "Iteration: 2861; Percent complete: 71.5%; Average loss: 2.7662\n",
            "Returned Loss: 2.7800222684457463\n",
            "Done One Timestep\n",
            "Iteration: 2862; Percent complete: 71.5%; Average loss: 2.7800\n",
            "Returned Loss: 3.051894161386232\n",
            "Done One Timestep\n",
            "Iteration: 2863; Percent complete: 71.6%; Average loss: 3.0519\n",
            "Returned Loss: 2.9587148313378147\n",
            "Done One Timestep\n",
            "Iteration: 2864; Percent complete: 71.6%; Average loss: 2.9587\n",
            "Returned Loss: 2.8060659402647494\n",
            "Done One Timestep\n",
            "Iteration: 2865; Percent complete: 71.6%; Average loss: 2.8061\n",
            "Returned Loss: 2.8510361324437485\n",
            "Done One Timestep\n",
            "Iteration: 2866; Percent complete: 71.7%; Average loss: 2.8510\n",
            "Returned Loss: 2.7989760271726696\n",
            "Done One Timestep\n",
            "Iteration: 2867; Percent complete: 71.7%; Average loss: 2.7990\n",
            "Returned Loss: 3.1076051007003396\n",
            "Done One Timestep\n",
            "Iteration: 2868; Percent complete: 71.7%; Average loss: 3.1076\n",
            "Returned Loss: 3.0505374628594337\n",
            "Done One Timestep\n",
            "Iteration: 2869; Percent complete: 71.7%; Average loss: 3.0505\n",
            "Returned Loss: 3.2912027115316747\n",
            "Done One Timestep\n",
            "Iteration: 2870; Percent complete: 71.8%; Average loss: 3.2912\n",
            "Returned Loss: 2.7579086633356678\n",
            "Done One Timestep\n",
            "Iteration: 2871; Percent complete: 71.8%; Average loss: 2.7579\n",
            "Returned Loss: 2.921945421789921\n",
            "Done One Timestep\n",
            "Iteration: 2872; Percent complete: 71.8%; Average loss: 2.9219\n",
            "Returned Loss: 2.648209735397727\n",
            "Done One Timestep\n",
            "Iteration: 2873; Percent complete: 71.8%; Average loss: 2.6482\n",
            "Returned Loss: 2.4781694060292065\n",
            "Done One Timestep\n",
            "Iteration: 2874; Percent complete: 71.9%; Average loss: 2.4782\n",
            "Returned Loss: 3.0304965992521566\n",
            "Done One Timestep\n",
            "Iteration: 2875; Percent complete: 71.9%; Average loss: 3.0305\n",
            "Returned Loss: 2.9194622022241723\n",
            "Done One Timestep\n",
            "Iteration: 2876; Percent complete: 71.9%; Average loss: 2.9195\n",
            "Returned Loss: 2.933325364374652\n",
            "Done One Timestep\n",
            "Iteration: 2877; Percent complete: 71.9%; Average loss: 2.9333\n",
            "Returned Loss: 3.0851996618497206\n",
            "Done One Timestep\n",
            "Iteration: 2878; Percent complete: 72.0%; Average loss: 3.0852\n",
            "Returned Loss: 3.0023463204438765\n",
            "Done One Timestep\n",
            "Iteration: 2879; Percent complete: 72.0%; Average loss: 3.0023\n",
            "Returned Loss: 3.064216145326065\n",
            "Done One Timestep\n",
            "Iteration: 2880; Percent complete: 72.0%; Average loss: 3.0642\n",
            "Returned Loss: 2.8131853355098473\n",
            "Done One Timestep\n",
            "Iteration: 2881; Percent complete: 72.0%; Average loss: 2.8132\n",
            "Returned Loss: 2.8009598842693904\n",
            "Done One Timestep\n",
            "Iteration: 2882; Percent complete: 72.0%; Average loss: 2.8010\n",
            "Returned Loss: 3.1202804711283\n",
            "Done One Timestep\n",
            "Iteration: 2883; Percent complete: 72.1%; Average loss: 3.1203\n",
            "Returned Loss: 2.7684349680126137\n",
            "Done One Timestep\n",
            "Iteration: 2884; Percent complete: 72.1%; Average loss: 2.7684\n",
            "Returned Loss: 2.961092007584201\n",
            "Done One Timestep\n",
            "Iteration: 2885; Percent complete: 72.1%; Average loss: 2.9611\n",
            "Returned Loss: 2.8160595347733346\n",
            "Done One Timestep\n",
            "Iteration: 2886; Percent complete: 72.2%; Average loss: 2.8161\n",
            "Returned Loss: 2.6651037274049476\n",
            "Done One Timestep\n",
            "Iteration: 2887; Percent complete: 72.2%; Average loss: 2.6651\n",
            "Returned Loss: 2.7771802407576796\n",
            "Done One Timestep\n",
            "Iteration: 2888; Percent complete: 72.2%; Average loss: 2.7772\n",
            "Returned Loss: 2.803457829741576\n",
            "Done One Timestep\n",
            "Iteration: 2889; Percent complete: 72.2%; Average loss: 2.8035\n",
            "Returned Loss: 2.9465912386730033\n",
            "Done One Timestep\n",
            "Iteration: 2890; Percent complete: 72.2%; Average loss: 2.9466\n",
            "Returned Loss: 3.0189869432211833\n",
            "Done One Timestep\n",
            "Iteration: 2891; Percent complete: 72.3%; Average loss: 3.0190\n",
            "Returned Loss: 3.075755740556735\n",
            "Done One Timestep\n",
            "Iteration: 2892; Percent complete: 72.3%; Average loss: 3.0758\n",
            "Returned Loss: 2.7749120954321183\n",
            "Done One Timestep\n",
            "Iteration: 2893; Percent complete: 72.3%; Average loss: 2.7749\n",
            "Returned Loss: 3.051128808808013\n",
            "Done One Timestep\n",
            "Iteration: 2894; Percent complete: 72.4%; Average loss: 3.0511\n",
            "Returned Loss: 2.980349792049713\n",
            "Done One Timestep\n",
            "Iteration: 2895; Percent complete: 72.4%; Average loss: 2.9803\n",
            "Returned Loss: 2.746414026647222\n",
            "Done One Timestep\n",
            "Iteration: 2896; Percent complete: 72.4%; Average loss: 2.7464\n",
            "Returned Loss: 2.745036440456466\n",
            "Done One Timestep\n",
            "Iteration: 2897; Percent complete: 72.4%; Average loss: 2.7450\n",
            "Returned Loss: 2.9670163022449882\n",
            "Done One Timestep\n",
            "Iteration: 2898; Percent complete: 72.5%; Average loss: 2.9670\n",
            "Returned Loss: 2.875535407439022\n",
            "Done One Timestep\n",
            "Iteration: 2899; Percent complete: 72.5%; Average loss: 2.8755\n",
            "Returned Loss: 2.866407246172538\n",
            "Done One Timestep\n",
            "Iteration: 2900; Percent complete: 72.5%; Average loss: 2.8664\n",
            "Returned Loss: 2.8721899427839666\n",
            "Done One Timestep\n",
            "Iteration: 2901; Percent complete: 72.5%; Average loss: 2.8722\n",
            "Returned Loss: 3.047520122437278\n",
            "Done One Timestep\n",
            "Iteration: 2902; Percent complete: 72.5%; Average loss: 3.0475\n",
            "Returned Loss: 2.6090336918410957\n",
            "Done One Timestep\n",
            "Iteration: 2903; Percent complete: 72.6%; Average loss: 2.6090\n",
            "Returned Loss: 3.045788584946422\n",
            "Done One Timestep\n",
            "Iteration: 2904; Percent complete: 72.6%; Average loss: 3.0458\n",
            "Returned Loss: 3.1797993294843336\n",
            "Done One Timestep\n",
            "Iteration: 2905; Percent complete: 72.6%; Average loss: 3.1798\n",
            "Returned Loss: 2.5406927024464148\n",
            "Done One Timestep\n",
            "Iteration: 2906; Percent complete: 72.7%; Average loss: 2.5407\n",
            "Returned Loss: 2.8028946333372455\n",
            "Done One Timestep\n",
            "Iteration: 2907; Percent complete: 72.7%; Average loss: 2.8029\n",
            "Returned Loss: 2.8547722819674357\n",
            "Done One Timestep\n",
            "Iteration: 2908; Percent complete: 72.7%; Average loss: 2.8548\n",
            "Returned Loss: 2.90423903947353\n",
            "Done One Timestep\n",
            "Iteration: 2909; Percent complete: 72.7%; Average loss: 2.9042\n",
            "Returned Loss: 2.721766218078009\n",
            "Done One Timestep\n",
            "Iteration: 2910; Percent complete: 72.8%; Average loss: 2.7218\n",
            "Returned Loss: 2.9683269093527676\n",
            "Done One Timestep\n",
            "Iteration: 2911; Percent complete: 72.8%; Average loss: 2.9683\n",
            "Returned Loss: 3.098020938560692\n",
            "Done One Timestep\n",
            "Iteration: 2912; Percent complete: 72.8%; Average loss: 3.0980\n",
            "Returned Loss: 3.1849711470582616\n",
            "Done One Timestep\n",
            "Iteration: 2913; Percent complete: 72.8%; Average loss: 3.1850\n",
            "Returned Loss: 2.7957304399670218\n",
            "Done One Timestep\n",
            "Iteration: 2914; Percent complete: 72.9%; Average loss: 2.7957\n",
            "Returned Loss: 2.9680240541940903\n",
            "Done One Timestep\n",
            "Iteration: 2915; Percent complete: 72.9%; Average loss: 2.9680\n",
            "Returned Loss: 2.7531729710914976\n",
            "Done One Timestep\n",
            "Iteration: 2916; Percent complete: 72.9%; Average loss: 2.7532\n",
            "Returned Loss: 3.1000520563790506\n",
            "Done One Timestep\n",
            "Iteration: 2917; Percent complete: 72.9%; Average loss: 3.1001\n",
            "Returned Loss: 2.9006584254875234\n",
            "Done One Timestep\n",
            "Iteration: 2918; Percent complete: 73.0%; Average loss: 2.9007\n",
            "Returned Loss: 3.012548523680862\n",
            "Done One Timestep\n",
            "Iteration: 2919; Percent complete: 73.0%; Average loss: 3.0125\n",
            "Returned Loss: 2.668104260647326\n",
            "Done One Timestep\n",
            "Iteration: 2920; Percent complete: 73.0%; Average loss: 2.6681\n",
            "Returned Loss: 2.834023962771318\n",
            "Done One Timestep\n",
            "Iteration: 2921; Percent complete: 73.0%; Average loss: 2.8340\n",
            "Returned Loss: 2.8530871932559028\n",
            "Done One Timestep\n",
            "Iteration: 2922; Percent complete: 73.0%; Average loss: 2.8531\n",
            "Returned Loss: 2.791754604060331\n",
            "Done One Timestep\n",
            "Iteration: 2923; Percent complete: 73.1%; Average loss: 2.7918\n",
            "Returned Loss: 3.0037038015801065\n",
            "Done One Timestep\n",
            "Iteration: 2924; Percent complete: 73.1%; Average loss: 3.0037\n",
            "Returned Loss: 3.0390008423911787\n",
            "Done One Timestep\n",
            "Iteration: 2925; Percent complete: 73.1%; Average loss: 3.0390\n",
            "Returned Loss: 2.8788967006972856\n",
            "Done One Timestep\n",
            "Iteration: 2926; Percent complete: 73.2%; Average loss: 2.8789\n",
            "Returned Loss: 2.8629090502944736\n",
            "Done One Timestep\n",
            "Iteration: 2927; Percent complete: 73.2%; Average loss: 2.8629\n",
            "Returned Loss: 2.8093174639992506\n",
            "Done One Timestep\n",
            "Iteration: 2928; Percent complete: 73.2%; Average loss: 2.8093\n",
            "Returned Loss: 2.619465492026576\n",
            "Done One Timestep\n",
            "Iteration: 2929; Percent complete: 73.2%; Average loss: 2.6195\n",
            "Returned Loss: 2.999264507120164\n",
            "Done One Timestep\n",
            "Iteration: 2930; Percent complete: 73.2%; Average loss: 2.9993\n",
            "Returned Loss: 2.9889889475868046\n",
            "Done One Timestep\n",
            "Iteration: 2931; Percent complete: 73.3%; Average loss: 2.9890\n",
            "Returned Loss: 2.8252640544348147\n",
            "Done One Timestep\n",
            "Iteration: 2932; Percent complete: 73.3%; Average loss: 2.8253\n",
            "Returned Loss: 2.8909659711226308\n",
            "Done One Timestep\n",
            "Iteration: 2933; Percent complete: 73.3%; Average loss: 2.8910\n",
            "Returned Loss: 2.9848189194838106\n",
            "Done One Timestep\n",
            "Iteration: 2934; Percent complete: 73.4%; Average loss: 2.9848\n",
            "Returned Loss: 2.8813941597233628\n",
            "Done One Timestep\n",
            "Iteration: 2935; Percent complete: 73.4%; Average loss: 2.8814\n",
            "Returned Loss: 2.9435514697176735\n",
            "Done One Timestep\n",
            "Iteration: 2936; Percent complete: 73.4%; Average loss: 2.9436\n",
            "Returned Loss: 2.9477272602240556\n",
            "Done One Timestep\n",
            "Iteration: 2937; Percent complete: 73.4%; Average loss: 2.9477\n",
            "Returned Loss: 3.0734543752282812\n",
            "Done One Timestep\n",
            "Iteration: 2938; Percent complete: 73.5%; Average loss: 3.0735\n",
            "Returned Loss: 3.0885441907719797\n",
            "Done One Timestep\n",
            "Iteration: 2939; Percent complete: 73.5%; Average loss: 3.0885\n",
            "Returned Loss: 2.8065319124107377\n",
            "Done One Timestep\n",
            "Iteration: 2940; Percent complete: 73.5%; Average loss: 2.8065\n",
            "Returned Loss: 3.0952024144909784\n",
            "Done One Timestep\n",
            "Iteration: 2941; Percent complete: 73.5%; Average loss: 3.0952\n",
            "Returned Loss: 2.7126401840788565\n",
            "Done One Timestep\n",
            "Iteration: 2942; Percent complete: 73.6%; Average loss: 2.7126\n",
            "Returned Loss: 3.1735812039519993\n",
            "Done One Timestep\n",
            "Iteration: 2943; Percent complete: 73.6%; Average loss: 3.1736\n",
            "Returned Loss: 3.0656107290578074\n",
            "Done One Timestep\n",
            "Iteration: 2944; Percent complete: 73.6%; Average loss: 3.0656\n",
            "Returned Loss: 3.1159832894109014\n",
            "Done One Timestep\n",
            "Iteration: 2945; Percent complete: 73.6%; Average loss: 3.1160\n",
            "Returned Loss: 2.89926622324856\n",
            "Done One Timestep\n",
            "Iteration: 2946; Percent complete: 73.7%; Average loss: 2.8993\n",
            "Returned Loss: 2.793171080625951\n",
            "Done One Timestep\n",
            "Iteration: 2947; Percent complete: 73.7%; Average loss: 2.7932\n",
            "Returned Loss: 2.707422594167292\n",
            "Done One Timestep\n",
            "Iteration: 2948; Percent complete: 73.7%; Average loss: 2.7074\n",
            "Returned Loss: 2.753430286633488\n",
            "Done One Timestep\n",
            "Iteration: 2949; Percent complete: 73.7%; Average loss: 2.7534\n",
            "Returned Loss: 2.898465613557917\n",
            "Done One Timestep\n",
            "Iteration: 2950; Percent complete: 73.8%; Average loss: 2.8985\n",
            "Returned Loss: 2.778070262693723\n",
            "Done One Timestep\n",
            "Iteration: 2951; Percent complete: 73.8%; Average loss: 2.7781\n",
            "Returned Loss: 2.9099079184083525\n",
            "Done One Timestep\n",
            "Iteration: 2952; Percent complete: 73.8%; Average loss: 2.9099\n",
            "Returned Loss: 2.739806948063786\n",
            "Done One Timestep\n",
            "Iteration: 2953; Percent complete: 73.8%; Average loss: 2.7398\n",
            "Returned Loss: 2.7888806452809263\n",
            "Done One Timestep\n",
            "Iteration: 2954; Percent complete: 73.9%; Average loss: 2.7889\n",
            "Returned Loss: 2.86373705823264\n",
            "Done One Timestep\n",
            "Iteration: 2955; Percent complete: 73.9%; Average loss: 2.8637\n",
            "Returned Loss: 2.6152515509869994\n",
            "Done One Timestep\n",
            "Iteration: 2956; Percent complete: 73.9%; Average loss: 2.6153\n",
            "Returned Loss: 2.938472971269759\n",
            "Done One Timestep\n",
            "Iteration: 2957; Percent complete: 73.9%; Average loss: 2.9385\n",
            "Returned Loss: 2.9576974509229115\n",
            "Done One Timestep\n",
            "Iteration: 2958; Percent complete: 74.0%; Average loss: 2.9577\n",
            "Returned Loss: 2.9811159179715725\n",
            "Done One Timestep\n",
            "Iteration: 2959; Percent complete: 74.0%; Average loss: 2.9811\n",
            "Returned Loss: 2.47173723093158\n",
            "Done One Timestep\n",
            "Iteration: 2960; Percent complete: 74.0%; Average loss: 2.4717\n",
            "Returned Loss: 3.0112244531040644\n",
            "Done One Timestep\n",
            "Iteration: 2961; Percent complete: 74.0%; Average loss: 3.0112\n",
            "Returned Loss: 2.8968848842183443\n",
            "Done One Timestep\n",
            "Iteration: 2962; Percent complete: 74.1%; Average loss: 2.8969\n",
            "Returned Loss: 3.0935604802095873\n",
            "Done One Timestep\n",
            "Iteration: 2963; Percent complete: 74.1%; Average loss: 3.0936\n",
            "Returned Loss: 2.890245893119703\n",
            "Done One Timestep\n",
            "Iteration: 2964; Percent complete: 74.1%; Average loss: 2.8902\n",
            "Returned Loss: 2.989371516445151\n",
            "Done One Timestep\n",
            "Iteration: 2965; Percent complete: 74.1%; Average loss: 2.9894\n",
            "Returned Loss: 2.8920329967146055\n",
            "Done One Timestep\n",
            "Iteration: 2966; Percent complete: 74.2%; Average loss: 2.8920\n",
            "Returned Loss: 2.9502260217015173\n",
            "Done One Timestep\n",
            "Iteration: 2967; Percent complete: 74.2%; Average loss: 2.9502\n",
            "Returned Loss: 2.840907197574089\n",
            "Done One Timestep\n",
            "Iteration: 2968; Percent complete: 74.2%; Average loss: 2.8409\n",
            "Returned Loss: 2.9466935279731983\n",
            "Done One Timestep\n",
            "Iteration: 2969; Percent complete: 74.2%; Average loss: 2.9467\n",
            "Returned Loss: 2.984480272176174\n",
            "Done One Timestep\n",
            "Iteration: 2970; Percent complete: 74.2%; Average loss: 2.9845\n",
            "Returned Loss: 3.074676309525967\n",
            "Done One Timestep\n",
            "Iteration: 2971; Percent complete: 74.3%; Average loss: 3.0747\n",
            "Returned Loss: 3.04575394608138\n",
            "Done One Timestep\n",
            "Iteration: 2972; Percent complete: 74.3%; Average loss: 3.0458\n",
            "Returned Loss: 2.8868784695301595\n",
            "Done One Timestep\n",
            "Iteration: 2973; Percent complete: 74.3%; Average loss: 2.8869\n",
            "Returned Loss: 2.845884018745598\n",
            "Done One Timestep\n",
            "Iteration: 2974; Percent complete: 74.4%; Average loss: 2.8459\n",
            "Returned Loss: 3.052465969183463\n",
            "Done One Timestep\n",
            "Iteration: 2975; Percent complete: 74.4%; Average loss: 3.0525\n",
            "Returned Loss: 3.1011831699803483\n",
            "Done One Timestep\n",
            "Iteration: 2976; Percent complete: 74.4%; Average loss: 3.1012\n",
            "Returned Loss: 3.002066923522624\n",
            "Done One Timestep\n",
            "Iteration: 2977; Percent complete: 74.4%; Average loss: 3.0021\n",
            "Returned Loss: 2.7410579829802066\n",
            "Done One Timestep\n",
            "Iteration: 2978; Percent complete: 74.5%; Average loss: 2.7411\n",
            "Returned Loss: 2.885974951875903\n",
            "Done One Timestep\n",
            "Iteration: 2979; Percent complete: 74.5%; Average loss: 2.8860\n",
            "Returned Loss: 3.062243361192356\n",
            "Done One Timestep\n",
            "Iteration: 2980; Percent complete: 74.5%; Average loss: 3.0622\n",
            "Returned Loss: 2.9275344949154456\n",
            "Done One Timestep\n",
            "Iteration: 2981; Percent complete: 74.5%; Average loss: 2.9275\n",
            "Returned Loss: 2.9653044097556576\n",
            "Done One Timestep\n",
            "Iteration: 2982; Percent complete: 74.6%; Average loss: 2.9653\n",
            "Returned Loss: 2.9474226434851882\n",
            "Done One Timestep\n",
            "Iteration: 2983; Percent complete: 74.6%; Average loss: 2.9474\n",
            "Returned Loss: 3.0028974234655097\n",
            "Done One Timestep\n",
            "Iteration: 2984; Percent complete: 74.6%; Average loss: 3.0029\n",
            "Returned Loss: 2.768222014371878\n",
            "Done One Timestep\n",
            "Iteration: 2985; Percent complete: 74.6%; Average loss: 2.7682\n",
            "Returned Loss: 2.929661900461827\n",
            "Done One Timestep\n",
            "Iteration: 2986; Percent complete: 74.7%; Average loss: 2.9297\n",
            "Returned Loss: 2.719742731361922\n",
            "Done One Timestep\n",
            "Iteration: 2987; Percent complete: 74.7%; Average loss: 2.7197\n",
            "Returned Loss: 3.0289215671113565\n",
            "Done One Timestep\n",
            "Iteration: 2988; Percent complete: 74.7%; Average loss: 3.0289\n",
            "Returned Loss: 2.8274766215787195\n",
            "Done One Timestep\n",
            "Iteration: 2989; Percent complete: 74.7%; Average loss: 2.8275\n",
            "Returned Loss: 2.9823556660348434\n",
            "Done One Timestep\n",
            "Iteration: 2990; Percent complete: 74.8%; Average loss: 2.9824\n",
            "Returned Loss: 2.90872373170975\n",
            "Done One Timestep\n",
            "Iteration: 2991; Percent complete: 74.8%; Average loss: 2.9087\n",
            "Returned Loss: 2.925500957267511\n",
            "Done One Timestep\n",
            "Iteration: 2992; Percent complete: 74.8%; Average loss: 2.9255\n",
            "Returned Loss: 2.751322148880799\n",
            "Done One Timestep\n",
            "Iteration: 2993; Percent complete: 74.8%; Average loss: 2.7513\n",
            "Returned Loss: 2.823859624344668\n",
            "Done One Timestep\n",
            "Iteration: 2994; Percent complete: 74.9%; Average loss: 2.8239\n",
            "Returned Loss: 2.8230101862936494\n",
            "Done One Timestep\n",
            "Iteration: 2995; Percent complete: 74.9%; Average loss: 2.8230\n",
            "Returned Loss: 2.8456934124537274\n",
            "Done One Timestep\n",
            "Iteration: 2996; Percent complete: 74.9%; Average loss: 2.8457\n",
            "Returned Loss: 2.7521517639143456\n",
            "Done One Timestep\n",
            "Iteration: 2997; Percent complete: 74.9%; Average loss: 2.7522\n",
            "Returned Loss: 2.898107743507959\n",
            "Done One Timestep\n",
            "Iteration: 2998; Percent complete: 75.0%; Average loss: 2.8981\n",
            "Returned Loss: 2.869208199309856\n",
            "Done One Timestep\n",
            "Iteration: 2999; Percent complete: 75.0%; Average loss: 2.8692\n",
            "Returned Loss: 2.7884180062352035\n",
            "Done One Timestep\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.7884\n",
            "Returned Loss: 2.8370891498895934\n",
            "Done One Timestep\n",
            "Iteration: 3001; Percent complete: 75.0%; Average loss: 2.8371\n",
            "Returned Loss: 2.751236106310226\n",
            "Done One Timestep\n",
            "Iteration: 3002; Percent complete: 75.0%; Average loss: 2.7512\n",
            "Returned Loss: 2.989431463241124\n",
            "Done One Timestep\n",
            "Iteration: 3003; Percent complete: 75.1%; Average loss: 2.9894\n",
            "Returned Loss: 2.977333067217289\n",
            "Done One Timestep\n",
            "Iteration: 3004; Percent complete: 75.1%; Average loss: 2.9773\n",
            "Returned Loss: 2.8312514994492077\n",
            "Done One Timestep\n",
            "Iteration: 3005; Percent complete: 75.1%; Average loss: 2.8313\n",
            "Returned Loss: 2.705595582480867\n",
            "Done One Timestep\n",
            "Iteration: 3006; Percent complete: 75.1%; Average loss: 2.7056\n",
            "Returned Loss: 3.0161460901269725\n",
            "Done One Timestep\n",
            "Iteration: 3007; Percent complete: 75.2%; Average loss: 3.0161\n",
            "Returned Loss: 2.8214525388329887\n",
            "Done One Timestep\n",
            "Iteration: 3008; Percent complete: 75.2%; Average loss: 2.8215\n",
            "Returned Loss: 2.855981767786996\n",
            "Done One Timestep\n",
            "Iteration: 3009; Percent complete: 75.2%; Average loss: 2.8560\n",
            "Returned Loss: 2.7646020459866714\n",
            "Done One Timestep\n",
            "Iteration: 3010; Percent complete: 75.2%; Average loss: 2.7646\n",
            "Returned Loss: 2.915465937362503\n",
            "Done One Timestep\n",
            "Iteration: 3011; Percent complete: 75.3%; Average loss: 2.9155\n",
            "Returned Loss: 2.78199970503761\n",
            "Done One Timestep\n",
            "Iteration: 3012; Percent complete: 75.3%; Average loss: 2.7820\n",
            "Returned Loss: 2.5211670316209656\n",
            "Done One Timestep\n",
            "Iteration: 3013; Percent complete: 75.3%; Average loss: 2.5212\n",
            "Returned Loss: 3.095275458399628\n",
            "Done One Timestep\n",
            "Iteration: 3014; Percent complete: 75.3%; Average loss: 3.0953\n",
            "Returned Loss: 2.9985961764588693\n",
            "Done One Timestep\n",
            "Iteration: 3015; Percent complete: 75.4%; Average loss: 2.9986\n",
            "Returned Loss: 2.994840172699255\n",
            "Done One Timestep\n",
            "Iteration: 3016; Percent complete: 75.4%; Average loss: 2.9948\n",
            "Returned Loss: 3.129803473265589\n",
            "Done One Timestep\n",
            "Iteration: 3017; Percent complete: 75.4%; Average loss: 3.1298\n",
            "Returned Loss: 2.774581169142828\n",
            "Done One Timestep\n",
            "Iteration: 3018; Percent complete: 75.4%; Average loss: 2.7746\n",
            "Returned Loss: 2.903960869222662\n",
            "Done One Timestep\n",
            "Iteration: 3019; Percent complete: 75.5%; Average loss: 2.9040\n",
            "Returned Loss: 2.7432290375508646\n",
            "Done One Timestep\n",
            "Iteration: 3020; Percent complete: 75.5%; Average loss: 2.7432\n",
            "Returned Loss: 2.660327787241857\n",
            "Done One Timestep\n",
            "Iteration: 3021; Percent complete: 75.5%; Average loss: 2.6603\n",
            "Returned Loss: 3.04731237299091\n",
            "Done One Timestep\n",
            "Iteration: 3022; Percent complete: 75.5%; Average loss: 3.0473\n",
            "Returned Loss: 2.834629685720754\n",
            "Done One Timestep\n",
            "Iteration: 3023; Percent complete: 75.6%; Average loss: 2.8346\n",
            "Returned Loss: 2.7265189591784367\n",
            "Done One Timestep\n",
            "Iteration: 3024; Percent complete: 75.6%; Average loss: 2.7265\n",
            "Returned Loss: 2.819937366206213\n",
            "Done One Timestep\n",
            "Iteration: 3025; Percent complete: 75.6%; Average loss: 2.8199\n",
            "Returned Loss: 2.8908809178101365\n",
            "Done One Timestep\n",
            "Iteration: 3026; Percent complete: 75.6%; Average loss: 2.8909\n",
            "Returned Loss: 2.6927773484932187\n",
            "Done One Timestep\n",
            "Iteration: 3027; Percent complete: 75.7%; Average loss: 2.6928\n",
            "Returned Loss: 2.6136024379583316\n",
            "Done One Timestep\n",
            "Iteration: 3028; Percent complete: 75.7%; Average loss: 2.6136\n",
            "Returned Loss: 2.8139806585229565\n",
            "Done One Timestep\n",
            "Iteration: 3029; Percent complete: 75.7%; Average loss: 2.8140\n",
            "Returned Loss: 3.0128675086526964\n",
            "Done One Timestep\n",
            "Iteration: 3030; Percent complete: 75.8%; Average loss: 3.0129\n",
            "Returned Loss: 2.6878541293271243\n",
            "Done One Timestep\n",
            "Iteration: 3031; Percent complete: 75.8%; Average loss: 2.6879\n",
            "Returned Loss: 2.999932077429479\n",
            "Done One Timestep\n",
            "Iteration: 3032; Percent complete: 75.8%; Average loss: 2.9999\n",
            "Returned Loss: 2.950641488617142\n",
            "Done One Timestep\n",
            "Iteration: 3033; Percent complete: 75.8%; Average loss: 2.9506\n",
            "Returned Loss: 2.83271845632423\n",
            "Done One Timestep\n",
            "Iteration: 3034; Percent complete: 75.8%; Average loss: 2.8327\n",
            "Returned Loss: 2.948731312471809\n",
            "Done One Timestep\n",
            "Iteration: 3035; Percent complete: 75.9%; Average loss: 2.9487\n",
            "Returned Loss: 2.7459970063181838\n",
            "Done One Timestep\n",
            "Iteration: 3036; Percent complete: 75.9%; Average loss: 2.7460\n",
            "Returned Loss: 2.847787570249655\n",
            "Done One Timestep\n",
            "Iteration: 3037; Percent complete: 75.9%; Average loss: 2.8478\n",
            "Returned Loss: 3.1725111195864493\n",
            "Done One Timestep\n",
            "Iteration: 3038; Percent complete: 75.9%; Average loss: 3.1725\n",
            "Returned Loss: 2.9175380372411768\n",
            "Done One Timestep\n",
            "Iteration: 3039; Percent complete: 76.0%; Average loss: 2.9175\n",
            "Returned Loss: 2.850306350398437\n",
            "Done One Timestep\n",
            "Iteration: 3040; Percent complete: 76.0%; Average loss: 2.8503\n",
            "Returned Loss: 2.8309695516889595\n",
            "Done One Timestep\n",
            "Iteration: 3041; Percent complete: 76.0%; Average loss: 2.8310\n",
            "Returned Loss: 3.067876125352296\n",
            "Done One Timestep\n",
            "Iteration: 3042; Percent complete: 76.0%; Average loss: 3.0679\n",
            "Returned Loss: 2.8404276813404548\n",
            "Done One Timestep\n",
            "Iteration: 3043; Percent complete: 76.1%; Average loss: 2.8404\n",
            "Returned Loss: 2.6789508011182757\n",
            "Done One Timestep\n",
            "Iteration: 3044; Percent complete: 76.1%; Average loss: 2.6790\n",
            "Returned Loss: 2.7387388769277057\n",
            "Done One Timestep\n",
            "Iteration: 3045; Percent complete: 76.1%; Average loss: 2.7387\n",
            "Returned Loss: 2.9852985756533026\n",
            "Done One Timestep\n",
            "Iteration: 3046; Percent complete: 76.1%; Average loss: 2.9853\n",
            "Returned Loss: 2.903885098246375\n",
            "Done One Timestep\n",
            "Iteration: 3047; Percent complete: 76.2%; Average loss: 2.9039\n",
            "Returned Loss: 2.929263953909051\n",
            "Done One Timestep\n",
            "Iteration: 3048; Percent complete: 76.2%; Average loss: 2.9293\n",
            "Returned Loss: 3.1274816703160733\n",
            "Done One Timestep\n",
            "Iteration: 3049; Percent complete: 76.2%; Average loss: 3.1275\n",
            "Returned Loss: 3.12854052377197\n",
            "Done One Timestep\n",
            "Iteration: 3050; Percent complete: 76.2%; Average loss: 3.1285\n",
            "Returned Loss: 2.8415925871154313\n",
            "Done One Timestep\n",
            "Iteration: 3051; Percent complete: 76.3%; Average loss: 2.8416\n",
            "Returned Loss: 2.6209795058951015\n",
            "Done One Timestep\n",
            "Iteration: 3052; Percent complete: 76.3%; Average loss: 2.6210\n",
            "Returned Loss: 3.0033647875950984\n",
            "Done One Timestep\n",
            "Iteration: 3053; Percent complete: 76.3%; Average loss: 3.0034\n",
            "Returned Loss: 2.741725982206113\n",
            "Done One Timestep\n",
            "Iteration: 3054; Percent complete: 76.3%; Average loss: 2.7417\n",
            "Returned Loss: 2.9344951851471115\n",
            "Done One Timestep\n",
            "Iteration: 3055; Percent complete: 76.4%; Average loss: 2.9345\n",
            "Returned Loss: 2.878989724273345\n",
            "Done One Timestep\n",
            "Iteration: 3056; Percent complete: 76.4%; Average loss: 2.8790\n",
            "Returned Loss: 2.9998735654847604\n",
            "Done One Timestep\n",
            "Iteration: 3057; Percent complete: 76.4%; Average loss: 2.9999\n",
            "Returned Loss: 2.6130503938567142\n",
            "Done One Timestep\n",
            "Iteration: 3058; Percent complete: 76.4%; Average loss: 2.6131\n",
            "Returned Loss: 2.825897839515269\n",
            "Done One Timestep\n",
            "Iteration: 3059; Percent complete: 76.5%; Average loss: 2.8259\n",
            "Returned Loss: 3.0277275331707414\n",
            "Done One Timestep\n",
            "Iteration: 3060; Percent complete: 76.5%; Average loss: 3.0277\n",
            "Returned Loss: 2.8499490881305873\n",
            "Done One Timestep\n",
            "Iteration: 3061; Percent complete: 76.5%; Average loss: 2.8499\n",
            "Returned Loss: 2.810744524950678\n",
            "Done One Timestep\n",
            "Iteration: 3062; Percent complete: 76.5%; Average loss: 2.8107\n",
            "Returned Loss: 2.7836368488587016\n",
            "Done One Timestep\n",
            "Iteration: 3063; Percent complete: 76.6%; Average loss: 2.7836\n",
            "Returned Loss: 2.629905383803689\n",
            "Done One Timestep\n",
            "Iteration: 3064; Percent complete: 76.6%; Average loss: 2.6299\n",
            "Returned Loss: 2.760943562828598\n",
            "Done One Timestep\n",
            "Iteration: 3065; Percent complete: 76.6%; Average loss: 2.7609\n",
            "Returned Loss: 2.908705019507896\n",
            "Done One Timestep\n",
            "Iteration: 3066; Percent complete: 76.6%; Average loss: 2.9087\n",
            "Returned Loss: 2.827334730874648\n",
            "Done One Timestep\n",
            "Iteration: 3067; Percent complete: 76.7%; Average loss: 2.8273\n",
            "Returned Loss: 3.0259883179322298\n",
            "Done One Timestep\n",
            "Iteration: 3068; Percent complete: 76.7%; Average loss: 3.0260\n",
            "Returned Loss: 2.780553656366423\n",
            "Done One Timestep\n",
            "Iteration: 3069; Percent complete: 76.7%; Average loss: 2.7806\n",
            "Returned Loss: 2.9236559925743646\n",
            "Done One Timestep\n",
            "Iteration: 3070; Percent complete: 76.8%; Average loss: 2.9237\n",
            "Returned Loss: 3.006401785791782\n",
            "Done One Timestep\n",
            "Iteration: 3071; Percent complete: 76.8%; Average loss: 3.0064\n",
            "Returned Loss: 2.693761658707381\n",
            "Done One Timestep\n",
            "Iteration: 3072; Percent complete: 76.8%; Average loss: 2.6938\n",
            "Returned Loss: 2.894413237975552\n",
            "Done One Timestep\n",
            "Iteration: 3073; Percent complete: 76.8%; Average loss: 2.8944\n",
            "Returned Loss: 2.896249531608035\n",
            "Done One Timestep\n",
            "Iteration: 3074; Percent complete: 76.8%; Average loss: 2.8962\n",
            "Returned Loss: 2.9396045112131555\n",
            "Done One Timestep\n",
            "Iteration: 3075; Percent complete: 76.9%; Average loss: 2.9396\n",
            "Returned Loss: 2.8620796293971384\n",
            "Done One Timestep\n",
            "Iteration: 3076; Percent complete: 76.9%; Average loss: 2.8621\n",
            "Returned Loss: 2.6092730814494973\n",
            "Done One Timestep\n",
            "Iteration: 3077; Percent complete: 76.9%; Average loss: 2.6093\n",
            "Returned Loss: 2.8477229597940665\n",
            "Done One Timestep\n",
            "Iteration: 3078; Percent complete: 77.0%; Average loss: 2.8477\n",
            "Returned Loss: 2.881108678154421\n",
            "Done One Timestep\n",
            "Iteration: 3079; Percent complete: 77.0%; Average loss: 2.8811\n",
            "Returned Loss: 2.736876529256406\n",
            "Done One Timestep\n",
            "Iteration: 3080; Percent complete: 77.0%; Average loss: 2.7369\n",
            "Returned Loss: 2.731005961301932\n",
            "Done One Timestep\n",
            "Iteration: 3081; Percent complete: 77.0%; Average loss: 2.7310\n",
            "Returned Loss: 3.1198530614795503\n",
            "Done One Timestep\n",
            "Iteration: 3082; Percent complete: 77.0%; Average loss: 3.1199\n",
            "Returned Loss: 2.8872574910349083\n",
            "Done One Timestep\n",
            "Iteration: 3083; Percent complete: 77.1%; Average loss: 2.8873\n",
            "Returned Loss: 2.913948513736725\n",
            "Done One Timestep\n",
            "Iteration: 3084; Percent complete: 77.1%; Average loss: 2.9139\n",
            "Returned Loss: 3.045012729320314\n",
            "Done One Timestep\n",
            "Iteration: 3085; Percent complete: 77.1%; Average loss: 3.0450\n",
            "Returned Loss: 2.764567308376233\n",
            "Done One Timestep\n",
            "Iteration: 3086; Percent complete: 77.1%; Average loss: 2.7646\n",
            "Returned Loss: 2.9346356619812117\n",
            "Done One Timestep\n",
            "Iteration: 3087; Percent complete: 77.2%; Average loss: 2.9346\n",
            "Returned Loss: 2.828002968016806\n",
            "Done One Timestep\n",
            "Iteration: 3088; Percent complete: 77.2%; Average loss: 2.8280\n",
            "Returned Loss: 2.7616129685542834\n",
            "Done One Timestep\n",
            "Iteration: 3089; Percent complete: 77.2%; Average loss: 2.7616\n",
            "Returned Loss: 2.8491145408422986\n",
            "Done One Timestep\n",
            "Iteration: 3090; Percent complete: 77.2%; Average loss: 2.8491\n",
            "Returned Loss: 2.8172934708648794\n",
            "Done One Timestep\n",
            "Iteration: 3091; Percent complete: 77.3%; Average loss: 2.8173\n",
            "Returned Loss: 2.69621861876722\n",
            "Done One Timestep\n",
            "Iteration: 3092; Percent complete: 77.3%; Average loss: 2.6962\n",
            "Returned Loss: 3.0336569861049374\n",
            "Done One Timestep\n",
            "Iteration: 3093; Percent complete: 77.3%; Average loss: 3.0337\n",
            "Returned Loss: 2.573501203772134\n",
            "Done One Timestep\n",
            "Iteration: 3094; Percent complete: 77.3%; Average loss: 2.5735\n",
            "Returned Loss: 2.809765613419406\n",
            "Done One Timestep\n",
            "Iteration: 3095; Percent complete: 77.4%; Average loss: 2.8098\n",
            "Returned Loss: 2.9600024278536337\n",
            "Done One Timestep\n",
            "Iteration: 3096; Percent complete: 77.4%; Average loss: 2.9600\n",
            "Returned Loss: 3.0108974133122914\n",
            "Done One Timestep\n",
            "Iteration: 3097; Percent complete: 77.4%; Average loss: 3.0109\n",
            "Returned Loss: 2.7568509423501903\n",
            "Done One Timestep\n",
            "Iteration: 3098; Percent complete: 77.5%; Average loss: 2.7569\n",
            "Returned Loss: 2.860033529798606\n",
            "Done One Timestep\n",
            "Iteration: 3099; Percent complete: 77.5%; Average loss: 2.8600\n",
            "Returned Loss: 2.970216001872241\n",
            "Done One Timestep\n",
            "Iteration: 3100; Percent complete: 77.5%; Average loss: 2.9702\n",
            "Returned Loss: 2.8276021272935843\n",
            "Done One Timestep\n",
            "Iteration: 3101; Percent complete: 77.5%; Average loss: 2.8276\n",
            "Returned Loss: 2.8209367524903763\n",
            "Done One Timestep\n",
            "Iteration: 3102; Percent complete: 77.5%; Average loss: 2.8209\n",
            "Returned Loss: 2.9471164534323284\n",
            "Done One Timestep\n",
            "Iteration: 3103; Percent complete: 77.6%; Average loss: 2.9471\n",
            "Returned Loss: 2.815552118320484\n",
            "Done One Timestep\n",
            "Iteration: 3104; Percent complete: 77.6%; Average loss: 2.8156\n",
            "Returned Loss: 2.82705555504445\n",
            "Done One Timestep\n",
            "Iteration: 3105; Percent complete: 77.6%; Average loss: 2.8271\n",
            "Returned Loss: 2.794025171842624\n",
            "Done One Timestep\n",
            "Iteration: 3106; Percent complete: 77.6%; Average loss: 2.7940\n",
            "Returned Loss: 2.7636859299819867\n",
            "Done One Timestep\n",
            "Iteration: 3107; Percent complete: 77.7%; Average loss: 2.7637\n",
            "Returned Loss: 2.856970214669581\n",
            "Done One Timestep\n",
            "Iteration: 3108; Percent complete: 77.7%; Average loss: 2.8570\n",
            "Returned Loss: 2.954418188935271\n",
            "Done One Timestep\n",
            "Iteration: 3109; Percent complete: 77.7%; Average loss: 2.9544\n",
            "Returned Loss: 2.7851381977740677\n",
            "Done One Timestep\n",
            "Iteration: 3110; Percent complete: 77.8%; Average loss: 2.7851\n",
            "Returned Loss: 2.934068161270907\n",
            "Done One Timestep\n",
            "Iteration: 3111; Percent complete: 77.8%; Average loss: 2.9341\n",
            "Returned Loss: 2.967426165774428\n",
            "Done One Timestep\n",
            "Iteration: 3112; Percent complete: 77.8%; Average loss: 2.9674\n",
            "Returned Loss: 2.92380197854309\n",
            "Done One Timestep\n",
            "Iteration: 3113; Percent complete: 77.8%; Average loss: 2.9238\n",
            "Returned Loss: 2.8008507396186624\n",
            "Done One Timestep\n",
            "Iteration: 3114; Percent complete: 77.8%; Average loss: 2.8009\n",
            "Returned Loss: 2.799062051065041\n",
            "Done One Timestep\n",
            "Iteration: 3115; Percent complete: 77.9%; Average loss: 2.7991\n",
            "Returned Loss: 3.0339322191424634\n",
            "Done One Timestep\n",
            "Iteration: 3116; Percent complete: 77.9%; Average loss: 3.0339\n",
            "Returned Loss: 2.8337709591112206\n",
            "Done One Timestep\n",
            "Iteration: 3117; Percent complete: 77.9%; Average loss: 2.8338\n",
            "Returned Loss: 2.6456613001191203\n",
            "Done One Timestep\n",
            "Iteration: 3118; Percent complete: 78.0%; Average loss: 2.6457\n",
            "Returned Loss: 2.837455375208887\n",
            "Done One Timestep\n",
            "Iteration: 3119; Percent complete: 78.0%; Average loss: 2.8375\n",
            "Returned Loss: 2.709085012253906\n",
            "Done One Timestep\n",
            "Iteration: 3120; Percent complete: 78.0%; Average loss: 2.7091\n",
            "Returned Loss: 2.8802962683178412\n",
            "Done One Timestep\n",
            "Iteration: 3121; Percent complete: 78.0%; Average loss: 2.8803\n",
            "Returned Loss: 3.0803297615168668\n",
            "Done One Timestep\n",
            "Iteration: 3122; Percent complete: 78.0%; Average loss: 3.0803\n",
            "Returned Loss: 2.853411800023309\n",
            "Done One Timestep\n",
            "Iteration: 3123; Percent complete: 78.1%; Average loss: 2.8534\n",
            "Returned Loss: 2.8710317646267933\n",
            "Done One Timestep\n",
            "Iteration: 3124; Percent complete: 78.1%; Average loss: 2.8710\n",
            "Returned Loss: 2.5391547538746053\n",
            "Done One Timestep\n",
            "Iteration: 3125; Percent complete: 78.1%; Average loss: 2.5392\n",
            "Returned Loss: 2.4587977516288695\n",
            "Done One Timestep\n",
            "Iteration: 3126; Percent complete: 78.1%; Average loss: 2.4588\n",
            "Returned Loss: 2.610557526857894\n",
            "Done One Timestep\n",
            "Iteration: 3127; Percent complete: 78.2%; Average loss: 2.6106\n",
            "Returned Loss: 2.9070188749088524\n",
            "Done One Timestep\n",
            "Iteration: 3128; Percent complete: 78.2%; Average loss: 2.9070\n",
            "Returned Loss: 2.9884245577536728\n",
            "Done One Timestep\n",
            "Iteration: 3129; Percent complete: 78.2%; Average loss: 2.9884\n",
            "Returned Loss: 2.7622321618071854\n",
            "Done One Timestep\n",
            "Iteration: 3130; Percent complete: 78.2%; Average loss: 2.7622\n",
            "Returned Loss: 2.714489620474369\n",
            "Done One Timestep\n",
            "Iteration: 3131; Percent complete: 78.3%; Average loss: 2.7145\n",
            "Returned Loss: 2.7853654074026113\n",
            "Done One Timestep\n",
            "Iteration: 3132; Percent complete: 78.3%; Average loss: 2.7854\n",
            "Returned Loss: 2.5859456322319114\n",
            "Done One Timestep\n",
            "Iteration: 3133; Percent complete: 78.3%; Average loss: 2.5859\n",
            "Returned Loss: 2.9382352557380877\n",
            "Done One Timestep\n",
            "Iteration: 3134; Percent complete: 78.3%; Average loss: 2.9382\n",
            "Returned Loss: 2.9838987722684016\n",
            "Done One Timestep\n",
            "Iteration: 3135; Percent complete: 78.4%; Average loss: 2.9839\n",
            "Returned Loss: 2.764689917641559\n",
            "Done One Timestep\n",
            "Iteration: 3136; Percent complete: 78.4%; Average loss: 2.7647\n",
            "Returned Loss: 2.723167704395475\n",
            "Done One Timestep\n",
            "Iteration: 3137; Percent complete: 78.4%; Average loss: 2.7232\n",
            "Returned Loss: 2.792413192900204\n",
            "Done One Timestep\n",
            "Iteration: 3138; Percent complete: 78.5%; Average loss: 2.7924\n",
            "Returned Loss: 2.4816083952348498\n",
            "Done One Timestep\n",
            "Iteration: 3139; Percent complete: 78.5%; Average loss: 2.4816\n",
            "Returned Loss: 2.5961162634253596\n",
            "Done One Timestep\n",
            "Iteration: 3140; Percent complete: 78.5%; Average loss: 2.5961\n",
            "Returned Loss: 2.8044592663560692\n",
            "Done One Timestep\n",
            "Iteration: 3141; Percent complete: 78.5%; Average loss: 2.8045\n",
            "Returned Loss: 2.8004191469740007\n",
            "Done One Timestep\n",
            "Iteration: 3142; Percent complete: 78.5%; Average loss: 2.8004\n",
            "Returned Loss: 2.824198222294265\n",
            "Done One Timestep\n",
            "Iteration: 3143; Percent complete: 78.6%; Average loss: 2.8242\n",
            "Returned Loss: 2.7717250135688336\n",
            "Done One Timestep\n",
            "Iteration: 3144; Percent complete: 78.6%; Average loss: 2.7717\n",
            "Returned Loss: 2.862258955874131\n",
            "Done One Timestep\n",
            "Iteration: 3145; Percent complete: 78.6%; Average loss: 2.8623\n",
            "Returned Loss: 2.6852315334651697\n",
            "Done One Timestep\n",
            "Iteration: 3146; Percent complete: 78.6%; Average loss: 2.6852\n",
            "Returned Loss: 2.8620256740016057\n",
            "Done One Timestep\n",
            "Iteration: 3147; Percent complete: 78.7%; Average loss: 2.8620\n",
            "Returned Loss: 2.879489477867425\n",
            "Done One Timestep\n",
            "Iteration: 3148; Percent complete: 78.7%; Average loss: 2.8795\n",
            "Returned Loss: 2.5893983476616773\n",
            "Done One Timestep\n",
            "Iteration: 3149; Percent complete: 78.7%; Average loss: 2.5894\n",
            "Returned Loss: 2.815662346102975\n",
            "Done One Timestep\n",
            "Iteration: 3150; Percent complete: 78.8%; Average loss: 2.8157\n",
            "Returned Loss: 2.932822058313426\n",
            "Done One Timestep\n",
            "Iteration: 3151; Percent complete: 78.8%; Average loss: 2.9328\n",
            "Returned Loss: 2.818397270057641\n",
            "Done One Timestep\n",
            "Iteration: 3152; Percent complete: 78.8%; Average loss: 2.8184\n",
            "Returned Loss: 2.6459026948053075\n",
            "Done One Timestep\n",
            "Iteration: 3153; Percent complete: 78.8%; Average loss: 2.6459\n",
            "Returned Loss: 2.9136763972644673\n",
            "Done One Timestep\n",
            "Iteration: 3154; Percent complete: 78.8%; Average loss: 2.9137\n",
            "Returned Loss: 2.8794962559364117\n",
            "Done One Timestep\n",
            "Iteration: 3155; Percent complete: 78.9%; Average loss: 2.8795\n",
            "Returned Loss: 2.991651892402721\n",
            "Done One Timestep\n",
            "Iteration: 3156; Percent complete: 78.9%; Average loss: 2.9917\n",
            "Returned Loss: 2.9519296189516897\n",
            "Done One Timestep\n",
            "Iteration: 3157; Percent complete: 78.9%; Average loss: 2.9519\n",
            "Returned Loss: 2.8526354448141387\n",
            "Done One Timestep\n",
            "Iteration: 3158; Percent complete: 79.0%; Average loss: 2.8526\n",
            "Returned Loss: 2.810840320753191\n",
            "Done One Timestep\n",
            "Iteration: 3159; Percent complete: 79.0%; Average loss: 2.8108\n",
            "Returned Loss: 2.9288657126339652\n",
            "Done One Timestep\n",
            "Iteration: 3160; Percent complete: 79.0%; Average loss: 2.9289\n",
            "Returned Loss: 2.765859634136016\n",
            "Done One Timestep\n",
            "Iteration: 3161; Percent complete: 79.0%; Average loss: 2.7659\n",
            "Returned Loss: 2.664863893108749\n",
            "Done One Timestep\n",
            "Iteration: 3162; Percent complete: 79.0%; Average loss: 2.6649\n",
            "Returned Loss: 2.9461755838340675\n",
            "Done One Timestep\n",
            "Iteration: 3163; Percent complete: 79.1%; Average loss: 2.9462\n",
            "Returned Loss: 2.6930476375092125\n",
            "Done One Timestep\n",
            "Iteration: 3164; Percent complete: 79.1%; Average loss: 2.6930\n",
            "Returned Loss: 3.0429010940106007\n",
            "Done One Timestep\n",
            "Iteration: 3165; Percent complete: 79.1%; Average loss: 3.0429\n",
            "Returned Loss: 2.7904466713168823\n",
            "Done One Timestep\n",
            "Iteration: 3166; Percent complete: 79.1%; Average loss: 2.7904\n",
            "Returned Loss: 2.8177055927714925\n",
            "Done One Timestep\n",
            "Iteration: 3167; Percent complete: 79.2%; Average loss: 2.8177\n",
            "Returned Loss: 2.809177502624214\n",
            "Done One Timestep\n",
            "Iteration: 3168; Percent complete: 79.2%; Average loss: 2.8092\n",
            "Returned Loss: 2.923090339105469\n",
            "Done One Timestep\n",
            "Iteration: 3169; Percent complete: 79.2%; Average loss: 2.9231\n",
            "Returned Loss: 2.66487507392272\n",
            "Done One Timestep\n",
            "Iteration: 3170; Percent complete: 79.2%; Average loss: 2.6649\n",
            "Returned Loss: 2.7813576165104004\n",
            "Done One Timestep\n",
            "Iteration: 3171; Percent complete: 79.3%; Average loss: 2.7814\n",
            "Returned Loss: 2.8507390340280443\n",
            "Done One Timestep\n",
            "Iteration: 3172; Percent complete: 79.3%; Average loss: 2.8507\n",
            "Returned Loss: 2.859685663023324\n",
            "Done One Timestep\n",
            "Iteration: 3173; Percent complete: 79.3%; Average loss: 2.8597\n",
            "Returned Loss: 2.8480963612596195\n",
            "Done One Timestep\n",
            "Iteration: 3174; Percent complete: 79.3%; Average loss: 2.8481\n",
            "Returned Loss: 2.7408997648564504\n",
            "Done One Timestep\n",
            "Iteration: 3175; Percent complete: 79.4%; Average loss: 2.7409\n",
            "Returned Loss: 2.737056117813762\n",
            "Done One Timestep\n",
            "Iteration: 3176; Percent complete: 79.4%; Average loss: 2.7371\n",
            "Returned Loss: 2.911357001878166\n",
            "Done One Timestep\n",
            "Iteration: 3177; Percent complete: 79.4%; Average loss: 2.9114\n",
            "Returned Loss: 3.0587832442026732\n",
            "Done One Timestep\n",
            "Iteration: 3178; Percent complete: 79.5%; Average loss: 3.0588\n",
            "Returned Loss: 2.786171232898396\n",
            "Done One Timestep\n",
            "Iteration: 3179; Percent complete: 79.5%; Average loss: 2.7862\n",
            "Returned Loss: 2.8013605047017336\n",
            "Done One Timestep\n",
            "Iteration: 3180; Percent complete: 79.5%; Average loss: 2.8014\n",
            "Returned Loss: 2.600823607722803\n",
            "Done One Timestep\n",
            "Iteration: 3181; Percent complete: 79.5%; Average loss: 2.6008\n",
            "Returned Loss: 2.9226993521661804\n",
            "Done One Timestep\n",
            "Iteration: 3182; Percent complete: 79.5%; Average loss: 2.9227\n",
            "Returned Loss: 2.8073865273933314\n",
            "Done One Timestep\n",
            "Iteration: 3183; Percent complete: 79.6%; Average loss: 2.8074\n",
            "Returned Loss: 2.609659597406327\n",
            "Done One Timestep\n",
            "Iteration: 3184; Percent complete: 79.6%; Average loss: 2.6097\n",
            "Returned Loss: 2.9288347683436142\n",
            "Done One Timestep\n",
            "Iteration: 3185; Percent complete: 79.6%; Average loss: 2.9288\n",
            "Returned Loss: 2.832533487639366\n",
            "Done One Timestep\n",
            "Iteration: 3186; Percent complete: 79.7%; Average loss: 2.8325\n",
            "Returned Loss: 2.8722946547044157\n",
            "Done One Timestep\n",
            "Iteration: 3187; Percent complete: 79.7%; Average loss: 2.8723\n",
            "Returned Loss: 2.8234368713469955\n",
            "Done One Timestep\n",
            "Iteration: 3188; Percent complete: 79.7%; Average loss: 2.8234\n",
            "Returned Loss: 2.648007409575467\n",
            "Done One Timestep\n",
            "Iteration: 3189; Percent complete: 79.7%; Average loss: 2.6480\n",
            "Returned Loss: 2.7468223825698255\n",
            "Done One Timestep\n",
            "Iteration: 3190; Percent complete: 79.8%; Average loss: 2.7468\n",
            "Returned Loss: 2.839508319266296\n",
            "Done One Timestep\n",
            "Iteration: 3191; Percent complete: 79.8%; Average loss: 2.8395\n",
            "Returned Loss: 2.8684317149305887\n",
            "Done One Timestep\n",
            "Iteration: 3192; Percent complete: 79.8%; Average loss: 2.8684\n",
            "Returned Loss: 2.9312161602644404\n",
            "Done One Timestep\n",
            "Iteration: 3193; Percent complete: 79.8%; Average loss: 2.9312\n",
            "Returned Loss: 2.9680866706552904\n",
            "Done One Timestep\n",
            "Iteration: 3194; Percent complete: 79.8%; Average loss: 2.9681\n",
            "Returned Loss: 2.879347087264965\n",
            "Done One Timestep\n",
            "Iteration: 3195; Percent complete: 79.9%; Average loss: 2.8793\n",
            "Returned Loss: 3.0884114553272957\n",
            "Done One Timestep\n",
            "Iteration: 3196; Percent complete: 79.9%; Average loss: 3.0884\n",
            "Returned Loss: 2.9887224283972826\n",
            "Done One Timestep\n",
            "Iteration: 3197; Percent complete: 79.9%; Average loss: 2.9887\n",
            "Returned Loss: 2.784857777170295\n",
            "Done One Timestep\n",
            "Iteration: 3198; Percent complete: 80.0%; Average loss: 2.7849\n",
            "Returned Loss: 2.7805789503420177\n",
            "Done One Timestep\n",
            "Iteration: 3199; Percent complete: 80.0%; Average loss: 2.7806\n",
            "Returned Loss: 2.827056076820239\n",
            "Done One Timestep\n",
            "Iteration: 3200; Percent complete: 80.0%; Average loss: 2.8271\n",
            "Returned Loss: 2.8236282972399804\n",
            "Done One Timestep\n",
            "Iteration: 3201; Percent complete: 80.0%; Average loss: 2.8236\n",
            "Returned Loss: 2.991984606074374\n",
            "Done One Timestep\n",
            "Iteration: 3202; Percent complete: 80.0%; Average loss: 2.9920\n",
            "Returned Loss: 2.769745499915888\n",
            "Done One Timestep\n",
            "Iteration: 3203; Percent complete: 80.1%; Average loss: 2.7697\n",
            "Returned Loss: 3.001258993292337\n",
            "Done One Timestep\n",
            "Iteration: 3204; Percent complete: 80.1%; Average loss: 3.0013\n",
            "Returned Loss: 2.8354961011727253\n",
            "Done One Timestep\n",
            "Iteration: 3205; Percent complete: 80.1%; Average loss: 2.8355\n",
            "Returned Loss: 2.901163654750269\n",
            "Done One Timestep\n",
            "Iteration: 3206; Percent complete: 80.2%; Average loss: 2.9012\n",
            "Returned Loss: 2.8047419253009847\n",
            "Done One Timestep\n",
            "Iteration: 3207; Percent complete: 80.2%; Average loss: 2.8047\n",
            "Returned Loss: 2.852889667543527\n",
            "Done One Timestep\n",
            "Iteration: 3208; Percent complete: 80.2%; Average loss: 2.8529\n",
            "Returned Loss: 2.8516804428066553\n",
            "Done One Timestep\n",
            "Iteration: 3209; Percent complete: 80.2%; Average loss: 2.8517\n",
            "Returned Loss: 2.663399835696651\n",
            "Done One Timestep\n",
            "Iteration: 3210; Percent complete: 80.2%; Average loss: 2.6634\n",
            "Returned Loss: 2.9812646439704396\n",
            "Done One Timestep\n",
            "Iteration: 3211; Percent complete: 80.3%; Average loss: 2.9813\n",
            "Returned Loss: 2.701962936901817\n",
            "Done One Timestep\n",
            "Iteration: 3212; Percent complete: 80.3%; Average loss: 2.7020\n",
            "Returned Loss: 2.837936810865358\n",
            "Done One Timestep\n",
            "Iteration: 3213; Percent complete: 80.3%; Average loss: 2.8379\n",
            "Returned Loss: 2.8797504605037076\n",
            "Done One Timestep\n",
            "Iteration: 3214; Percent complete: 80.3%; Average loss: 2.8798\n",
            "Returned Loss: 2.877231315352181\n",
            "Done One Timestep\n",
            "Iteration: 3215; Percent complete: 80.4%; Average loss: 2.8772\n",
            "Returned Loss: 2.8444428029293616\n",
            "Done One Timestep\n",
            "Iteration: 3216; Percent complete: 80.4%; Average loss: 2.8444\n",
            "Returned Loss: 2.923479399284742\n",
            "Done One Timestep\n",
            "Iteration: 3217; Percent complete: 80.4%; Average loss: 2.9235\n",
            "Returned Loss: 2.9400516693206464\n",
            "Done One Timestep\n",
            "Iteration: 3218; Percent complete: 80.5%; Average loss: 2.9401\n",
            "Returned Loss: 2.878062379852399\n",
            "Done One Timestep\n",
            "Iteration: 3219; Percent complete: 80.5%; Average loss: 2.8781\n",
            "Returned Loss: 2.651776667820783\n",
            "Done One Timestep\n",
            "Iteration: 3220; Percent complete: 80.5%; Average loss: 2.6518\n",
            "Returned Loss: 2.8851526341956073\n",
            "Done One Timestep\n",
            "Iteration: 3221; Percent complete: 80.5%; Average loss: 2.8852\n",
            "Returned Loss: 2.9758088174541815\n",
            "Done One Timestep\n",
            "Iteration: 3222; Percent complete: 80.5%; Average loss: 2.9758\n",
            "Returned Loss: 2.910914333542188\n",
            "Done One Timestep\n",
            "Iteration: 3223; Percent complete: 80.6%; Average loss: 2.9109\n",
            "Returned Loss: 2.7114321068460394\n",
            "Done One Timestep\n",
            "Iteration: 3224; Percent complete: 80.6%; Average loss: 2.7114\n",
            "Returned Loss: 2.7295453716271405\n",
            "Done One Timestep\n",
            "Iteration: 3225; Percent complete: 80.6%; Average loss: 2.7295\n",
            "Returned Loss: 2.7613928246955584\n",
            "Done One Timestep\n",
            "Iteration: 3226; Percent complete: 80.7%; Average loss: 2.7614\n",
            "Returned Loss: 2.8634470267054852\n",
            "Done One Timestep\n",
            "Iteration: 3227; Percent complete: 80.7%; Average loss: 2.8634\n",
            "Returned Loss: 2.8121662834040873\n",
            "Done One Timestep\n",
            "Iteration: 3228; Percent complete: 80.7%; Average loss: 2.8122\n",
            "Returned Loss: 2.8203051080728714\n",
            "Done One Timestep\n",
            "Iteration: 3229; Percent complete: 80.7%; Average loss: 2.8203\n",
            "Returned Loss: 3.0604638399478667\n",
            "Done One Timestep\n",
            "Iteration: 3230; Percent complete: 80.8%; Average loss: 3.0605\n",
            "Returned Loss: 2.3950686199012186\n",
            "Done One Timestep\n",
            "Iteration: 3231; Percent complete: 80.8%; Average loss: 2.3951\n",
            "Returned Loss: 2.834579170975965\n",
            "Done One Timestep\n",
            "Iteration: 3232; Percent complete: 80.8%; Average loss: 2.8346\n",
            "Returned Loss: 2.650194936294562\n",
            "Done One Timestep\n",
            "Iteration: 3233; Percent complete: 80.8%; Average loss: 2.6502\n",
            "Returned Loss: 2.8243958322757696\n",
            "Done One Timestep\n",
            "Iteration: 3234; Percent complete: 80.8%; Average loss: 2.8244\n",
            "Returned Loss: 3.005274612241469\n",
            "Done One Timestep\n",
            "Iteration: 3235; Percent complete: 80.9%; Average loss: 3.0053\n",
            "Returned Loss: 2.6680607199883046\n",
            "Done One Timestep\n",
            "Iteration: 3236; Percent complete: 80.9%; Average loss: 2.6681\n",
            "Returned Loss: 2.9448211261521102\n",
            "Done One Timestep\n",
            "Iteration: 3237; Percent complete: 80.9%; Average loss: 2.9448\n",
            "Returned Loss: 2.7390971752608535\n",
            "Done One Timestep\n",
            "Iteration: 3238; Percent complete: 81.0%; Average loss: 2.7391\n",
            "Returned Loss: 2.998108416817485\n",
            "Done One Timestep\n",
            "Iteration: 3239; Percent complete: 81.0%; Average loss: 2.9981\n",
            "Returned Loss: 2.969967261313733\n",
            "Done One Timestep\n",
            "Iteration: 3240; Percent complete: 81.0%; Average loss: 2.9700\n",
            "Returned Loss: 2.8870388543064793\n",
            "Done One Timestep\n",
            "Iteration: 3241; Percent complete: 81.0%; Average loss: 2.8870\n",
            "Returned Loss: 2.97355046875437\n",
            "Done One Timestep\n",
            "Iteration: 3242; Percent complete: 81.0%; Average loss: 2.9736\n",
            "Returned Loss: 2.940636630794687\n",
            "Done One Timestep\n",
            "Iteration: 3243; Percent complete: 81.1%; Average loss: 2.9406\n",
            "Returned Loss: 2.6834813718321193\n",
            "Done One Timestep\n",
            "Iteration: 3244; Percent complete: 81.1%; Average loss: 2.6835\n",
            "Returned Loss: 2.7664754115196497\n",
            "Done One Timestep\n",
            "Iteration: 3245; Percent complete: 81.1%; Average loss: 2.7665\n",
            "Returned Loss: 2.8012166009558475\n",
            "Done One Timestep\n",
            "Iteration: 3246; Percent complete: 81.2%; Average loss: 2.8012\n",
            "Returned Loss: 2.870435779028398\n",
            "Done One Timestep\n",
            "Iteration: 3247; Percent complete: 81.2%; Average loss: 2.8704\n",
            "Returned Loss: 2.969391070010085\n",
            "Done One Timestep\n",
            "Iteration: 3248; Percent complete: 81.2%; Average loss: 2.9694\n",
            "Returned Loss: 2.823855852891203\n",
            "Done One Timestep\n",
            "Iteration: 3249; Percent complete: 81.2%; Average loss: 2.8239\n",
            "Returned Loss: 2.7132475837394607\n",
            "Done One Timestep\n",
            "Iteration: 3250; Percent complete: 81.2%; Average loss: 2.7132\n",
            "Returned Loss: 2.8224168654901383\n",
            "Done One Timestep\n",
            "Iteration: 3251; Percent complete: 81.3%; Average loss: 2.8224\n",
            "Returned Loss: 2.6616839820416858\n",
            "Done One Timestep\n",
            "Iteration: 3252; Percent complete: 81.3%; Average loss: 2.6617\n",
            "Returned Loss: 3.1357064877723095\n",
            "Done One Timestep\n",
            "Iteration: 3253; Percent complete: 81.3%; Average loss: 3.1357\n",
            "Returned Loss: 2.807564003086437\n",
            "Done One Timestep\n",
            "Iteration: 3254; Percent complete: 81.3%; Average loss: 2.8076\n",
            "Returned Loss: 2.957852657586336\n",
            "Done One Timestep\n",
            "Iteration: 3255; Percent complete: 81.4%; Average loss: 2.9579\n",
            "Returned Loss: 2.750536426825586\n",
            "Done One Timestep\n",
            "Iteration: 3256; Percent complete: 81.4%; Average loss: 2.7505\n",
            "Returned Loss: 2.913817433034396\n",
            "Done One Timestep\n",
            "Iteration: 3257; Percent complete: 81.4%; Average loss: 2.9138\n",
            "Returned Loss: 2.6027911784525832\n",
            "Done One Timestep\n",
            "Iteration: 3258; Percent complete: 81.5%; Average loss: 2.6028\n",
            "Returned Loss: 2.8338516336893615\n",
            "Done One Timestep\n",
            "Iteration: 3259; Percent complete: 81.5%; Average loss: 2.8339\n",
            "Returned Loss: 2.7269585273485544\n",
            "Done One Timestep\n",
            "Iteration: 3260; Percent complete: 81.5%; Average loss: 2.7270\n",
            "Returned Loss: 2.7221642853294927\n",
            "Done One Timestep\n",
            "Iteration: 3261; Percent complete: 81.5%; Average loss: 2.7222\n",
            "Returned Loss: 2.7620929669989223\n",
            "Done One Timestep\n",
            "Iteration: 3262; Percent complete: 81.5%; Average loss: 2.7621\n",
            "Returned Loss: 2.6570365461093433\n",
            "Done One Timestep\n",
            "Iteration: 3263; Percent complete: 81.6%; Average loss: 2.6570\n",
            "Returned Loss: 2.9350984715953623\n",
            "Done One Timestep\n",
            "Iteration: 3264; Percent complete: 81.6%; Average loss: 2.9351\n",
            "Returned Loss: 2.712431226697419\n",
            "Done One Timestep\n",
            "Iteration: 3265; Percent complete: 81.6%; Average loss: 2.7124\n",
            "Returned Loss: 2.699901373478225\n",
            "Done One Timestep\n",
            "Iteration: 3266; Percent complete: 81.7%; Average loss: 2.6999\n",
            "Returned Loss: 2.820813086849004\n",
            "Done One Timestep\n",
            "Iteration: 3267; Percent complete: 81.7%; Average loss: 2.8208\n",
            "Returned Loss: 2.915021175765458\n",
            "Done One Timestep\n",
            "Iteration: 3268; Percent complete: 81.7%; Average loss: 2.9150\n",
            "Returned Loss: 2.92909392832\n",
            "Done One Timestep\n",
            "Iteration: 3269; Percent complete: 81.7%; Average loss: 2.9291\n",
            "Returned Loss: 2.744707765176381\n",
            "Done One Timestep\n",
            "Iteration: 3270; Percent complete: 81.8%; Average loss: 2.7447\n",
            "Returned Loss: 2.636066147842197\n",
            "Done One Timestep\n",
            "Iteration: 3271; Percent complete: 81.8%; Average loss: 2.6361\n",
            "Returned Loss: 2.749456472907583\n",
            "Done One Timestep\n",
            "Iteration: 3272; Percent complete: 81.8%; Average loss: 2.7495\n",
            "Returned Loss: 2.863312175529392\n",
            "Done One Timestep\n",
            "Iteration: 3273; Percent complete: 81.8%; Average loss: 2.8633\n",
            "Returned Loss: 2.7707137549841256\n",
            "Done One Timestep\n",
            "Iteration: 3274; Percent complete: 81.8%; Average loss: 2.7707\n",
            "Returned Loss: 2.7305387237430097\n",
            "Done One Timestep\n",
            "Iteration: 3275; Percent complete: 81.9%; Average loss: 2.7305\n",
            "Returned Loss: 2.7555420092419225\n",
            "Done One Timestep\n",
            "Iteration: 3276; Percent complete: 81.9%; Average loss: 2.7555\n",
            "Returned Loss: 2.7453703474981292\n",
            "Done One Timestep\n",
            "Iteration: 3277; Percent complete: 81.9%; Average loss: 2.7454\n",
            "Returned Loss: 2.913412201508193\n",
            "Done One Timestep\n",
            "Iteration: 3278; Percent complete: 82.0%; Average loss: 2.9134\n",
            "Returned Loss: 2.4890198923676135\n",
            "Done One Timestep\n",
            "Iteration: 3279; Percent complete: 82.0%; Average loss: 2.4890\n",
            "Returned Loss: 2.5945282104282383\n",
            "Done One Timestep\n",
            "Iteration: 3280; Percent complete: 82.0%; Average loss: 2.5945\n",
            "Returned Loss: 2.813711998336003\n",
            "Done One Timestep\n",
            "Iteration: 3281; Percent complete: 82.0%; Average loss: 2.8137\n",
            "Returned Loss: 2.828370706192011\n",
            "Done One Timestep\n",
            "Iteration: 3282; Percent complete: 82.0%; Average loss: 2.8284\n",
            "Returned Loss: 2.731843044362243\n",
            "Done One Timestep\n",
            "Iteration: 3283; Percent complete: 82.1%; Average loss: 2.7318\n",
            "Returned Loss: 2.510248738229298\n",
            "Done One Timestep\n",
            "Iteration: 3284; Percent complete: 82.1%; Average loss: 2.5102\n",
            "Returned Loss: 2.8263682801849566\n",
            "Done One Timestep\n",
            "Iteration: 3285; Percent complete: 82.1%; Average loss: 2.8264\n",
            "Returned Loss: 2.698347825332447\n",
            "Done One Timestep\n",
            "Iteration: 3286; Percent complete: 82.2%; Average loss: 2.6983\n",
            "Returned Loss: 2.4653501299647402\n",
            "Done One Timestep\n",
            "Iteration: 3287; Percent complete: 82.2%; Average loss: 2.4654\n",
            "Returned Loss: 2.9163219300043015\n",
            "Done One Timestep\n",
            "Iteration: 3288; Percent complete: 82.2%; Average loss: 2.9163\n",
            "Returned Loss: 2.768639707334474\n",
            "Done One Timestep\n",
            "Iteration: 3289; Percent complete: 82.2%; Average loss: 2.7686\n",
            "Returned Loss: 2.7766171435711198\n",
            "Done One Timestep\n",
            "Iteration: 3290; Percent complete: 82.2%; Average loss: 2.7766\n",
            "Returned Loss: 3.1899693975998358\n",
            "Done One Timestep\n",
            "Iteration: 3291; Percent complete: 82.3%; Average loss: 3.1900\n",
            "Returned Loss: 2.7734769590002673\n",
            "Done One Timestep\n",
            "Iteration: 3292; Percent complete: 82.3%; Average loss: 2.7735\n",
            "Returned Loss: 2.635635991232098\n",
            "Done One Timestep\n",
            "Iteration: 3293; Percent complete: 82.3%; Average loss: 2.6356\n",
            "Returned Loss: 2.7685903944484216\n",
            "Done One Timestep\n",
            "Iteration: 3294; Percent complete: 82.3%; Average loss: 2.7686\n",
            "Returned Loss: 2.6949382045909194\n",
            "Done One Timestep\n",
            "Iteration: 3295; Percent complete: 82.4%; Average loss: 2.6949\n",
            "Returned Loss: 2.5231748684639266\n",
            "Done One Timestep\n",
            "Iteration: 3296; Percent complete: 82.4%; Average loss: 2.5232\n",
            "Returned Loss: 2.7687103815860015\n",
            "Done One Timestep\n",
            "Iteration: 3297; Percent complete: 82.4%; Average loss: 2.7687\n",
            "Returned Loss: 3.1358060905552625\n",
            "Done One Timestep\n",
            "Iteration: 3298; Percent complete: 82.5%; Average loss: 3.1358\n",
            "Returned Loss: 2.7941346346279543\n",
            "Done One Timestep\n",
            "Iteration: 3299; Percent complete: 82.5%; Average loss: 2.7941\n",
            "Returned Loss: 2.644175670364312\n",
            "Done One Timestep\n",
            "Iteration: 3300; Percent complete: 82.5%; Average loss: 2.6442\n",
            "Returned Loss: 2.6575480080351497\n",
            "Done One Timestep\n",
            "Iteration: 3301; Percent complete: 82.5%; Average loss: 2.6575\n",
            "Returned Loss: 2.86086356477973\n",
            "Done One Timestep\n",
            "Iteration: 3302; Percent complete: 82.5%; Average loss: 2.8609\n",
            "Returned Loss: 2.6936005005379586\n",
            "Done One Timestep\n",
            "Iteration: 3303; Percent complete: 82.6%; Average loss: 2.6936\n",
            "Returned Loss: 2.8822606783460745\n",
            "Done One Timestep\n",
            "Iteration: 3304; Percent complete: 82.6%; Average loss: 2.8823\n",
            "Returned Loss: 2.9975286913149564\n",
            "Done One Timestep\n",
            "Iteration: 3305; Percent complete: 82.6%; Average loss: 2.9975\n",
            "Returned Loss: 2.9851232965218624\n",
            "Done One Timestep\n",
            "Iteration: 3306; Percent complete: 82.7%; Average loss: 2.9851\n",
            "Returned Loss: 2.7447380653012017\n",
            "Done One Timestep\n",
            "Iteration: 3307; Percent complete: 82.7%; Average loss: 2.7447\n",
            "Returned Loss: 2.6846470642055356\n",
            "Done One Timestep\n",
            "Iteration: 3308; Percent complete: 82.7%; Average loss: 2.6846\n",
            "Returned Loss: 2.6985357127802367\n",
            "Done One Timestep\n",
            "Iteration: 3309; Percent complete: 82.7%; Average loss: 2.6985\n",
            "Returned Loss: 2.8170442493583665\n",
            "Done One Timestep\n",
            "Iteration: 3310; Percent complete: 82.8%; Average loss: 2.8170\n",
            "Returned Loss: 2.7645520997942317\n",
            "Done One Timestep\n",
            "Iteration: 3311; Percent complete: 82.8%; Average loss: 2.7646\n",
            "Returned Loss: 3.0935295874854396\n",
            "Done One Timestep\n",
            "Iteration: 3312; Percent complete: 82.8%; Average loss: 3.0935\n",
            "Returned Loss: 2.6609467431693634\n",
            "Done One Timestep\n",
            "Iteration: 3313; Percent complete: 82.8%; Average loss: 2.6609\n",
            "Returned Loss: 2.627378167312903\n",
            "Done One Timestep\n",
            "Iteration: 3314; Percent complete: 82.8%; Average loss: 2.6274\n",
            "Returned Loss: 2.604027199837161\n",
            "Done One Timestep\n",
            "Iteration: 3315; Percent complete: 82.9%; Average loss: 2.6040\n",
            "Returned Loss: 2.7498694679100537\n",
            "Done One Timestep\n",
            "Iteration: 3316; Percent complete: 82.9%; Average loss: 2.7499\n",
            "Returned Loss: 2.6725778702669833\n",
            "Done One Timestep\n",
            "Iteration: 3317; Percent complete: 82.9%; Average loss: 2.6726\n",
            "Returned Loss: 2.7461204685831584\n",
            "Done One Timestep\n",
            "Iteration: 3318; Percent complete: 83.0%; Average loss: 2.7461\n",
            "Returned Loss: 2.634173957751765\n",
            "Done One Timestep\n",
            "Iteration: 3319; Percent complete: 83.0%; Average loss: 2.6342\n",
            "Returned Loss: 3.073559200525511\n",
            "Done One Timestep\n",
            "Iteration: 3320; Percent complete: 83.0%; Average loss: 3.0736\n",
            "Returned Loss: 2.7606561505967218\n",
            "Done One Timestep\n",
            "Iteration: 3321; Percent complete: 83.0%; Average loss: 2.7607\n",
            "Returned Loss: 2.754304835364332\n",
            "Done One Timestep\n",
            "Iteration: 3322; Percent complete: 83.0%; Average loss: 2.7543\n",
            "Returned Loss: 2.966336057480846\n",
            "Done One Timestep\n",
            "Iteration: 3323; Percent complete: 83.1%; Average loss: 2.9663\n",
            "Returned Loss: 3.0042322028084376\n",
            "Done One Timestep\n",
            "Iteration: 3324; Percent complete: 83.1%; Average loss: 3.0042\n",
            "Returned Loss: 2.785824191583971\n",
            "Done One Timestep\n",
            "Iteration: 3325; Percent complete: 83.1%; Average loss: 2.7858\n",
            "Returned Loss: 2.6209837143484327\n",
            "Done One Timestep\n",
            "Iteration: 3326; Percent complete: 83.2%; Average loss: 2.6210\n",
            "Returned Loss: 2.9634310201906104\n",
            "Done One Timestep\n",
            "Iteration: 3327; Percent complete: 83.2%; Average loss: 2.9634\n",
            "Returned Loss: 2.6674984834677917\n",
            "Done One Timestep\n",
            "Iteration: 3328; Percent complete: 83.2%; Average loss: 2.6675\n",
            "Returned Loss: 2.7403054032729215\n",
            "Done One Timestep\n",
            "Iteration: 3329; Percent complete: 83.2%; Average loss: 2.7403\n",
            "Returned Loss: 2.707675684384666\n",
            "Done One Timestep\n",
            "Iteration: 3330; Percent complete: 83.2%; Average loss: 2.7077\n",
            "Returned Loss: 2.7184450054008393\n",
            "Done One Timestep\n",
            "Iteration: 3331; Percent complete: 83.3%; Average loss: 2.7184\n",
            "Returned Loss: 2.8858558281662727\n",
            "Done One Timestep\n",
            "Iteration: 3332; Percent complete: 83.3%; Average loss: 2.8859\n",
            "Returned Loss: 2.566351801556213\n",
            "Done One Timestep\n",
            "Iteration: 3333; Percent complete: 83.3%; Average loss: 2.5664\n",
            "Returned Loss: 2.8075058368251846\n",
            "Done One Timestep\n",
            "Iteration: 3334; Percent complete: 83.4%; Average loss: 2.8075\n",
            "Returned Loss: 2.9637021561805397\n",
            "Done One Timestep\n",
            "Iteration: 3335; Percent complete: 83.4%; Average loss: 2.9637\n",
            "Returned Loss: 2.7495024148102214\n",
            "Done One Timestep\n",
            "Iteration: 3336; Percent complete: 83.4%; Average loss: 2.7495\n",
            "Returned Loss: 2.7401553924617246\n",
            "Done One Timestep\n",
            "Iteration: 3337; Percent complete: 83.4%; Average loss: 2.7402\n",
            "Returned Loss: 2.555916732351107\n",
            "Done One Timestep\n",
            "Iteration: 3338; Percent complete: 83.5%; Average loss: 2.5559\n",
            "Returned Loss: 2.596240409422195\n",
            "Done One Timestep\n",
            "Iteration: 3339; Percent complete: 83.5%; Average loss: 2.5962\n",
            "Returned Loss: 2.9137986116879215\n",
            "Done One Timestep\n",
            "Iteration: 3340; Percent complete: 83.5%; Average loss: 2.9138\n",
            "Returned Loss: 2.7215029899484944\n",
            "Done One Timestep\n",
            "Iteration: 3341; Percent complete: 83.5%; Average loss: 2.7215\n",
            "Returned Loss: 2.7545414801405848\n",
            "Done One Timestep\n",
            "Iteration: 3342; Percent complete: 83.5%; Average loss: 2.7545\n",
            "Returned Loss: 2.787615919507767\n",
            "Done One Timestep\n",
            "Iteration: 3343; Percent complete: 83.6%; Average loss: 2.7876\n",
            "Returned Loss: 2.694709065095006\n",
            "Done One Timestep\n",
            "Iteration: 3344; Percent complete: 83.6%; Average loss: 2.6947\n",
            "Returned Loss: 2.7807769077773177\n",
            "Done One Timestep\n",
            "Iteration: 3345; Percent complete: 83.6%; Average loss: 2.7808\n",
            "Returned Loss: 2.780237279751724\n",
            "Done One Timestep\n",
            "Iteration: 3346; Percent complete: 83.7%; Average loss: 2.7802\n",
            "Returned Loss: 2.7269040089326912\n",
            "Done One Timestep\n",
            "Iteration: 3347; Percent complete: 83.7%; Average loss: 2.7269\n",
            "Returned Loss: 2.8150587506573315\n",
            "Done One Timestep\n",
            "Iteration: 3348; Percent complete: 83.7%; Average loss: 2.8151\n",
            "Returned Loss: 2.6882272890771417\n",
            "Done One Timestep\n",
            "Iteration: 3349; Percent complete: 83.7%; Average loss: 2.6882\n",
            "Returned Loss: 2.794939618929872\n",
            "Done One Timestep\n",
            "Iteration: 3350; Percent complete: 83.8%; Average loss: 2.7949\n",
            "Returned Loss: 2.8187784216942866\n",
            "Done One Timestep\n",
            "Iteration: 3351; Percent complete: 83.8%; Average loss: 2.8188\n",
            "Returned Loss: 2.5819344715162877\n",
            "Done One Timestep\n",
            "Iteration: 3352; Percent complete: 83.8%; Average loss: 2.5819\n",
            "Returned Loss: 2.796859353808916\n",
            "Done One Timestep\n",
            "Iteration: 3353; Percent complete: 83.8%; Average loss: 2.7969\n",
            "Returned Loss: 2.8916908906609335\n",
            "Done One Timestep\n",
            "Iteration: 3354; Percent complete: 83.9%; Average loss: 2.8917\n",
            "Returned Loss: 2.702254165986485\n",
            "Done One Timestep\n",
            "Iteration: 3355; Percent complete: 83.9%; Average loss: 2.7023\n",
            "Returned Loss: 2.6878815952818695\n",
            "Done One Timestep\n",
            "Iteration: 3356; Percent complete: 83.9%; Average loss: 2.6879\n",
            "Returned Loss: 2.7129876869509464\n",
            "Done One Timestep\n",
            "Iteration: 3357; Percent complete: 83.9%; Average loss: 2.7130\n",
            "Returned Loss: 2.8357211707383008\n",
            "Done One Timestep\n",
            "Iteration: 3358; Percent complete: 84.0%; Average loss: 2.8357\n",
            "Returned Loss: 2.6539133522058393\n",
            "Done One Timestep\n",
            "Iteration: 3359; Percent complete: 84.0%; Average loss: 2.6539\n",
            "Returned Loss: 2.8478943980945384\n",
            "Done One Timestep\n",
            "Iteration: 3360; Percent complete: 84.0%; Average loss: 2.8479\n",
            "Returned Loss: 2.49994768695962\n",
            "Done One Timestep\n",
            "Iteration: 3361; Percent complete: 84.0%; Average loss: 2.4999\n",
            "Returned Loss: 3.0297965879330686\n",
            "Done One Timestep\n",
            "Iteration: 3362; Percent complete: 84.0%; Average loss: 3.0298\n",
            "Returned Loss: 2.8012671168738357\n",
            "Done One Timestep\n",
            "Iteration: 3363; Percent complete: 84.1%; Average loss: 2.8013\n",
            "Returned Loss: 2.8474253767624176\n",
            "Done One Timestep\n",
            "Iteration: 3364; Percent complete: 84.1%; Average loss: 2.8474\n",
            "Returned Loss: 2.7859397385269404\n",
            "Done One Timestep\n",
            "Iteration: 3365; Percent complete: 84.1%; Average loss: 2.7859\n",
            "Returned Loss: 2.899367436556355\n",
            "Done One Timestep\n",
            "Iteration: 3366; Percent complete: 84.2%; Average loss: 2.8994\n",
            "Returned Loss: 2.6859065121714405\n",
            "Done One Timestep\n",
            "Iteration: 3367; Percent complete: 84.2%; Average loss: 2.6859\n",
            "Returned Loss: 2.847126044045684\n",
            "Done One Timestep\n",
            "Iteration: 3368; Percent complete: 84.2%; Average loss: 2.8471\n",
            "Returned Loss: 2.8530621744998514\n",
            "Done One Timestep\n",
            "Iteration: 3369; Percent complete: 84.2%; Average loss: 2.8531\n",
            "Returned Loss: 2.7648088350726256\n",
            "Done One Timestep\n",
            "Iteration: 3370; Percent complete: 84.2%; Average loss: 2.7648\n",
            "Returned Loss: 2.8505404020240275\n",
            "Done One Timestep\n",
            "Iteration: 3371; Percent complete: 84.3%; Average loss: 2.8505\n",
            "Returned Loss: 2.8110667079012712\n",
            "Done One Timestep\n",
            "Iteration: 3372; Percent complete: 84.3%; Average loss: 2.8111\n",
            "Returned Loss: 2.831042429466661\n",
            "Done One Timestep\n",
            "Iteration: 3373; Percent complete: 84.3%; Average loss: 2.8310\n",
            "Returned Loss: 2.7220318048323975\n",
            "Done One Timestep\n",
            "Iteration: 3374; Percent complete: 84.4%; Average loss: 2.7220\n",
            "Returned Loss: 3.008793243510994\n",
            "Done One Timestep\n",
            "Iteration: 3375; Percent complete: 84.4%; Average loss: 3.0088\n",
            "Returned Loss: 2.881189056769414\n",
            "Done One Timestep\n",
            "Iteration: 3376; Percent complete: 84.4%; Average loss: 2.8812\n",
            "Returned Loss: 2.460147104383157\n",
            "Done One Timestep\n",
            "Iteration: 3377; Percent complete: 84.4%; Average loss: 2.4601\n",
            "Returned Loss: 2.7682099665519853\n",
            "Done One Timestep\n",
            "Iteration: 3378; Percent complete: 84.5%; Average loss: 2.7682\n",
            "Returned Loss: 2.7023502429171153\n",
            "Done One Timestep\n",
            "Iteration: 3379; Percent complete: 84.5%; Average loss: 2.7024\n",
            "Returned Loss: 2.7860360530610304\n",
            "Done One Timestep\n",
            "Iteration: 3380; Percent complete: 84.5%; Average loss: 2.7860\n",
            "Returned Loss: 2.8724604167552603\n",
            "Done One Timestep\n",
            "Iteration: 3381; Percent complete: 84.5%; Average loss: 2.8725\n",
            "Returned Loss: 2.7557574461618803\n",
            "Done One Timestep\n",
            "Iteration: 3382; Percent complete: 84.5%; Average loss: 2.7558\n",
            "Returned Loss: 3.16047534681628\n",
            "Done One Timestep\n",
            "Iteration: 3383; Percent complete: 84.6%; Average loss: 3.1605\n",
            "Returned Loss: 2.8140464809086296\n",
            "Done One Timestep\n",
            "Iteration: 3384; Percent complete: 84.6%; Average loss: 2.8140\n",
            "Returned Loss: 2.924818255441199\n",
            "Done One Timestep\n",
            "Iteration: 3385; Percent complete: 84.6%; Average loss: 2.9248\n",
            "Returned Loss: 2.890707407496836\n",
            "Done One Timestep\n",
            "Iteration: 3386; Percent complete: 84.7%; Average loss: 2.8907\n",
            "Returned Loss: 2.6956102354766487\n",
            "Done One Timestep\n",
            "Iteration: 3387; Percent complete: 84.7%; Average loss: 2.6956\n",
            "Returned Loss: 2.5535254405106937\n",
            "Done One Timestep\n",
            "Iteration: 3388; Percent complete: 84.7%; Average loss: 2.5535\n",
            "Returned Loss: 2.758314329120528\n",
            "Done One Timestep\n",
            "Iteration: 3389; Percent complete: 84.7%; Average loss: 2.7583\n",
            "Returned Loss: 2.8700693046803623\n",
            "Done One Timestep\n",
            "Iteration: 3390; Percent complete: 84.8%; Average loss: 2.8701\n",
            "Returned Loss: 2.7167360356554573\n",
            "Done One Timestep\n",
            "Iteration: 3391; Percent complete: 84.8%; Average loss: 2.7167\n",
            "Returned Loss: 2.7115509976881413\n",
            "Done One Timestep\n",
            "Iteration: 3392; Percent complete: 84.8%; Average loss: 2.7116\n",
            "Returned Loss: 2.6377160546523104\n",
            "Done One Timestep\n",
            "Iteration: 3393; Percent complete: 84.8%; Average loss: 2.6377\n",
            "Returned Loss: 2.6055387442239843\n",
            "Done One Timestep\n",
            "Iteration: 3394; Percent complete: 84.9%; Average loss: 2.6055\n",
            "Returned Loss: 2.736499308592987\n",
            "Done One Timestep\n",
            "Iteration: 3395; Percent complete: 84.9%; Average loss: 2.7365\n",
            "Returned Loss: 2.7850724402418794\n",
            "Done One Timestep\n",
            "Iteration: 3396; Percent complete: 84.9%; Average loss: 2.7851\n",
            "Returned Loss: 2.6969958245832597\n",
            "Done One Timestep\n",
            "Iteration: 3397; Percent complete: 84.9%; Average loss: 2.6970\n",
            "Returned Loss: 2.501189571130247\n",
            "Done One Timestep\n",
            "Iteration: 3398; Percent complete: 85.0%; Average loss: 2.5012\n",
            "Returned Loss: 2.67642132718745\n",
            "Done One Timestep\n",
            "Iteration: 3399; Percent complete: 85.0%; Average loss: 2.6764\n",
            "Returned Loss: 2.7949444247345787\n",
            "Done One Timestep\n",
            "Iteration: 3400; Percent complete: 85.0%; Average loss: 2.7949\n",
            "Returned Loss: 2.7536000570672408\n",
            "Done One Timestep\n",
            "Iteration: 3401; Percent complete: 85.0%; Average loss: 2.7536\n",
            "Returned Loss: 2.9270293276508568\n",
            "Done One Timestep\n",
            "Iteration: 3402; Percent complete: 85.0%; Average loss: 2.9270\n",
            "Returned Loss: 2.921693210110029\n",
            "Done One Timestep\n",
            "Iteration: 3403; Percent complete: 85.1%; Average loss: 2.9217\n",
            "Returned Loss: 2.778510992673438\n",
            "Done One Timestep\n",
            "Iteration: 3404; Percent complete: 85.1%; Average loss: 2.7785\n",
            "Returned Loss: 2.7079436430118475\n",
            "Done One Timestep\n",
            "Iteration: 3405; Percent complete: 85.1%; Average loss: 2.7079\n",
            "Returned Loss: 2.995079142625252\n",
            "Done One Timestep\n",
            "Iteration: 3406; Percent complete: 85.2%; Average loss: 2.9951\n",
            "Returned Loss: 2.862593348585886\n",
            "Done One Timestep\n",
            "Iteration: 3407; Percent complete: 85.2%; Average loss: 2.8626\n",
            "Returned Loss: 2.7998616327762043\n",
            "Done One Timestep\n",
            "Iteration: 3408; Percent complete: 85.2%; Average loss: 2.7999\n",
            "Returned Loss: 2.7625049763339633\n",
            "Done One Timestep\n",
            "Iteration: 3409; Percent complete: 85.2%; Average loss: 2.7625\n",
            "Returned Loss: 2.9915048274513163\n",
            "Done One Timestep\n",
            "Iteration: 3410; Percent complete: 85.2%; Average loss: 2.9915\n",
            "Returned Loss: 2.5680902779772876\n",
            "Done One Timestep\n",
            "Iteration: 3411; Percent complete: 85.3%; Average loss: 2.5681\n",
            "Returned Loss: 2.834589434256801\n",
            "Done One Timestep\n",
            "Iteration: 3412; Percent complete: 85.3%; Average loss: 2.8346\n",
            "Returned Loss: 2.528131882472795\n",
            "Done One Timestep\n",
            "Iteration: 3413; Percent complete: 85.3%; Average loss: 2.5281\n",
            "Returned Loss: 2.9291831518367797\n",
            "Done One Timestep\n",
            "Iteration: 3414; Percent complete: 85.4%; Average loss: 2.9292\n",
            "Returned Loss: 2.795949917624095\n",
            "Done One Timestep\n",
            "Iteration: 3415; Percent complete: 85.4%; Average loss: 2.7959\n",
            "Returned Loss: 3.104056332198262\n",
            "Done One Timestep\n",
            "Iteration: 3416; Percent complete: 85.4%; Average loss: 3.1041\n",
            "Returned Loss: 2.8992230987103813\n",
            "Done One Timestep\n",
            "Iteration: 3417; Percent complete: 85.4%; Average loss: 2.8992\n",
            "Returned Loss: 2.9801385501727737\n",
            "Done One Timestep\n",
            "Iteration: 3418; Percent complete: 85.5%; Average loss: 2.9801\n",
            "Returned Loss: 2.5860006686843895\n",
            "Done One Timestep\n",
            "Iteration: 3419; Percent complete: 85.5%; Average loss: 2.5860\n",
            "Returned Loss: 2.818306878591913\n",
            "Done One Timestep\n",
            "Iteration: 3420; Percent complete: 85.5%; Average loss: 2.8183\n",
            "Returned Loss: 2.5259495140563013\n",
            "Done One Timestep\n",
            "Iteration: 3421; Percent complete: 85.5%; Average loss: 2.5259\n",
            "Returned Loss: 2.7080826832405207\n",
            "Done One Timestep\n",
            "Iteration: 3422; Percent complete: 85.5%; Average loss: 2.7081\n",
            "Returned Loss: 2.7499963365338482\n",
            "Done One Timestep\n",
            "Iteration: 3423; Percent complete: 85.6%; Average loss: 2.7500\n",
            "Returned Loss: 2.92755599831218\n",
            "Done One Timestep\n",
            "Iteration: 3424; Percent complete: 85.6%; Average loss: 2.9276\n",
            "Returned Loss: 2.665321208902667\n",
            "Done One Timestep\n",
            "Iteration: 3425; Percent complete: 85.6%; Average loss: 2.6653\n",
            "Returned Loss: 2.583853196531513\n",
            "Done One Timestep\n",
            "Iteration: 3426; Percent complete: 85.7%; Average loss: 2.5839\n",
            "Returned Loss: 2.7517855662993704\n",
            "Done One Timestep\n",
            "Iteration: 3427; Percent complete: 85.7%; Average loss: 2.7518\n",
            "Returned Loss: 3.066818753571203\n",
            "Done One Timestep\n",
            "Iteration: 3428; Percent complete: 85.7%; Average loss: 3.0668\n",
            "Returned Loss: 2.5895822472644574\n",
            "Done One Timestep\n",
            "Iteration: 3429; Percent complete: 85.7%; Average loss: 2.5896\n",
            "Returned Loss: 2.6962038521055285\n",
            "Done One Timestep\n",
            "Iteration: 3430; Percent complete: 85.8%; Average loss: 2.6962\n",
            "Returned Loss: 2.879481492499458\n",
            "Done One Timestep\n",
            "Iteration: 3431; Percent complete: 85.8%; Average loss: 2.8795\n",
            "Returned Loss: 2.7104003414263964\n",
            "Done One Timestep\n",
            "Iteration: 3432; Percent complete: 85.8%; Average loss: 2.7104\n",
            "Returned Loss: 2.756137248586666\n",
            "Done One Timestep\n",
            "Iteration: 3433; Percent complete: 85.8%; Average loss: 2.7561\n",
            "Returned Loss: 2.5702258148942527\n",
            "Done One Timestep\n",
            "Iteration: 3434; Percent complete: 85.9%; Average loss: 2.5702\n",
            "Returned Loss: 2.7837978152486755\n",
            "Done One Timestep\n",
            "Iteration: 3435; Percent complete: 85.9%; Average loss: 2.7838\n",
            "Returned Loss: 3.1115114337595906\n",
            "Done One Timestep\n",
            "Iteration: 3436; Percent complete: 85.9%; Average loss: 3.1115\n",
            "Returned Loss: 2.7344077351878022\n",
            "Done One Timestep\n",
            "Iteration: 3437; Percent complete: 85.9%; Average loss: 2.7344\n",
            "Returned Loss: 2.4182116605813113\n",
            "Done One Timestep\n",
            "Iteration: 3438; Percent complete: 86.0%; Average loss: 2.4182\n",
            "Returned Loss: 2.7942112841767717\n",
            "Done One Timestep\n",
            "Iteration: 3439; Percent complete: 86.0%; Average loss: 2.7942\n",
            "Returned Loss: 2.9881354722729063\n",
            "Done One Timestep\n",
            "Iteration: 3440; Percent complete: 86.0%; Average loss: 2.9881\n",
            "Returned Loss: 2.7100799280807983\n",
            "Done One Timestep\n",
            "Iteration: 3441; Percent complete: 86.0%; Average loss: 2.7101\n",
            "Returned Loss: 2.4311528373207163\n",
            "Done One Timestep\n",
            "Iteration: 3442; Percent complete: 86.1%; Average loss: 2.4312\n",
            "Returned Loss: 2.670806812054753\n",
            "Done One Timestep\n",
            "Iteration: 3443; Percent complete: 86.1%; Average loss: 2.6708\n",
            "Returned Loss: 2.6325711417730466\n",
            "Done One Timestep\n",
            "Iteration: 3444; Percent complete: 86.1%; Average loss: 2.6326\n",
            "Returned Loss: 2.8421233570728655\n",
            "Done One Timestep\n",
            "Iteration: 3445; Percent complete: 86.1%; Average loss: 2.8421\n",
            "Returned Loss: 2.5546778883528956\n",
            "Done One Timestep\n",
            "Iteration: 3446; Percent complete: 86.2%; Average loss: 2.5547\n",
            "Returned Loss: 2.6494120989079293\n",
            "Done One Timestep\n",
            "Iteration: 3447; Percent complete: 86.2%; Average loss: 2.6494\n",
            "Returned Loss: 2.672090586077669\n",
            "Done One Timestep\n",
            "Iteration: 3448; Percent complete: 86.2%; Average loss: 2.6721\n",
            "Returned Loss: 2.809820377197164\n",
            "Done One Timestep\n",
            "Iteration: 3449; Percent complete: 86.2%; Average loss: 2.8098\n",
            "Returned Loss: 3.1407460166601155\n",
            "Done One Timestep\n",
            "Iteration: 3450; Percent complete: 86.2%; Average loss: 3.1407\n",
            "Returned Loss: 2.79474438731902\n",
            "Done One Timestep\n",
            "Iteration: 3451; Percent complete: 86.3%; Average loss: 2.7947\n",
            "Returned Loss: 2.7017737412198377\n",
            "Done One Timestep\n",
            "Iteration: 3452; Percent complete: 86.3%; Average loss: 2.7018\n",
            "Returned Loss: 2.753754515040563\n",
            "Done One Timestep\n",
            "Iteration: 3453; Percent complete: 86.3%; Average loss: 2.7538\n",
            "Returned Loss: 2.759929747033339\n",
            "Done One Timestep\n",
            "Iteration: 3454; Percent complete: 86.4%; Average loss: 2.7599\n",
            "Returned Loss: 2.624548227897518\n",
            "Done One Timestep\n",
            "Iteration: 3455; Percent complete: 86.4%; Average loss: 2.6245\n",
            "Returned Loss: 2.8092201005798416\n",
            "Done One Timestep\n",
            "Iteration: 3456; Percent complete: 86.4%; Average loss: 2.8092\n",
            "Returned Loss: 2.722141933939958\n",
            "Done One Timestep\n",
            "Iteration: 3457; Percent complete: 86.4%; Average loss: 2.7221\n",
            "Returned Loss: 2.580681819061283\n",
            "Done One Timestep\n",
            "Iteration: 3458; Percent complete: 86.5%; Average loss: 2.5807\n",
            "Returned Loss: 2.5327693031459027\n",
            "Done One Timestep\n",
            "Iteration: 3459; Percent complete: 86.5%; Average loss: 2.5328\n",
            "Returned Loss: 2.773556257760273\n",
            "Done One Timestep\n",
            "Iteration: 3460; Percent complete: 86.5%; Average loss: 2.7736\n",
            "Returned Loss: 2.8258643732785083\n",
            "Done One Timestep\n",
            "Iteration: 3461; Percent complete: 86.5%; Average loss: 2.8259\n",
            "Returned Loss: 2.427085597007371\n",
            "Done One Timestep\n",
            "Iteration: 3462; Percent complete: 86.6%; Average loss: 2.4271\n",
            "Returned Loss: 2.6877131994321686\n",
            "Done One Timestep\n",
            "Iteration: 3463; Percent complete: 86.6%; Average loss: 2.6877\n",
            "Returned Loss: 2.9135435575091058\n",
            "Done One Timestep\n",
            "Iteration: 3464; Percent complete: 86.6%; Average loss: 2.9135\n",
            "Returned Loss: 2.804606813219279\n",
            "Done One Timestep\n",
            "Iteration: 3465; Percent complete: 86.6%; Average loss: 2.8046\n",
            "Returned Loss: 2.874795621010226\n",
            "Done One Timestep\n",
            "Iteration: 3466; Percent complete: 86.7%; Average loss: 2.8748\n",
            "Returned Loss: 2.683282183272817\n",
            "Done One Timestep\n",
            "Iteration: 3467; Percent complete: 86.7%; Average loss: 2.6833\n",
            "Returned Loss: 2.9110539760962246\n",
            "Done One Timestep\n",
            "Iteration: 3468; Percent complete: 86.7%; Average loss: 2.9111\n",
            "Returned Loss: 2.7397765983635813\n",
            "Done One Timestep\n",
            "Iteration: 3469; Percent complete: 86.7%; Average loss: 2.7398\n",
            "Returned Loss: 2.7512960664500805\n",
            "Done One Timestep\n",
            "Iteration: 3470; Percent complete: 86.8%; Average loss: 2.7513\n",
            "Returned Loss: 2.763486409761661\n",
            "Done One Timestep\n",
            "Iteration: 3471; Percent complete: 86.8%; Average loss: 2.7635\n",
            "Returned Loss: 2.663578424417458\n",
            "Done One Timestep\n",
            "Iteration: 3472; Percent complete: 86.8%; Average loss: 2.6636\n",
            "Returned Loss: 2.6024802901111177\n",
            "Done One Timestep\n",
            "Iteration: 3473; Percent complete: 86.8%; Average loss: 2.6025\n",
            "Returned Loss: 2.7292008726474117\n",
            "Done One Timestep\n",
            "Iteration: 3474; Percent complete: 86.9%; Average loss: 2.7292\n",
            "Returned Loss: 2.855130144616181\n",
            "Done One Timestep\n",
            "Iteration: 3475; Percent complete: 86.9%; Average loss: 2.8551\n",
            "Returned Loss: 2.771469421229442\n",
            "Done One Timestep\n",
            "Iteration: 3476; Percent complete: 86.9%; Average loss: 2.7715\n",
            "Returned Loss: 2.596025459323071\n",
            "Done One Timestep\n",
            "Iteration: 3477; Percent complete: 86.9%; Average loss: 2.5960\n",
            "Returned Loss: 2.6132029036437125\n",
            "Done One Timestep\n",
            "Iteration: 3478; Percent complete: 87.0%; Average loss: 2.6132\n",
            "Returned Loss: 2.7295195341930074\n",
            "Done One Timestep\n",
            "Iteration: 3479; Percent complete: 87.0%; Average loss: 2.7295\n",
            "Returned Loss: 2.8367926701016932\n",
            "Done One Timestep\n",
            "Iteration: 3480; Percent complete: 87.0%; Average loss: 2.8368\n",
            "Returned Loss: 2.9831979062693903\n",
            "Done One Timestep\n",
            "Iteration: 3481; Percent complete: 87.0%; Average loss: 2.9832\n",
            "Returned Loss: 2.68775107926563\n",
            "Done One Timestep\n",
            "Iteration: 3482; Percent complete: 87.1%; Average loss: 2.6878\n",
            "Returned Loss: 2.7594244227434874\n",
            "Done One Timestep\n",
            "Iteration: 3483; Percent complete: 87.1%; Average loss: 2.7594\n",
            "Returned Loss: 2.4075781509032375\n",
            "Done One Timestep\n",
            "Iteration: 3484; Percent complete: 87.1%; Average loss: 2.4076\n",
            "Returned Loss: 2.734976893434798\n",
            "Done One Timestep\n",
            "Iteration: 3485; Percent complete: 87.1%; Average loss: 2.7350\n",
            "Returned Loss: 2.5854293434808677\n",
            "Done One Timestep\n",
            "Iteration: 3486; Percent complete: 87.2%; Average loss: 2.5854\n",
            "Returned Loss: 2.5769661987993673\n",
            "Done One Timestep\n",
            "Iteration: 3487; Percent complete: 87.2%; Average loss: 2.5770\n",
            "Returned Loss: 2.7183392476143413\n",
            "Done One Timestep\n",
            "Iteration: 3488; Percent complete: 87.2%; Average loss: 2.7183\n",
            "Returned Loss: 2.77292741293425\n",
            "Done One Timestep\n",
            "Iteration: 3489; Percent complete: 87.2%; Average loss: 2.7729\n",
            "Returned Loss: 2.941568387383864\n",
            "Done One Timestep\n",
            "Iteration: 3490; Percent complete: 87.2%; Average loss: 2.9416\n",
            "Returned Loss: 2.6232762986137796\n",
            "Done One Timestep\n",
            "Iteration: 3491; Percent complete: 87.3%; Average loss: 2.6233\n",
            "Returned Loss: 2.745513277837182\n",
            "Done One Timestep\n",
            "Iteration: 3492; Percent complete: 87.3%; Average loss: 2.7455\n",
            "Returned Loss: 3.014667880624541\n",
            "Done One Timestep\n",
            "Iteration: 3493; Percent complete: 87.3%; Average loss: 3.0147\n",
            "Returned Loss: 2.761821595859476\n",
            "Done One Timestep\n",
            "Iteration: 3494; Percent complete: 87.4%; Average loss: 2.7618\n",
            "Returned Loss: 2.7229136136629415\n",
            "Done One Timestep\n",
            "Iteration: 3495; Percent complete: 87.4%; Average loss: 2.7229\n",
            "Returned Loss: 2.71914556298898\n",
            "Done One Timestep\n",
            "Iteration: 3496; Percent complete: 87.4%; Average loss: 2.7191\n",
            "Returned Loss: 2.7393271010797804\n",
            "Done One Timestep\n",
            "Iteration: 3497; Percent complete: 87.4%; Average loss: 2.7393\n",
            "Returned Loss: 3.040788393225504\n",
            "Done One Timestep\n",
            "Iteration: 3498; Percent complete: 87.5%; Average loss: 3.0408\n",
            "Returned Loss: 2.7313497798786184\n",
            "Done One Timestep\n",
            "Iteration: 3499; Percent complete: 87.5%; Average loss: 2.7313\n",
            "Returned Loss: 2.8138228130905407\n",
            "Done One Timestep\n",
            "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.8138\n",
            "Returned Loss: 2.8242629542781974\n",
            "Done One Timestep\n",
            "Iteration: 3501; Percent complete: 87.5%; Average loss: 2.8243\n",
            "Returned Loss: 2.7421149930527693\n",
            "Done One Timestep\n",
            "Iteration: 3502; Percent complete: 87.5%; Average loss: 2.7421\n",
            "Returned Loss: 2.688145544365506\n",
            "Done One Timestep\n",
            "Iteration: 3503; Percent complete: 87.6%; Average loss: 2.6881\n",
            "Returned Loss: 2.676510143037452\n",
            "Done One Timestep\n",
            "Iteration: 3504; Percent complete: 87.6%; Average loss: 2.6765\n",
            "Returned Loss: 2.8043691139047344\n",
            "Done One Timestep\n",
            "Iteration: 3505; Percent complete: 87.6%; Average loss: 2.8044\n",
            "Returned Loss: 2.847610227940872\n",
            "Done One Timestep\n",
            "Iteration: 3506; Percent complete: 87.6%; Average loss: 2.8476\n",
            "Returned Loss: 2.9288270945530295\n",
            "Done One Timestep\n",
            "Iteration: 3507; Percent complete: 87.7%; Average loss: 2.9288\n",
            "Returned Loss: 2.8226719004808416\n",
            "Done One Timestep\n",
            "Iteration: 3508; Percent complete: 87.7%; Average loss: 2.8227\n",
            "Returned Loss: 2.8369755009903934\n",
            "Done One Timestep\n",
            "Iteration: 3509; Percent complete: 87.7%; Average loss: 2.8370\n",
            "Returned Loss: 2.8321925185639456\n",
            "Done One Timestep\n",
            "Iteration: 3510; Percent complete: 87.8%; Average loss: 2.8322\n",
            "Returned Loss: 2.6849000546598325\n",
            "Done One Timestep\n",
            "Iteration: 3511; Percent complete: 87.8%; Average loss: 2.6849\n",
            "Returned Loss: 2.5973763630293045\n",
            "Done One Timestep\n",
            "Iteration: 3512; Percent complete: 87.8%; Average loss: 2.5974\n",
            "Returned Loss: 2.749030513935379\n",
            "Done One Timestep\n",
            "Iteration: 3513; Percent complete: 87.8%; Average loss: 2.7490\n",
            "Returned Loss: 2.8115972779082634\n",
            "Done One Timestep\n",
            "Iteration: 3514; Percent complete: 87.8%; Average loss: 2.8116\n",
            "Returned Loss: 2.7460947319582742\n",
            "Done One Timestep\n",
            "Iteration: 3515; Percent complete: 87.9%; Average loss: 2.7461\n",
            "Returned Loss: 2.642800798071474\n",
            "Done One Timestep\n",
            "Iteration: 3516; Percent complete: 87.9%; Average loss: 2.6428\n",
            "Returned Loss: 2.829071009768006\n",
            "Done One Timestep\n",
            "Iteration: 3517; Percent complete: 87.9%; Average loss: 2.8291\n",
            "Returned Loss: 2.7447484289599795\n",
            "Done One Timestep\n",
            "Iteration: 3518; Percent complete: 87.9%; Average loss: 2.7447\n",
            "Returned Loss: 2.5872030105886017\n",
            "Done One Timestep\n",
            "Iteration: 3519; Percent complete: 88.0%; Average loss: 2.5872\n",
            "Returned Loss: 2.807625653707906\n",
            "Done One Timestep\n",
            "Iteration: 3520; Percent complete: 88.0%; Average loss: 2.8076\n",
            "Returned Loss: 2.7560813311225862\n",
            "Done One Timestep\n",
            "Iteration: 3521; Percent complete: 88.0%; Average loss: 2.7561\n",
            "Returned Loss: 2.8561233084275823\n",
            "Done One Timestep\n",
            "Iteration: 3522; Percent complete: 88.0%; Average loss: 2.8561\n",
            "Returned Loss: 3.0212322237871048\n",
            "Done One Timestep\n",
            "Iteration: 3523; Percent complete: 88.1%; Average loss: 3.0212\n",
            "Returned Loss: 2.880827460741298\n",
            "Done One Timestep\n",
            "Iteration: 3524; Percent complete: 88.1%; Average loss: 2.8808\n",
            "Returned Loss: 2.580503729628399\n",
            "Done One Timestep\n",
            "Iteration: 3525; Percent complete: 88.1%; Average loss: 2.5805\n",
            "Returned Loss: 2.894451743663302\n",
            "Done One Timestep\n",
            "Iteration: 3526; Percent complete: 88.1%; Average loss: 2.8945\n",
            "Returned Loss: 2.5007080470603746\n",
            "Done One Timestep\n",
            "Iteration: 3527; Percent complete: 88.2%; Average loss: 2.5007\n",
            "Returned Loss: 2.5926809127659314\n",
            "Done One Timestep\n",
            "Iteration: 3528; Percent complete: 88.2%; Average loss: 2.5927\n",
            "Returned Loss: 2.5937756612820073\n",
            "Done One Timestep\n",
            "Iteration: 3529; Percent complete: 88.2%; Average loss: 2.5938\n",
            "Returned Loss: 2.854671915061772\n",
            "Done One Timestep\n",
            "Iteration: 3530; Percent complete: 88.2%; Average loss: 2.8547\n",
            "Returned Loss: 2.7704351110572834\n",
            "Done One Timestep\n",
            "Iteration: 3531; Percent complete: 88.3%; Average loss: 2.7704\n",
            "Returned Loss: 2.7859444114642264\n",
            "Done One Timestep\n",
            "Iteration: 3532; Percent complete: 88.3%; Average loss: 2.7859\n",
            "Returned Loss: 2.644044198993305\n",
            "Done One Timestep\n",
            "Iteration: 3533; Percent complete: 88.3%; Average loss: 2.6440\n",
            "Returned Loss: 2.8069815188340765\n",
            "Done One Timestep\n",
            "Iteration: 3534; Percent complete: 88.3%; Average loss: 2.8070\n",
            "Returned Loss: 2.8059829862794174\n",
            "Done One Timestep\n",
            "Iteration: 3535; Percent complete: 88.4%; Average loss: 2.8060\n",
            "Returned Loss: 2.748384270610602\n",
            "Done One Timestep\n",
            "Iteration: 3536; Percent complete: 88.4%; Average loss: 2.7484\n",
            "Returned Loss: 2.5352427107504907\n",
            "Done One Timestep\n",
            "Iteration: 3537; Percent complete: 88.4%; Average loss: 2.5352\n",
            "Returned Loss: 2.847427858106991\n",
            "Done One Timestep\n",
            "Iteration: 3538; Percent complete: 88.4%; Average loss: 2.8474\n",
            "Returned Loss: 2.970872176431508\n",
            "Done One Timestep\n",
            "Iteration: 3539; Percent complete: 88.5%; Average loss: 2.9709\n",
            "Returned Loss: 2.795394525128599\n",
            "Done One Timestep\n",
            "Iteration: 3540; Percent complete: 88.5%; Average loss: 2.7954\n",
            "Returned Loss: 2.502303420926796\n",
            "Done One Timestep\n",
            "Iteration: 3541; Percent complete: 88.5%; Average loss: 2.5023\n",
            "Returned Loss: 2.4859011026895437\n",
            "Done One Timestep\n",
            "Iteration: 3542; Percent complete: 88.5%; Average loss: 2.4859\n",
            "Returned Loss: 2.8352479502269277\n",
            "Done One Timestep\n",
            "Iteration: 3543; Percent complete: 88.6%; Average loss: 2.8352\n",
            "Returned Loss: 2.8278931295598526\n",
            "Done One Timestep\n",
            "Iteration: 3544; Percent complete: 88.6%; Average loss: 2.8279\n",
            "Returned Loss: 2.5872986045823216\n",
            "Done One Timestep\n",
            "Iteration: 3545; Percent complete: 88.6%; Average loss: 2.5873\n",
            "Returned Loss: 2.624318926397765\n",
            "Done One Timestep\n",
            "Iteration: 3546; Percent complete: 88.6%; Average loss: 2.6243\n",
            "Returned Loss: 2.573454498455622\n",
            "Done One Timestep\n",
            "Iteration: 3547; Percent complete: 88.7%; Average loss: 2.5735\n",
            "Returned Loss: 2.7774470915760134\n",
            "Done One Timestep\n",
            "Iteration: 3548; Percent complete: 88.7%; Average loss: 2.7774\n",
            "Returned Loss: 2.6963341654391297\n",
            "Done One Timestep\n",
            "Iteration: 3549; Percent complete: 88.7%; Average loss: 2.6963\n",
            "Returned Loss: 2.6825315351399563\n",
            "Done One Timestep\n",
            "Iteration: 3550; Percent complete: 88.8%; Average loss: 2.6825\n",
            "Returned Loss: 2.7126147680637493\n",
            "Done One Timestep\n",
            "Iteration: 3551; Percent complete: 88.8%; Average loss: 2.7126\n",
            "Returned Loss: 2.5844867261070195\n",
            "Done One Timestep\n",
            "Iteration: 3552; Percent complete: 88.8%; Average loss: 2.5845\n",
            "Returned Loss: 2.561059789663834\n",
            "Done One Timestep\n",
            "Iteration: 3553; Percent complete: 88.8%; Average loss: 2.5611\n",
            "Returned Loss: 2.720730666074434\n",
            "Done One Timestep\n",
            "Iteration: 3554; Percent complete: 88.8%; Average loss: 2.7207\n",
            "Returned Loss: 2.8121248937848518\n",
            "Done One Timestep\n",
            "Iteration: 3555; Percent complete: 88.9%; Average loss: 2.8121\n",
            "Returned Loss: 2.6455352427070586\n",
            "Done One Timestep\n",
            "Iteration: 3556; Percent complete: 88.9%; Average loss: 2.6455\n",
            "Returned Loss: 2.8541342084218053\n",
            "Done One Timestep\n",
            "Iteration: 3557; Percent complete: 88.9%; Average loss: 2.8541\n",
            "Returned Loss: 2.702535455402337\n",
            "Done One Timestep\n",
            "Iteration: 3558; Percent complete: 88.9%; Average loss: 2.7025\n",
            "Returned Loss: 2.647682206344125\n",
            "Done One Timestep\n",
            "Iteration: 3559; Percent complete: 89.0%; Average loss: 2.6477\n",
            "Returned Loss: 2.8502942976675514\n",
            "Done One Timestep\n",
            "Iteration: 3560; Percent complete: 89.0%; Average loss: 2.8503\n",
            "Returned Loss: 2.6951814963597887\n",
            "Done One Timestep\n",
            "Iteration: 3561; Percent complete: 89.0%; Average loss: 2.6952\n",
            "Returned Loss: 2.938697581287001\n",
            "Done One Timestep\n",
            "Iteration: 3562; Percent complete: 89.0%; Average loss: 2.9387\n",
            "Returned Loss: 2.617297991836334\n",
            "Done One Timestep\n",
            "Iteration: 3563; Percent complete: 89.1%; Average loss: 2.6173\n",
            "Returned Loss: 2.7245159266767827\n",
            "Done One Timestep\n",
            "Iteration: 3564; Percent complete: 89.1%; Average loss: 2.7245\n",
            "Returned Loss: 2.7261108972959462\n",
            "Done One Timestep\n",
            "Iteration: 3565; Percent complete: 89.1%; Average loss: 2.7261\n",
            "Returned Loss: 2.6280170579251094\n",
            "Done One Timestep\n",
            "Iteration: 3566; Percent complete: 89.1%; Average loss: 2.6280\n",
            "Returned Loss: 2.775819794487028\n",
            "Done One Timestep\n",
            "Iteration: 3567; Percent complete: 89.2%; Average loss: 2.7758\n",
            "Returned Loss: 2.626690217779543\n",
            "Done One Timestep\n",
            "Iteration: 3568; Percent complete: 89.2%; Average loss: 2.6267\n",
            "Returned Loss: 2.8004881686474903\n",
            "Done One Timestep\n",
            "Iteration: 3569; Percent complete: 89.2%; Average loss: 2.8005\n",
            "Returned Loss: 2.670453823942842\n",
            "Done One Timestep\n",
            "Iteration: 3570; Percent complete: 89.2%; Average loss: 2.6705\n",
            "Returned Loss: 2.883401173341855\n",
            "Done One Timestep\n",
            "Iteration: 3571; Percent complete: 89.3%; Average loss: 2.8834\n",
            "Returned Loss: 2.814690920304626\n",
            "Done One Timestep\n",
            "Iteration: 3572; Percent complete: 89.3%; Average loss: 2.8147\n",
            "Returned Loss: 2.802987768644528\n",
            "Done One Timestep\n",
            "Iteration: 3573; Percent complete: 89.3%; Average loss: 2.8030\n",
            "Returned Loss: 2.6915423659052413\n",
            "Done One Timestep\n",
            "Iteration: 3574; Percent complete: 89.3%; Average loss: 2.6915\n",
            "Returned Loss: 2.8394733132440964\n",
            "Done One Timestep\n",
            "Iteration: 3575; Percent complete: 89.4%; Average loss: 2.8395\n",
            "Returned Loss: 2.7625518592862734\n",
            "Done One Timestep\n",
            "Iteration: 3576; Percent complete: 89.4%; Average loss: 2.7626\n",
            "Returned Loss: 2.840977501323485\n",
            "Done One Timestep\n",
            "Iteration: 3577; Percent complete: 89.4%; Average loss: 2.8410\n",
            "Returned Loss: 2.6544778184684916\n",
            "Done One Timestep\n",
            "Iteration: 3578; Percent complete: 89.5%; Average loss: 2.6545\n",
            "Returned Loss: 2.6687482304439913\n",
            "Done One Timestep\n",
            "Iteration: 3579; Percent complete: 89.5%; Average loss: 2.6687\n",
            "Returned Loss: 2.7075975799918486\n",
            "Done One Timestep\n",
            "Iteration: 3580; Percent complete: 89.5%; Average loss: 2.7076\n",
            "Returned Loss: 2.9754672445248636\n",
            "Done One Timestep\n",
            "Iteration: 3581; Percent complete: 89.5%; Average loss: 2.9755\n",
            "Returned Loss: 2.765651487598535\n",
            "Done One Timestep\n",
            "Iteration: 3582; Percent complete: 89.5%; Average loss: 2.7657\n",
            "Returned Loss: 2.639691365112401\n",
            "Done One Timestep\n",
            "Iteration: 3583; Percent complete: 89.6%; Average loss: 2.6397\n",
            "Returned Loss: 2.8299118876023033\n",
            "Done One Timestep\n",
            "Iteration: 3584; Percent complete: 89.6%; Average loss: 2.8299\n",
            "Returned Loss: 2.600991033520737\n",
            "Done One Timestep\n",
            "Iteration: 3585; Percent complete: 89.6%; Average loss: 2.6010\n",
            "Returned Loss: 2.683648007111736\n",
            "Done One Timestep\n",
            "Iteration: 3586; Percent complete: 89.6%; Average loss: 2.6836\n",
            "Returned Loss: 2.7307137123636163\n",
            "Done One Timestep\n",
            "Iteration: 3587; Percent complete: 89.7%; Average loss: 2.7307\n",
            "Returned Loss: 2.6296291182353344\n",
            "Done One Timestep\n",
            "Iteration: 3588; Percent complete: 89.7%; Average loss: 2.6296\n",
            "Returned Loss: 2.72487950604409\n",
            "Done One Timestep\n",
            "Iteration: 3589; Percent complete: 89.7%; Average loss: 2.7249\n",
            "Returned Loss: 2.7998256656226146\n",
            "Done One Timestep\n",
            "Iteration: 3590; Percent complete: 89.8%; Average loss: 2.7998\n",
            "Returned Loss: 2.9769076349371186\n",
            "Done One Timestep\n",
            "Iteration: 3591; Percent complete: 89.8%; Average loss: 2.9769\n",
            "Returned Loss: 2.5294936183368497\n",
            "Done One Timestep\n",
            "Iteration: 3592; Percent complete: 89.8%; Average loss: 2.5295\n",
            "Returned Loss: 2.7641599328226336\n",
            "Done One Timestep\n",
            "Iteration: 3593; Percent complete: 89.8%; Average loss: 2.7642\n",
            "Returned Loss: 2.7496071613520083\n",
            "Done One Timestep\n",
            "Iteration: 3594; Percent complete: 89.8%; Average loss: 2.7496\n",
            "Returned Loss: 2.7251413033839293\n",
            "Done One Timestep\n",
            "Iteration: 3595; Percent complete: 89.9%; Average loss: 2.7251\n",
            "Returned Loss: 2.712260411853473\n",
            "Done One Timestep\n",
            "Iteration: 3596; Percent complete: 89.9%; Average loss: 2.7123\n",
            "Returned Loss: 2.8162925124301856\n",
            "Done One Timestep\n",
            "Iteration: 3597; Percent complete: 89.9%; Average loss: 2.8163\n",
            "Returned Loss: 2.5827898504088096\n",
            "Done One Timestep\n",
            "Iteration: 3598; Percent complete: 90.0%; Average loss: 2.5828\n",
            "Returned Loss: 2.697978070448214\n",
            "Done One Timestep\n",
            "Iteration: 3599; Percent complete: 90.0%; Average loss: 2.6980\n",
            "Returned Loss: 2.598029345979846\n",
            "Done One Timestep\n",
            "Iteration: 3600; Percent complete: 90.0%; Average loss: 2.5980\n",
            "Returned Loss: 2.7168516817808444\n",
            "Done One Timestep\n",
            "Iteration: 3601; Percent complete: 90.0%; Average loss: 2.7169\n",
            "Returned Loss: 2.7870442735781276\n",
            "Done One Timestep\n",
            "Iteration: 3602; Percent complete: 90.0%; Average loss: 2.7870\n",
            "Returned Loss: 2.903997242337078\n",
            "Done One Timestep\n",
            "Iteration: 3603; Percent complete: 90.1%; Average loss: 2.9040\n",
            "Returned Loss: 2.5597193058520715\n",
            "Done One Timestep\n",
            "Iteration: 3604; Percent complete: 90.1%; Average loss: 2.5597\n",
            "Returned Loss: 2.8302623726488734\n",
            "Done One Timestep\n",
            "Iteration: 3605; Percent complete: 90.1%; Average loss: 2.8303\n",
            "Returned Loss: 2.75395114420811\n",
            "Done One Timestep\n",
            "Iteration: 3606; Percent complete: 90.1%; Average loss: 2.7540\n",
            "Returned Loss: 2.706802849445095\n",
            "Done One Timestep\n",
            "Iteration: 3607; Percent complete: 90.2%; Average loss: 2.7068\n",
            "Returned Loss: 2.77668691477914\n",
            "Done One Timestep\n",
            "Iteration: 3608; Percent complete: 90.2%; Average loss: 2.7767\n",
            "Returned Loss: 2.898978745860441\n",
            "Done One Timestep\n",
            "Iteration: 3609; Percent complete: 90.2%; Average loss: 2.8990\n",
            "Returned Loss: 2.759632522666946\n",
            "Done One Timestep\n",
            "Iteration: 3610; Percent complete: 90.2%; Average loss: 2.7596\n",
            "Returned Loss: 2.73576438518797\n",
            "Done One Timestep\n",
            "Iteration: 3611; Percent complete: 90.3%; Average loss: 2.7358\n",
            "Returned Loss: 2.624301794735367\n",
            "Done One Timestep\n",
            "Iteration: 3612; Percent complete: 90.3%; Average loss: 2.6243\n",
            "Returned Loss: 2.819167794744186\n",
            "Done One Timestep\n",
            "Iteration: 3613; Percent complete: 90.3%; Average loss: 2.8192\n",
            "Returned Loss: 2.821648857268853\n",
            "Done One Timestep\n",
            "Iteration: 3614; Percent complete: 90.3%; Average loss: 2.8216\n",
            "Returned Loss: 2.766722483446867\n",
            "Done One Timestep\n",
            "Iteration: 3615; Percent complete: 90.4%; Average loss: 2.7667\n",
            "Returned Loss: 2.6278008895542007\n",
            "Done One Timestep\n",
            "Iteration: 3616; Percent complete: 90.4%; Average loss: 2.6278\n",
            "Returned Loss: 2.705702419509748\n",
            "Done One Timestep\n",
            "Iteration: 3617; Percent complete: 90.4%; Average loss: 2.7057\n",
            "Returned Loss: 2.876192384935401\n",
            "Done One Timestep\n",
            "Iteration: 3618; Percent complete: 90.5%; Average loss: 2.8762\n",
            "Returned Loss: 2.6240790606866256\n",
            "Done One Timestep\n",
            "Iteration: 3619; Percent complete: 90.5%; Average loss: 2.6241\n",
            "Returned Loss: 2.77688633017062\n",
            "Done One Timestep\n",
            "Iteration: 3620; Percent complete: 90.5%; Average loss: 2.7769\n",
            "Returned Loss: 2.6885088125445757\n",
            "Done One Timestep\n",
            "Iteration: 3621; Percent complete: 90.5%; Average loss: 2.6885\n",
            "Returned Loss: 2.842300577742579\n",
            "Done One Timestep\n",
            "Iteration: 3622; Percent complete: 90.5%; Average loss: 2.8423\n",
            "Returned Loss: 2.6437210496303907\n",
            "Done One Timestep\n",
            "Iteration: 3623; Percent complete: 90.6%; Average loss: 2.6437\n",
            "Returned Loss: 2.5993956431957392\n",
            "Done One Timestep\n",
            "Iteration: 3624; Percent complete: 90.6%; Average loss: 2.5994\n",
            "Returned Loss: 2.6261110789797124\n",
            "Done One Timestep\n",
            "Iteration: 3625; Percent complete: 90.6%; Average loss: 2.6261\n",
            "Returned Loss: 2.3256578777198165\n",
            "Done One Timestep\n",
            "Iteration: 3626; Percent complete: 90.6%; Average loss: 2.3257\n",
            "Returned Loss: 2.7289045423743103\n",
            "Done One Timestep\n",
            "Iteration: 3627; Percent complete: 90.7%; Average loss: 2.7289\n",
            "Returned Loss: 2.645707518880131\n",
            "Done One Timestep\n",
            "Iteration: 3628; Percent complete: 90.7%; Average loss: 2.6457\n",
            "Returned Loss: 2.669791108704392\n",
            "Done One Timestep\n",
            "Iteration: 3629; Percent complete: 90.7%; Average loss: 2.6698\n",
            "Returned Loss: 2.6032820749553918\n",
            "Done One Timestep\n",
            "Iteration: 3630; Percent complete: 90.8%; Average loss: 2.6033\n",
            "Returned Loss: 2.7317904469495895\n",
            "Done One Timestep\n",
            "Iteration: 3631; Percent complete: 90.8%; Average loss: 2.7318\n",
            "Returned Loss: 2.7644358246222787\n",
            "Done One Timestep\n",
            "Iteration: 3632; Percent complete: 90.8%; Average loss: 2.7644\n",
            "Returned Loss: 2.7553593705778416\n",
            "Done One Timestep\n",
            "Iteration: 3633; Percent complete: 90.8%; Average loss: 2.7554\n",
            "Returned Loss: 2.469932739837018\n",
            "Done One Timestep\n",
            "Iteration: 3634; Percent complete: 90.8%; Average loss: 2.4699\n",
            "Returned Loss: 2.538596103470042\n",
            "Done One Timestep\n",
            "Iteration: 3635; Percent complete: 90.9%; Average loss: 2.5386\n",
            "Returned Loss: 2.742144401709376\n",
            "Done One Timestep\n",
            "Iteration: 3636; Percent complete: 90.9%; Average loss: 2.7421\n",
            "Returned Loss: 2.6802375467825796\n",
            "Done One Timestep\n",
            "Iteration: 3637; Percent complete: 90.9%; Average loss: 2.6802\n",
            "Returned Loss: 2.9377383398982326\n",
            "Done One Timestep\n",
            "Iteration: 3638; Percent complete: 91.0%; Average loss: 2.9377\n",
            "Returned Loss: 2.8488296356733507\n",
            "Done One Timestep\n",
            "Iteration: 3639; Percent complete: 91.0%; Average loss: 2.8488\n",
            "Returned Loss: 2.635087966431383\n",
            "Done One Timestep\n",
            "Iteration: 3640; Percent complete: 91.0%; Average loss: 2.6351\n",
            "Returned Loss: 2.769739902269541\n",
            "Done One Timestep\n",
            "Iteration: 3641; Percent complete: 91.0%; Average loss: 2.7697\n",
            "Returned Loss: 2.7373464642625267\n",
            "Done One Timestep\n",
            "Iteration: 3642; Percent complete: 91.0%; Average loss: 2.7373\n",
            "Returned Loss: 2.711869177489319\n",
            "Done One Timestep\n",
            "Iteration: 3643; Percent complete: 91.1%; Average loss: 2.7119\n",
            "Returned Loss: 2.577242400309979\n",
            "Done One Timestep\n",
            "Iteration: 3644; Percent complete: 91.1%; Average loss: 2.5772\n",
            "Returned Loss: 2.806617089577148\n",
            "Done One Timestep\n",
            "Iteration: 3645; Percent complete: 91.1%; Average loss: 2.8066\n",
            "Returned Loss: 2.6499133502301344\n",
            "Done One Timestep\n",
            "Iteration: 3646; Percent complete: 91.1%; Average loss: 2.6499\n",
            "Returned Loss: 2.7547490364522673\n",
            "Done One Timestep\n",
            "Iteration: 3647; Percent complete: 91.2%; Average loss: 2.7547\n",
            "Returned Loss: 2.872039683552851\n",
            "Done One Timestep\n",
            "Iteration: 3648; Percent complete: 91.2%; Average loss: 2.8720\n",
            "Returned Loss: 2.6414283494473283\n",
            "Done One Timestep\n",
            "Iteration: 3649; Percent complete: 91.2%; Average loss: 2.6414\n",
            "Returned Loss: 2.8638886230533283\n",
            "Done One Timestep\n",
            "Iteration: 3650; Percent complete: 91.2%; Average loss: 2.8639\n",
            "Returned Loss: 2.64895976170225\n",
            "Done One Timestep\n",
            "Iteration: 3651; Percent complete: 91.3%; Average loss: 2.6490\n",
            "Returned Loss: 2.5959156653792945\n",
            "Done One Timestep\n",
            "Iteration: 3652; Percent complete: 91.3%; Average loss: 2.5959\n",
            "Returned Loss: 2.6919511467845147\n",
            "Done One Timestep\n",
            "Iteration: 3653; Percent complete: 91.3%; Average loss: 2.6920\n",
            "Returned Loss: 2.646168560454048\n",
            "Done One Timestep\n",
            "Iteration: 3654; Percent complete: 91.3%; Average loss: 2.6462\n",
            "Returned Loss: 2.7549748398063985\n",
            "Done One Timestep\n",
            "Iteration: 3655; Percent complete: 91.4%; Average loss: 2.7550\n",
            "Returned Loss: 2.782025433736679\n",
            "Done One Timestep\n",
            "Iteration: 3656; Percent complete: 91.4%; Average loss: 2.7820\n",
            "Returned Loss: 2.910056876833853\n",
            "Done One Timestep\n",
            "Iteration: 3657; Percent complete: 91.4%; Average loss: 2.9101\n",
            "Returned Loss: 2.7981707704209287\n",
            "Done One Timestep\n",
            "Iteration: 3658; Percent complete: 91.5%; Average loss: 2.7982\n",
            "Returned Loss: 2.817887914548978\n",
            "Done One Timestep\n",
            "Iteration: 3659; Percent complete: 91.5%; Average loss: 2.8179\n",
            "Returned Loss: 2.690589962606571\n",
            "Done One Timestep\n",
            "Iteration: 3660; Percent complete: 91.5%; Average loss: 2.6906\n",
            "Returned Loss: 2.79812602948996\n",
            "Done One Timestep\n",
            "Iteration: 3661; Percent complete: 91.5%; Average loss: 2.7981\n",
            "Returned Loss: 2.9095078771619733\n",
            "Done One Timestep\n",
            "Iteration: 3662; Percent complete: 91.5%; Average loss: 2.9095\n",
            "Returned Loss: 2.7736275182724763\n",
            "Done One Timestep\n",
            "Iteration: 3663; Percent complete: 91.6%; Average loss: 2.7736\n",
            "Returned Loss: 2.6102422535476193\n",
            "Done One Timestep\n",
            "Iteration: 3664; Percent complete: 91.6%; Average loss: 2.6102\n",
            "Returned Loss: 2.702713136518667\n",
            "Done One Timestep\n",
            "Iteration: 3665; Percent complete: 91.6%; Average loss: 2.7027\n",
            "Returned Loss: 2.616812055875643\n",
            "Done One Timestep\n",
            "Iteration: 3666; Percent complete: 91.6%; Average loss: 2.6168\n",
            "Returned Loss: 2.857170843539275\n",
            "Done One Timestep\n",
            "Iteration: 3667; Percent complete: 91.7%; Average loss: 2.8572\n",
            "Returned Loss: 2.824313395138373\n",
            "Done One Timestep\n",
            "Iteration: 3668; Percent complete: 91.7%; Average loss: 2.8243\n",
            "Returned Loss: 2.5666125402785838\n",
            "Done One Timestep\n",
            "Iteration: 3669; Percent complete: 91.7%; Average loss: 2.5666\n",
            "Returned Loss: 2.7263060936320516\n",
            "Done One Timestep\n",
            "Iteration: 3670; Percent complete: 91.8%; Average loss: 2.7263\n",
            "Returned Loss: 2.9476927469668475\n",
            "Done One Timestep\n",
            "Iteration: 3671; Percent complete: 91.8%; Average loss: 2.9477\n",
            "Returned Loss: 2.636531920477826\n",
            "Done One Timestep\n",
            "Iteration: 3672; Percent complete: 91.8%; Average loss: 2.6365\n",
            "Returned Loss: 2.586891861354532\n",
            "Done One Timestep\n",
            "Iteration: 3673; Percent complete: 91.8%; Average loss: 2.5869\n",
            "Returned Loss: 2.4734137461596535\n",
            "Done One Timestep\n",
            "Iteration: 3674; Percent complete: 91.8%; Average loss: 2.4734\n",
            "Returned Loss: 2.800563615916021\n",
            "Done One Timestep\n",
            "Iteration: 3675; Percent complete: 91.9%; Average loss: 2.8006\n",
            "Returned Loss: 2.5995421617282912\n",
            "Done One Timestep\n",
            "Iteration: 3676; Percent complete: 91.9%; Average loss: 2.5995\n",
            "Returned Loss: 2.5361607419122465\n",
            "Done One Timestep\n",
            "Iteration: 3677; Percent complete: 91.9%; Average loss: 2.5362\n",
            "Returned Loss: 2.3976682232578796\n",
            "Done One Timestep\n",
            "Iteration: 3678; Percent complete: 92.0%; Average loss: 2.3977\n",
            "Returned Loss: 2.7768790371963257\n",
            "Done One Timestep\n",
            "Iteration: 3679; Percent complete: 92.0%; Average loss: 2.7769\n",
            "Returned Loss: 2.805964475250075\n",
            "Done One Timestep\n",
            "Iteration: 3680; Percent complete: 92.0%; Average loss: 2.8060\n",
            "Returned Loss: 2.4240855105752455\n",
            "Done One Timestep\n",
            "Iteration: 3681; Percent complete: 92.0%; Average loss: 2.4241\n",
            "Returned Loss: 2.761374923754938\n",
            "Done One Timestep\n",
            "Iteration: 3682; Percent complete: 92.0%; Average loss: 2.7614\n",
            "Returned Loss: 2.5008746971440385\n",
            "Done One Timestep\n",
            "Iteration: 3683; Percent complete: 92.1%; Average loss: 2.5009\n",
            "Returned Loss: 2.6971398107267897\n",
            "Done One Timestep\n",
            "Iteration: 3684; Percent complete: 92.1%; Average loss: 2.6971\n",
            "Returned Loss: 2.768445525927411\n",
            "Done One Timestep\n",
            "Iteration: 3685; Percent complete: 92.1%; Average loss: 2.7684\n",
            "Returned Loss: 2.547318372915824\n",
            "Done One Timestep\n",
            "Iteration: 3686; Percent complete: 92.2%; Average loss: 2.5473\n",
            "Returned Loss: 2.507189209914661\n",
            "Done One Timestep\n",
            "Iteration: 3687; Percent complete: 92.2%; Average loss: 2.5072\n",
            "Returned Loss: 2.869826219268143\n",
            "Done One Timestep\n",
            "Iteration: 3688; Percent complete: 92.2%; Average loss: 2.8698\n",
            "Returned Loss: 2.66423694808748\n",
            "Done One Timestep\n",
            "Iteration: 3689; Percent complete: 92.2%; Average loss: 2.6642\n",
            "Returned Loss: 2.9221740841307002\n",
            "Done One Timestep\n",
            "Iteration: 3690; Percent complete: 92.2%; Average loss: 2.9222\n",
            "Returned Loss: 2.8314680916667596\n",
            "Done One Timestep\n",
            "Iteration: 3691; Percent complete: 92.3%; Average loss: 2.8315\n",
            "Returned Loss: 2.807218573202204\n",
            "Done One Timestep\n",
            "Iteration: 3692; Percent complete: 92.3%; Average loss: 2.8072\n",
            "Returned Loss: 2.5371775404598513\n",
            "Done One Timestep\n",
            "Iteration: 3693; Percent complete: 92.3%; Average loss: 2.5372\n",
            "Returned Loss: 2.7363526282054558\n",
            "Done One Timestep\n",
            "Iteration: 3694; Percent complete: 92.3%; Average loss: 2.7364\n",
            "Returned Loss: 2.6904683120846196\n",
            "Done One Timestep\n",
            "Iteration: 3695; Percent complete: 92.4%; Average loss: 2.6905\n",
            "Returned Loss: 2.701760062909781\n",
            "Done One Timestep\n",
            "Iteration: 3696; Percent complete: 92.4%; Average loss: 2.7018\n",
            "Returned Loss: 2.604962546091813\n",
            "Done One Timestep\n",
            "Iteration: 3697; Percent complete: 92.4%; Average loss: 2.6050\n",
            "Returned Loss: 2.910296593745566\n",
            "Done One Timestep\n",
            "Iteration: 3698; Percent complete: 92.5%; Average loss: 2.9103\n",
            "Returned Loss: 2.7241041702342983\n",
            "Done One Timestep\n",
            "Iteration: 3699; Percent complete: 92.5%; Average loss: 2.7241\n",
            "Returned Loss: 2.7196656974053686\n",
            "Done One Timestep\n",
            "Iteration: 3700; Percent complete: 92.5%; Average loss: 2.7197\n",
            "Returned Loss: 2.783014254804443\n",
            "Done One Timestep\n",
            "Iteration: 3701; Percent complete: 92.5%; Average loss: 2.7830\n",
            "Returned Loss: 2.6167630211959705\n",
            "Done One Timestep\n",
            "Iteration: 3702; Percent complete: 92.5%; Average loss: 2.6168\n",
            "Returned Loss: 2.653823023513857\n",
            "Done One Timestep\n",
            "Iteration: 3703; Percent complete: 92.6%; Average loss: 2.6538\n",
            "Returned Loss: 2.616413557470419\n",
            "Done One Timestep\n",
            "Iteration: 3704; Percent complete: 92.6%; Average loss: 2.6164\n",
            "Returned Loss: 2.589996730098501\n",
            "Done One Timestep\n",
            "Iteration: 3705; Percent complete: 92.6%; Average loss: 2.5900\n",
            "Returned Loss: 2.9070133260681295\n",
            "Done One Timestep\n",
            "Iteration: 3706; Percent complete: 92.7%; Average loss: 2.9070\n",
            "Returned Loss: 2.6528492769806755\n",
            "Done One Timestep\n",
            "Iteration: 3707; Percent complete: 92.7%; Average loss: 2.6528\n",
            "Returned Loss: 2.6616216118732656\n",
            "Done One Timestep\n",
            "Iteration: 3708; Percent complete: 92.7%; Average loss: 2.6616\n",
            "Returned Loss: 2.579996931093608\n",
            "Done One Timestep\n",
            "Iteration: 3709; Percent complete: 92.7%; Average loss: 2.5800\n",
            "Returned Loss: 2.694343249765465\n",
            "Done One Timestep\n",
            "Iteration: 3710; Percent complete: 92.8%; Average loss: 2.6943\n",
            "Returned Loss: 2.552872513438081\n",
            "Done One Timestep\n",
            "Iteration: 3711; Percent complete: 92.8%; Average loss: 2.5529\n",
            "Returned Loss: 2.665821885713661\n",
            "Done One Timestep\n",
            "Iteration: 3712; Percent complete: 92.8%; Average loss: 2.6658\n",
            "Returned Loss: 2.640561541569975\n",
            "Done One Timestep\n",
            "Iteration: 3713; Percent complete: 92.8%; Average loss: 2.6406\n",
            "Returned Loss: 2.54964462900631\n",
            "Done One Timestep\n",
            "Iteration: 3714; Percent complete: 92.8%; Average loss: 2.5496\n",
            "Returned Loss: 2.7555568350428543\n",
            "Done One Timestep\n",
            "Iteration: 3715; Percent complete: 92.9%; Average loss: 2.7556\n",
            "Returned Loss: 2.5126093023185\n",
            "Done One Timestep\n",
            "Iteration: 3716; Percent complete: 92.9%; Average loss: 2.5126\n",
            "Returned Loss: 2.5981857723221617\n",
            "Done One Timestep\n",
            "Iteration: 3717; Percent complete: 92.9%; Average loss: 2.5982\n",
            "Returned Loss: 2.7300829063104137\n",
            "Done One Timestep\n",
            "Iteration: 3718; Percent complete: 93.0%; Average loss: 2.7301\n",
            "Returned Loss: 2.613724089639958\n",
            "Done One Timestep\n",
            "Iteration: 3719; Percent complete: 93.0%; Average loss: 2.6137\n",
            "Returned Loss: 2.8679956195737017\n",
            "Done One Timestep\n",
            "Iteration: 3720; Percent complete: 93.0%; Average loss: 2.8680\n",
            "Returned Loss: 2.5192581701147208\n",
            "Done One Timestep\n",
            "Iteration: 3721; Percent complete: 93.0%; Average loss: 2.5193\n",
            "Returned Loss: 2.6720656649319126\n",
            "Done One Timestep\n",
            "Iteration: 3722; Percent complete: 93.0%; Average loss: 2.6721\n",
            "Returned Loss: 2.717461123604115\n",
            "Done One Timestep\n",
            "Iteration: 3723; Percent complete: 93.1%; Average loss: 2.7175\n",
            "Returned Loss: 2.7867818341108\n",
            "Done One Timestep\n",
            "Iteration: 3724; Percent complete: 93.1%; Average loss: 2.7868\n",
            "Returned Loss: 2.6852271839900133\n",
            "Done One Timestep\n",
            "Iteration: 3725; Percent complete: 93.1%; Average loss: 2.6852\n",
            "Returned Loss: 2.779767829748032\n",
            "Done One Timestep\n",
            "Iteration: 3726; Percent complete: 93.2%; Average loss: 2.7798\n",
            "Returned Loss: 2.9166615776159817\n",
            "Done One Timestep\n",
            "Iteration: 3727; Percent complete: 93.2%; Average loss: 2.9167\n",
            "Returned Loss: 2.6195626035154436\n",
            "Done One Timestep\n",
            "Iteration: 3728; Percent complete: 93.2%; Average loss: 2.6196\n",
            "Returned Loss: 2.6989578273871224\n",
            "Done One Timestep\n",
            "Iteration: 3729; Percent complete: 93.2%; Average loss: 2.6990\n",
            "Returned Loss: 2.723831344527656\n",
            "Done One Timestep\n",
            "Iteration: 3730; Percent complete: 93.2%; Average loss: 2.7238\n",
            "Returned Loss: 2.70605704274795\n",
            "Done One Timestep\n",
            "Iteration: 3731; Percent complete: 93.3%; Average loss: 2.7061\n",
            "Returned Loss: 2.6241551596772275\n",
            "Done One Timestep\n",
            "Iteration: 3732; Percent complete: 93.3%; Average loss: 2.6242\n",
            "Returned Loss: 2.615443185159217\n",
            "Done One Timestep\n",
            "Iteration: 3733; Percent complete: 93.3%; Average loss: 2.6154\n",
            "Returned Loss: 2.8246203186067276\n",
            "Done One Timestep\n",
            "Iteration: 3734; Percent complete: 93.3%; Average loss: 2.8246\n",
            "Returned Loss: 2.507849334368864\n",
            "Done One Timestep\n",
            "Iteration: 3735; Percent complete: 93.4%; Average loss: 2.5078\n",
            "Returned Loss: 2.366433712967631\n",
            "Done One Timestep\n",
            "Iteration: 3736; Percent complete: 93.4%; Average loss: 2.3664\n",
            "Returned Loss: 2.816604749602237\n",
            "Done One Timestep\n",
            "Iteration: 3737; Percent complete: 93.4%; Average loss: 2.8166\n",
            "Returned Loss: 2.8571549841848425\n",
            "Done One Timestep\n",
            "Iteration: 3738; Percent complete: 93.5%; Average loss: 2.8572\n",
            "Returned Loss: 2.9173485912991812\n",
            "Done One Timestep\n",
            "Iteration: 3739; Percent complete: 93.5%; Average loss: 2.9173\n",
            "Returned Loss: 2.592495142716866\n",
            "Done One Timestep\n",
            "Iteration: 3740; Percent complete: 93.5%; Average loss: 2.5925\n",
            "Returned Loss: 2.764151076838031\n",
            "Done One Timestep\n",
            "Iteration: 3741; Percent complete: 93.5%; Average loss: 2.7642\n",
            "Returned Loss: 2.451116197307243\n",
            "Done One Timestep\n",
            "Iteration: 3742; Percent complete: 93.5%; Average loss: 2.4511\n",
            "Returned Loss: 2.7165563736130767\n",
            "Done One Timestep\n",
            "Iteration: 3743; Percent complete: 93.6%; Average loss: 2.7166\n",
            "Returned Loss: 2.7426070443012733\n",
            "Done One Timestep\n",
            "Iteration: 3744; Percent complete: 93.6%; Average loss: 2.7426\n",
            "Returned Loss: 2.761430566679586\n",
            "Done One Timestep\n",
            "Iteration: 3745; Percent complete: 93.6%; Average loss: 2.7614\n",
            "Returned Loss: 2.980623787880814\n",
            "Done One Timestep\n",
            "Iteration: 3746; Percent complete: 93.7%; Average loss: 2.9806\n",
            "Returned Loss: 2.571506066111315\n",
            "Done One Timestep\n",
            "Iteration: 3747; Percent complete: 93.7%; Average loss: 2.5715\n",
            "Returned Loss: 2.720322622659523\n",
            "Done One Timestep\n",
            "Iteration: 3748; Percent complete: 93.7%; Average loss: 2.7203\n",
            "Returned Loss: 2.5647948140213073\n",
            "Done One Timestep\n",
            "Iteration: 3749; Percent complete: 93.7%; Average loss: 2.5648\n",
            "Returned Loss: 2.6843954905275913\n",
            "Done One Timestep\n",
            "Iteration: 3750; Percent complete: 93.8%; Average loss: 2.6844\n",
            "Returned Loss: 2.830763483803263\n",
            "Done One Timestep\n",
            "Iteration: 3751; Percent complete: 93.8%; Average loss: 2.8308\n",
            "Returned Loss: 2.825272713432891\n",
            "Done One Timestep\n",
            "Iteration: 3752; Percent complete: 93.8%; Average loss: 2.8253\n",
            "Returned Loss: 2.4089043347617998\n",
            "Done One Timestep\n",
            "Iteration: 3753; Percent complete: 93.8%; Average loss: 2.4089\n",
            "Returned Loss: 2.566839129883003\n",
            "Done One Timestep\n",
            "Iteration: 3754; Percent complete: 93.8%; Average loss: 2.5668\n",
            "Returned Loss: 2.6453330132170088\n",
            "Done One Timestep\n",
            "Iteration: 3755; Percent complete: 93.9%; Average loss: 2.6453\n",
            "Returned Loss: 2.585497921295897\n",
            "Done One Timestep\n",
            "Iteration: 3756; Percent complete: 93.9%; Average loss: 2.5855\n",
            "Returned Loss: 2.7500679257847667\n",
            "Done One Timestep\n",
            "Iteration: 3757; Percent complete: 93.9%; Average loss: 2.7501\n",
            "Returned Loss: 2.6728033175049135\n",
            "Done One Timestep\n",
            "Iteration: 3758; Percent complete: 94.0%; Average loss: 2.6728\n",
            "Returned Loss: 2.7743880372079586\n",
            "Done One Timestep\n",
            "Iteration: 3759; Percent complete: 94.0%; Average loss: 2.7744\n",
            "Returned Loss: 2.6087786396435177\n",
            "Done One Timestep\n",
            "Iteration: 3760; Percent complete: 94.0%; Average loss: 2.6088\n",
            "Returned Loss: 2.620416949734037\n",
            "Done One Timestep\n",
            "Iteration: 3761; Percent complete: 94.0%; Average loss: 2.6204\n",
            "Returned Loss: 2.722294105615001\n",
            "Done One Timestep\n",
            "Iteration: 3762; Percent complete: 94.0%; Average loss: 2.7223\n",
            "Returned Loss: 2.735770897513329\n",
            "Done One Timestep\n",
            "Iteration: 3763; Percent complete: 94.1%; Average loss: 2.7358\n",
            "Returned Loss: 2.688563806576063\n",
            "Done One Timestep\n",
            "Iteration: 3764; Percent complete: 94.1%; Average loss: 2.6886\n",
            "Returned Loss: 2.457263576676123\n",
            "Done One Timestep\n",
            "Iteration: 3765; Percent complete: 94.1%; Average loss: 2.4573\n",
            "Returned Loss: 2.710062238046475\n",
            "Done One Timestep\n",
            "Iteration: 3766; Percent complete: 94.2%; Average loss: 2.7101\n",
            "Returned Loss: 2.5507919438415545\n",
            "Done One Timestep\n",
            "Iteration: 3767; Percent complete: 94.2%; Average loss: 2.5508\n",
            "Returned Loss: 2.6918050393156245\n",
            "Done One Timestep\n",
            "Iteration: 3768; Percent complete: 94.2%; Average loss: 2.6918\n",
            "Returned Loss: 2.8204931585302497\n",
            "Done One Timestep\n",
            "Iteration: 3769; Percent complete: 94.2%; Average loss: 2.8205\n",
            "Returned Loss: 2.574082874565148\n",
            "Done One Timestep\n",
            "Iteration: 3770; Percent complete: 94.2%; Average loss: 2.5741\n",
            "Returned Loss: 2.660645284675561\n",
            "Done One Timestep\n",
            "Iteration: 3771; Percent complete: 94.3%; Average loss: 2.6606\n",
            "Returned Loss: 2.4960409336250704\n",
            "Done One Timestep\n",
            "Iteration: 3772; Percent complete: 94.3%; Average loss: 2.4960\n",
            "Returned Loss: 2.4272263259673723\n",
            "Done One Timestep\n",
            "Iteration: 3773; Percent complete: 94.3%; Average loss: 2.4272\n",
            "Returned Loss: 2.770802401585152\n",
            "Done One Timestep\n",
            "Iteration: 3774; Percent complete: 94.3%; Average loss: 2.7708\n",
            "Returned Loss: 2.539814604363052\n",
            "Done One Timestep\n",
            "Iteration: 3775; Percent complete: 94.4%; Average loss: 2.5398\n",
            "Returned Loss: 2.9165540379553363\n",
            "Done One Timestep\n",
            "Iteration: 3776; Percent complete: 94.4%; Average loss: 2.9166\n",
            "Returned Loss: 2.644923059758428\n",
            "Done One Timestep\n",
            "Iteration: 3777; Percent complete: 94.4%; Average loss: 2.6449\n",
            "Returned Loss: 2.7316462589942447\n",
            "Done One Timestep\n",
            "Iteration: 3778; Percent complete: 94.5%; Average loss: 2.7316\n",
            "Returned Loss: 2.8220989912756567\n",
            "Done One Timestep\n",
            "Iteration: 3779; Percent complete: 94.5%; Average loss: 2.8221\n",
            "Returned Loss: 2.7182848661535153\n",
            "Done One Timestep\n",
            "Iteration: 3780; Percent complete: 94.5%; Average loss: 2.7183\n",
            "Returned Loss: 2.580620701443404\n",
            "Done One Timestep\n",
            "Iteration: 3781; Percent complete: 94.5%; Average loss: 2.5806\n",
            "Returned Loss: 2.9322230939185623\n",
            "Done One Timestep\n",
            "Iteration: 3782; Percent complete: 94.5%; Average loss: 2.9322\n",
            "Returned Loss: 2.572217889725194\n",
            "Done One Timestep\n",
            "Iteration: 3783; Percent complete: 94.6%; Average loss: 2.5722\n",
            "Returned Loss: 2.6605746214958885\n",
            "Done One Timestep\n",
            "Iteration: 3784; Percent complete: 94.6%; Average loss: 2.6606\n",
            "Returned Loss: 2.5076991575827567\n",
            "Done One Timestep\n",
            "Iteration: 3785; Percent complete: 94.6%; Average loss: 2.5077\n",
            "Returned Loss: 2.7192683920232685\n",
            "Done One Timestep\n",
            "Iteration: 3786; Percent complete: 94.7%; Average loss: 2.7193\n",
            "Returned Loss: 2.5970813932159964\n",
            "Done One Timestep\n",
            "Iteration: 3787; Percent complete: 94.7%; Average loss: 2.5971\n",
            "Returned Loss: 2.4514893912506683\n",
            "Done One Timestep\n",
            "Iteration: 3788; Percent complete: 94.7%; Average loss: 2.4515\n",
            "Returned Loss: 2.7109878826480514\n",
            "Done One Timestep\n",
            "Iteration: 3789; Percent complete: 94.7%; Average loss: 2.7110\n",
            "Returned Loss: 2.2632729029933394\n",
            "Done One Timestep\n",
            "Iteration: 3790; Percent complete: 94.8%; Average loss: 2.2633\n",
            "Returned Loss: 2.7150973407686623\n",
            "Done One Timestep\n",
            "Iteration: 3791; Percent complete: 94.8%; Average loss: 2.7151\n",
            "Returned Loss: 2.630763677010709\n",
            "Done One Timestep\n",
            "Iteration: 3792; Percent complete: 94.8%; Average loss: 2.6308\n",
            "Returned Loss: 2.726475474929825\n",
            "Done One Timestep\n",
            "Iteration: 3793; Percent complete: 94.8%; Average loss: 2.7265\n",
            "Returned Loss: 2.611656586515033\n",
            "Done One Timestep\n",
            "Iteration: 3794; Percent complete: 94.8%; Average loss: 2.6117\n",
            "Returned Loss: 2.680064125883175\n",
            "Done One Timestep\n",
            "Iteration: 3795; Percent complete: 94.9%; Average loss: 2.6801\n",
            "Returned Loss: 2.685533989265958\n",
            "Done One Timestep\n",
            "Iteration: 3796; Percent complete: 94.9%; Average loss: 2.6855\n",
            "Returned Loss: 2.586001710303128\n",
            "Done One Timestep\n",
            "Iteration: 3797; Percent complete: 94.9%; Average loss: 2.5860\n",
            "Returned Loss: 2.5743769840922845\n",
            "Done One Timestep\n",
            "Iteration: 3798; Percent complete: 95.0%; Average loss: 2.5744\n",
            "Returned Loss: 2.6048980116508194\n",
            "Done One Timestep\n",
            "Iteration: 3799; Percent complete: 95.0%; Average loss: 2.6049\n",
            "Returned Loss: 2.748677020184464\n",
            "Done One Timestep\n",
            "Iteration: 3800; Percent complete: 95.0%; Average loss: 2.7487\n",
            "Returned Loss: 2.659839217359521\n",
            "Done One Timestep\n",
            "Iteration: 3801; Percent complete: 95.0%; Average loss: 2.6598\n",
            "Returned Loss: 2.4864321833277363\n",
            "Done One Timestep\n",
            "Iteration: 3802; Percent complete: 95.0%; Average loss: 2.4864\n",
            "Returned Loss: 2.6365977388117394\n",
            "Done One Timestep\n",
            "Iteration: 3803; Percent complete: 95.1%; Average loss: 2.6366\n",
            "Returned Loss: 2.5402779001511173\n",
            "Done One Timestep\n",
            "Iteration: 3804; Percent complete: 95.1%; Average loss: 2.5403\n",
            "Returned Loss: 2.6909063420120667\n",
            "Done One Timestep\n",
            "Iteration: 3805; Percent complete: 95.1%; Average loss: 2.6909\n",
            "Returned Loss: 2.6769381134254933\n",
            "Done One Timestep\n",
            "Iteration: 3806; Percent complete: 95.2%; Average loss: 2.6769\n",
            "Returned Loss: 2.656203075361022\n",
            "Done One Timestep\n",
            "Iteration: 3807; Percent complete: 95.2%; Average loss: 2.6562\n",
            "Returned Loss: 2.4279000228560466\n",
            "Done One Timestep\n",
            "Iteration: 3808; Percent complete: 95.2%; Average loss: 2.4279\n",
            "Returned Loss: 2.933284900651126\n",
            "Done One Timestep\n",
            "Iteration: 3809; Percent complete: 95.2%; Average loss: 2.9333\n",
            "Returned Loss: 2.7577695611485327\n",
            "Done One Timestep\n",
            "Iteration: 3810; Percent complete: 95.2%; Average loss: 2.7578\n",
            "Returned Loss: 2.6551233474679177\n",
            "Done One Timestep\n",
            "Iteration: 3811; Percent complete: 95.3%; Average loss: 2.6551\n",
            "Returned Loss: 2.757368378910216\n",
            "Done One Timestep\n",
            "Iteration: 3812; Percent complete: 95.3%; Average loss: 2.7574\n",
            "Returned Loss: 2.6924516727294248\n",
            "Done One Timestep\n",
            "Iteration: 3813; Percent complete: 95.3%; Average loss: 2.6925\n",
            "Returned Loss: 2.7282996514871813\n",
            "Done One Timestep\n",
            "Iteration: 3814; Percent complete: 95.3%; Average loss: 2.7283\n",
            "Returned Loss: 2.675647112814217\n",
            "Done One Timestep\n",
            "Iteration: 3815; Percent complete: 95.4%; Average loss: 2.6756\n",
            "Returned Loss: 2.9558022490605134\n",
            "Done One Timestep\n",
            "Iteration: 3816; Percent complete: 95.4%; Average loss: 2.9558\n",
            "Returned Loss: 2.609338810276382\n",
            "Done One Timestep\n",
            "Iteration: 3817; Percent complete: 95.4%; Average loss: 2.6093\n",
            "Returned Loss: 2.722074606488673\n",
            "Done One Timestep\n",
            "Iteration: 3818; Percent complete: 95.5%; Average loss: 2.7221\n",
            "Returned Loss: 2.6384862350759866\n",
            "Done One Timestep\n",
            "Iteration: 3819; Percent complete: 95.5%; Average loss: 2.6385\n",
            "Returned Loss: 2.439359214335127\n",
            "Done One Timestep\n",
            "Iteration: 3820; Percent complete: 95.5%; Average loss: 2.4394\n",
            "Returned Loss: 2.5967043314905625\n",
            "Done One Timestep\n",
            "Iteration: 3821; Percent complete: 95.5%; Average loss: 2.5967\n",
            "Returned Loss: 2.744044095088246\n",
            "Done One Timestep\n",
            "Iteration: 3822; Percent complete: 95.5%; Average loss: 2.7440\n",
            "Returned Loss: 2.8059420904733496\n",
            "Done One Timestep\n",
            "Iteration: 3823; Percent complete: 95.6%; Average loss: 2.8059\n",
            "Returned Loss: 2.5946337533803145\n",
            "Done One Timestep\n",
            "Iteration: 3824; Percent complete: 95.6%; Average loss: 2.5946\n",
            "Returned Loss: 2.7388617845513226\n",
            "Done One Timestep\n",
            "Iteration: 3825; Percent complete: 95.6%; Average loss: 2.7389\n",
            "Returned Loss: 2.591118202636055\n",
            "Done One Timestep\n",
            "Iteration: 3826; Percent complete: 95.7%; Average loss: 2.5911\n",
            "Returned Loss: 2.772677084106711\n",
            "Done One Timestep\n",
            "Iteration: 3827; Percent complete: 95.7%; Average loss: 2.7727\n",
            "Returned Loss: 2.819081745138291\n",
            "Done One Timestep\n",
            "Iteration: 3828; Percent complete: 95.7%; Average loss: 2.8191\n",
            "Returned Loss: 2.695270740356417\n",
            "Done One Timestep\n",
            "Iteration: 3829; Percent complete: 95.7%; Average loss: 2.6953\n",
            "Returned Loss: 2.476004428247645\n",
            "Done One Timestep\n",
            "Iteration: 3830; Percent complete: 95.8%; Average loss: 2.4760\n",
            "Returned Loss: 2.5047836922435356\n",
            "Done One Timestep\n",
            "Iteration: 3831; Percent complete: 95.8%; Average loss: 2.5048\n",
            "Returned Loss: 2.707626525554806\n",
            "Done One Timestep\n",
            "Iteration: 3832; Percent complete: 95.8%; Average loss: 2.7076\n",
            "Returned Loss: 2.897811063557165\n",
            "Done One Timestep\n",
            "Iteration: 3833; Percent complete: 95.8%; Average loss: 2.8978\n",
            "Returned Loss: 2.6468101256129493\n",
            "Done One Timestep\n",
            "Iteration: 3834; Percent complete: 95.9%; Average loss: 2.6468\n",
            "Returned Loss: 2.5843355417528695\n",
            "Done One Timestep\n",
            "Iteration: 3835; Percent complete: 95.9%; Average loss: 2.5843\n",
            "Returned Loss: 2.51323442104835\n",
            "Done One Timestep\n",
            "Iteration: 3836; Percent complete: 95.9%; Average loss: 2.5132\n",
            "Returned Loss: 2.706258112922884\n",
            "Done One Timestep\n",
            "Iteration: 3837; Percent complete: 95.9%; Average loss: 2.7063\n",
            "Returned Loss: 2.6277382815029564\n",
            "Done One Timestep\n",
            "Iteration: 3838; Percent complete: 96.0%; Average loss: 2.6277\n",
            "Returned Loss: 2.7988567826319106\n",
            "Done One Timestep\n",
            "Iteration: 3839; Percent complete: 96.0%; Average loss: 2.7989\n",
            "Returned Loss: 2.6214058050321403\n",
            "Done One Timestep\n",
            "Iteration: 3840; Percent complete: 96.0%; Average loss: 2.6214\n",
            "Returned Loss: 2.5892737681479776\n",
            "Done One Timestep\n",
            "Iteration: 3841; Percent complete: 96.0%; Average loss: 2.5893\n",
            "Returned Loss: 2.70782443200369\n",
            "Done One Timestep\n",
            "Iteration: 3842; Percent complete: 96.0%; Average loss: 2.7078\n",
            "Returned Loss: 2.761585511399303\n",
            "Done One Timestep\n",
            "Iteration: 3843; Percent complete: 96.1%; Average loss: 2.7616\n",
            "Returned Loss: 2.6422792860742343\n",
            "Done One Timestep\n",
            "Iteration: 3844; Percent complete: 96.1%; Average loss: 2.6423\n",
            "Returned Loss: 2.630250683840918\n",
            "Done One Timestep\n",
            "Iteration: 3845; Percent complete: 96.1%; Average loss: 2.6303\n",
            "Returned Loss: 2.701195384479589\n",
            "Done One Timestep\n",
            "Iteration: 3846; Percent complete: 96.2%; Average loss: 2.7012\n",
            "Returned Loss: 2.7698179065874733\n",
            "Done One Timestep\n",
            "Iteration: 3847; Percent complete: 96.2%; Average loss: 2.7698\n",
            "Returned Loss: 2.614340007037798\n",
            "Done One Timestep\n",
            "Iteration: 3848; Percent complete: 96.2%; Average loss: 2.6143\n",
            "Returned Loss: 2.8753509672253856\n",
            "Done One Timestep\n",
            "Iteration: 3849; Percent complete: 96.2%; Average loss: 2.8754\n",
            "Returned Loss: 2.527195920642976\n",
            "Done One Timestep\n",
            "Iteration: 3850; Percent complete: 96.2%; Average loss: 2.5272\n",
            "Returned Loss: 2.429772026038761\n",
            "Done One Timestep\n",
            "Iteration: 3851; Percent complete: 96.3%; Average loss: 2.4298\n",
            "Returned Loss: 2.637183401813792\n",
            "Done One Timestep\n",
            "Iteration: 3852; Percent complete: 96.3%; Average loss: 2.6372\n",
            "Returned Loss: 2.555845452537881\n",
            "Done One Timestep\n",
            "Iteration: 3853; Percent complete: 96.3%; Average loss: 2.5558\n",
            "Returned Loss: 2.612020322241888\n",
            "Done One Timestep\n",
            "Iteration: 3854; Percent complete: 96.4%; Average loss: 2.6120\n",
            "Returned Loss: 2.7509825501480316\n",
            "Done One Timestep\n",
            "Iteration: 3855; Percent complete: 96.4%; Average loss: 2.7510\n",
            "Returned Loss: 2.630402387619841\n",
            "Done One Timestep\n",
            "Iteration: 3856; Percent complete: 96.4%; Average loss: 2.6304\n",
            "Returned Loss: 2.583498291486587\n",
            "Done One Timestep\n",
            "Iteration: 3857; Percent complete: 96.4%; Average loss: 2.5835\n",
            "Returned Loss: 2.5068376909003733\n",
            "Done One Timestep\n",
            "Iteration: 3858; Percent complete: 96.5%; Average loss: 2.5068\n",
            "Returned Loss: 2.7026068546586486\n",
            "Done One Timestep\n",
            "Iteration: 3859; Percent complete: 96.5%; Average loss: 2.7026\n",
            "Returned Loss: 2.50795710653561\n",
            "Done One Timestep\n",
            "Iteration: 3860; Percent complete: 96.5%; Average loss: 2.5080\n",
            "Returned Loss: 2.468372591102381\n",
            "Done One Timestep\n",
            "Iteration: 3861; Percent complete: 96.5%; Average loss: 2.4684\n",
            "Returned Loss: 2.745338194516594\n",
            "Done One Timestep\n",
            "Iteration: 3862; Percent complete: 96.5%; Average loss: 2.7453\n",
            "Returned Loss: 2.619871838018298\n",
            "Done One Timestep\n",
            "Iteration: 3863; Percent complete: 96.6%; Average loss: 2.6199\n",
            "Returned Loss: 2.5201794551761045\n",
            "Done One Timestep\n",
            "Iteration: 3864; Percent complete: 96.6%; Average loss: 2.5202\n",
            "Returned Loss: 2.688473013442067\n",
            "Done One Timestep\n",
            "Iteration: 3865; Percent complete: 96.6%; Average loss: 2.6885\n",
            "Returned Loss: 2.616292936753811\n",
            "Done One Timestep\n",
            "Iteration: 3866; Percent complete: 96.7%; Average loss: 2.6163\n",
            "Returned Loss: 2.4453969666015976\n",
            "Done One Timestep\n",
            "Iteration: 3867; Percent complete: 96.7%; Average loss: 2.4454\n",
            "Returned Loss: 2.7568694218271816\n",
            "Done One Timestep\n",
            "Iteration: 3868; Percent complete: 96.7%; Average loss: 2.7569\n",
            "Returned Loss: 2.8004116954899696\n",
            "Done One Timestep\n",
            "Iteration: 3869; Percent complete: 96.7%; Average loss: 2.8004\n",
            "Returned Loss: 2.621264278119163\n",
            "Done One Timestep\n",
            "Iteration: 3870; Percent complete: 96.8%; Average loss: 2.6213\n",
            "Returned Loss: 2.5932553817414132\n",
            "Done One Timestep\n",
            "Iteration: 3871; Percent complete: 96.8%; Average loss: 2.5933\n",
            "Returned Loss: 2.639860172695023\n",
            "Done One Timestep\n",
            "Iteration: 3872; Percent complete: 96.8%; Average loss: 2.6399\n",
            "Returned Loss: 2.66176038701379\n",
            "Done One Timestep\n",
            "Iteration: 3873; Percent complete: 96.8%; Average loss: 2.6618\n",
            "Returned Loss: 2.5473569515927106\n",
            "Done One Timestep\n",
            "Iteration: 3874; Percent complete: 96.9%; Average loss: 2.5474\n",
            "Returned Loss: 2.5779191885612436\n",
            "Done One Timestep\n",
            "Iteration: 3875; Percent complete: 96.9%; Average loss: 2.5779\n",
            "Returned Loss: 2.715730361217229\n",
            "Done One Timestep\n",
            "Iteration: 3876; Percent complete: 96.9%; Average loss: 2.7157\n",
            "Returned Loss: 2.557957120685695\n",
            "Done One Timestep\n",
            "Iteration: 3877; Percent complete: 96.9%; Average loss: 2.5580\n",
            "Returned Loss: 2.748481030841681\n",
            "Done One Timestep\n",
            "Iteration: 3878; Percent complete: 97.0%; Average loss: 2.7485\n",
            "Returned Loss: 2.5726941801456453\n",
            "Done One Timestep\n",
            "Iteration: 3879; Percent complete: 97.0%; Average loss: 2.5727\n",
            "Returned Loss: 2.820897321129845\n",
            "Done One Timestep\n",
            "Iteration: 3880; Percent complete: 97.0%; Average loss: 2.8209\n",
            "Returned Loss: 2.426461175406404\n",
            "Done One Timestep\n",
            "Iteration: 3881; Percent complete: 97.0%; Average loss: 2.4265\n",
            "Returned Loss: 2.786773463939909\n",
            "Done One Timestep\n",
            "Iteration: 3882; Percent complete: 97.0%; Average loss: 2.7868\n",
            "Returned Loss: 2.7627780869315806\n",
            "Done One Timestep\n",
            "Iteration: 3883; Percent complete: 97.1%; Average loss: 2.7628\n",
            "Returned Loss: 2.5623711997227794\n",
            "Done One Timestep\n",
            "Iteration: 3884; Percent complete: 97.1%; Average loss: 2.5624\n",
            "Returned Loss: 2.7156139008436933\n",
            "Done One Timestep\n",
            "Iteration: 3885; Percent complete: 97.1%; Average loss: 2.7156\n",
            "Returned Loss: 2.5887881901538288\n",
            "Done One Timestep\n",
            "Iteration: 3886; Percent complete: 97.2%; Average loss: 2.5888\n",
            "Returned Loss: 2.558502404454716\n",
            "Done One Timestep\n",
            "Iteration: 3887; Percent complete: 97.2%; Average loss: 2.5585\n",
            "Returned Loss: 2.6342272547478798\n",
            "Done One Timestep\n",
            "Iteration: 3888; Percent complete: 97.2%; Average loss: 2.6342\n",
            "Returned Loss: 2.6558947493862695\n",
            "Done One Timestep\n",
            "Iteration: 3889; Percent complete: 97.2%; Average loss: 2.6559\n",
            "Returned Loss: 2.5799579651759585\n",
            "Done One Timestep\n",
            "Iteration: 3890; Percent complete: 97.2%; Average loss: 2.5800\n",
            "Returned Loss: 2.5651276253224307\n",
            "Done One Timestep\n",
            "Iteration: 3891; Percent complete: 97.3%; Average loss: 2.5651\n",
            "Returned Loss: 2.6168545253711137\n",
            "Done One Timestep\n",
            "Iteration: 3892; Percent complete: 97.3%; Average loss: 2.6169\n",
            "Returned Loss: 2.676277144969111\n",
            "Done One Timestep\n",
            "Iteration: 3893; Percent complete: 97.3%; Average loss: 2.6763\n",
            "Returned Loss: 2.751056430606899\n",
            "Done One Timestep\n",
            "Iteration: 3894; Percent complete: 97.4%; Average loss: 2.7511\n",
            "Returned Loss: 2.6773555558768805\n",
            "Done One Timestep\n",
            "Iteration: 3895; Percent complete: 97.4%; Average loss: 2.6774\n",
            "Returned Loss: 2.5164501298270143\n",
            "Done One Timestep\n",
            "Iteration: 3896; Percent complete: 97.4%; Average loss: 2.5165\n",
            "Returned Loss: 2.491345564875474\n",
            "Done One Timestep\n",
            "Iteration: 3897; Percent complete: 97.4%; Average loss: 2.4913\n",
            "Returned Loss: 2.638525958883443\n",
            "Done One Timestep\n",
            "Iteration: 3898; Percent complete: 97.5%; Average loss: 2.6385\n",
            "Returned Loss: 2.6636008745253013\n",
            "Done One Timestep\n",
            "Iteration: 3899; Percent complete: 97.5%; Average loss: 2.6636\n",
            "Returned Loss: 2.7522649230449154\n",
            "Done One Timestep\n",
            "Iteration: 3900; Percent complete: 97.5%; Average loss: 2.7523\n",
            "Returned Loss: 2.535906056985305\n",
            "Done One Timestep\n",
            "Iteration: 3901; Percent complete: 97.5%; Average loss: 2.5359\n",
            "Returned Loss: 2.719949515334313\n",
            "Done One Timestep\n",
            "Iteration: 3902; Percent complete: 97.5%; Average loss: 2.7199\n",
            "Returned Loss: 2.744457064358076\n",
            "Done One Timestep\n",
            "Iteration: 3903; Percent complete: 97.6%; Average loss: 2.7445\n",
            "Returned Loss: 2.500575707749694\n",
            "Done One Timestep\n",
            "Iteration: 3904; Percent complete: 97.6%; Average loss: 2.5006\n",
            "Returned Loss: 2.5589660506774536\n",
            "Done One Timestep\n",
            "Iteration: 3905; Percent complete: 97.6%; Average loss: 2.5590\n",
            "Returned Loss: 2.610590285785597\n",
            "Done One Timestep\n",
            "Iteration: 3906; Percent complete: 97.7%; Average loss: 2.6106\n",
            "Returned Loss: 2.447470571510885\n",
            "Done One Timestep\n",
            "Iteration: 3907; Percent complete: 97.7%; Average loss: 2.4475\n",
            "Returned Loss: 2.683796909557423\n",
            "Done One Timestep\n",
            "Iteration: 3908; Percent complete: 97.7%; Average loss: 2.6838\n",
            "Returned Loss: 2.6514701589442793\n",
            "Done One Timestep\n",
            "Iteration: 3909; Percent complete: 97.7%; Average loss: 2.6515\n",
            "Returned Loss: 2.5927027662847935\n",
            "Done One Timestep\n",
            "Iteration: 3910; Percent complete: 97.8%; Average loss: 2.5927\n",
            "Returned Loss: 2.826671546963354\n",
            "Done One Timestep\n",
            "Iteration: 3911; Percent complete: 97.8%; Average loss: 2.8267\n",
            "Returned Loss: 2.638555131653968\n",
            "Done One Timestep\n",
            "Iteration: 3912; Percent complete: 97.8%; Average loss: 2.6386\n",
            "Returned Loss: 2.6021396674225943\n",
            "Done One Timestep\n",
            "Iteration: 3913; Percent complete: 97.8%; Average loss: 2.6021\n",
            "Returned Loss: 2.5241260552711764\n",
            "Done One Timestep\n",
            "Iteration: 3914; Percent complete: 97.9%; Average loss: 2.5241\n",
            "Returned Loss: 2.780902102511997\n",
            "Done One Timestep\n",
            "Iteration: 3915; Percent complete: 97.9%; Average loss: 2.7809\n",
            "Returned Loss: 2.649975565474009\n",
            "Done One Timestep\n",
            "Iteration: 3916; Percent complete: 97.9%; Average loss: 2.6500\n",
            "Returned Loss: 2.7116785710927416\n",
            "Done One Timestep\n",
            "Iteration: 3917; Percent complete: 97.9%; Average loss: 2.7117\n",
            "Returned Loss: 2.60097781764367\n",
            "Done One Timestep\n",
            "Iteration: 3918; Percent complete: 98.0%; Average loss: 2.6010\n",
            "Returned Loss: 2.520661114094323\n",
            "Done One Timestep\n",
            "Iteration: 3919; Percent complete: 98.0%; Average loss: 2.5207\n",
            "Returned Loss: 2.7970928673120867\n",
            "Done One Timestep\n",
            "Iteration: 3920; Percent complete: 98.0%; Average loss: 2.7971\n",
            "Returned Loss: 2.7475206405174872\n",
            "Done One Timestep\n",
            "Iteration: 3921; Percent complete: 98.0%; Average loss: 2.7475\n",
            "Returned Loss: 2.8052773197282397\n",
            "Done One Timestep\n",
            "Iteration: 3922; Percent complete: 98.0%; Average loss: 2.8053\n",
            "Returned Loss: 2.6527645556759465\n",
            "Done One Timestep\n",
            "Iteration: 3923; Percent complete: 98.1%; Average loss: 2.6528\n",
            "Returned Loss: 2.7773460271188406\n",
            "Done One Timestep\n",
            "Iteration: 3924; Percent complete: 98.1%; Average loss: 2.7773\n",
            "Returned Loss: 2.513706989545654\n",
            "Done One Timestep\n",
            "Iteration: 3925; Percent complete: 98.1%; Average loss: 2.5137\n",
            "Returned Loss: 2.6542099115445037\n",
            "Done One Timestep\n",
            "Iteration: 3926; Percent complete: 98.2%; Average loss: 2.6542\n",
            "Returned Loss: 2.677282387215663\n",
            "Done One Timestep\n",
            "Iteration: 3927; Percent complete: 98.2%; Average loss: 2.6773\n",
            "Returned Loss: 2.4805515636545503\n",
            "Done One Timestep\n",
            "Iteration: 3928; Percent complete: 98.2%; Average loss: 2.4806\n",
            "Returned Loss: 2.677694012931524\n",
            "Done One Timestep\n",
            "Iteration: 3929; Percent complete: 98.2%; Average loss: 2.6777\n",
            "Returned Loss: 2.499486676492672\n",
            "Done One Timestep\n",
            "Iteration: 3930; Percent complete: 98.2%; Average loss: 2.4995\n",
            "Returned Loss: 2.6285570837890893\n",
            "Done One Timestep\n",
            "Iteration: 3931; Percent complete: 98.3%; Average loss: 2.6286\n",
            "Returned Loss: 2.5827241989244043\n",
            "Done One Timestep\n",
            "Iteration: 3932; Percent complete: 98.3%; Average loss: 2.5827\n",
            "Returned Loss: 2.68374440520429\n",
            "Done One Timestep\n",
            "Iteration: 3933; Percent complete: 98.3%; Average loss: 2.6837\n",
            "Returned Loss: 2.4815732419094254\n",
            "Done One Timestep\n",
            "Iteration: 3934; Percent complete: 98.4%; Average loss: 2.4816\n",
            "Returned Loss: 2.681535989742716\n",
            "Done One Timestep\n",
            "Iteration: 3935; Percent complete: 98.4%; Average loss: 2.6815\n",
            "Returned Loss: 2.709440652525429\n",
            "Done One Timestep\n",
            "Iteration: 3936; Percent complete: 98.4%; Average loss: 2.7094\n",
            "Returned Loss: 2.4663176130270585\n",
            "Done One Timestep\n",
            "Iteration: 3937; Percent complete: 98.4%; Average loss: 2.4663\n",
            "Returned Loss: 2.3704880581621732\n",
            "Done One Timestep\n",
            "Iteration: 3938; Percent complete: 98.5%; Average loss: 2.3705\n",
            "Returned Loss: 2.4607712167740603\n",
            "Done One Timestep\n",
            "Iteration: 3939; Percent complete: 98.5%; Average loss: 2.4608\n",
            "Returned Loss: 2.523542873353626\n",
            "Done One Timestep\n",
            "Iteration: 3940; Percent complete: 98.5%; Average loss: 2.5235\n",
            "Returned Loss: 2.531547837945376\n",
            "Done One Timestep\n",
            "Iteration: 3941; Percent complete: 98.5%; Average loss: 2.5315\n",
            "Returned Loss: 2.6695485434214716\n",
            "Done One Timestep\n",
            "Iteration: 3942; Percent complete: 98.6%; Average loss: 2.6695\n",
            "Returned Loss: 2.771520767783845\n",
            "Done One Timestep\n",
            "Iteration: 3943; Percent complete: 98.6%; Average loss: 2.7715\n",
            "Returned Loss: 2.557968525427149\n",
            "Done One Timestep\n",
            "Iteration: 3944; Percent complete: 98.6%; Average loss: 2.5580\n",
            "Returned Loss: 2.614941144180103\n",
            "Done One Timestep\n",
            "Iteration: 3945; Percent complete: 98.6%; Average loss: 2.6149\n",
            "Returned Loss: 2.4328225689241663\n",
            "Done One Timestep\n",
            "Iteration: 3946; Percent complete: 98.7%; Average loss: 2.4328\n",
            "Returned Loss: 2.5207026903034255\n",
            "Done One Timestep\n",
            "Iteration: 3947; Percent complete: 98.7%; Average loss: 2.5207\n",
            "Returned Loss: 2.6224986619475965\n",
            "Done One Timestep\n",
            "Iteration: 3948; Percent complete: 98.7%; Average loss: 2.6225\n",
            "Returned Loss: 2.659639238218084\n",
            "Done One Timestep\n",
            "Iteration: 3949; Percent complete: 98.7%; Average loss: 2.6596\n",
            "Returned Loss: 2.461451827951936\n",
            "Done One Timestep\n",
            "Iteration: 3950; Percent complete: 98.8%; Average loss: 2.4615\n",
            "Returned Loss: 2.8205112372329615\n",
            "Done One Timestep\n",
            "Iteration: 3951; Percent complete: 98.8%; Average loss: 2.8205\n",
            "Returned Loss: 2.782424532014522\n",
            "Done One Timestep\n",
            "Iteration: 3952; Percent complete: 98.8%; Average loss: 2.7824\n",
            "Returned Loss: 2.7661814544862255\n",
            "Done One Timestep\n",
            "Iteration: 3953; Percent complete: 98.8%; Average loss: 2.7662\n",
            "Returned Loss: 2.6541008478556565\n",
            "Done One Timestep\n",
            "Iteration: 3954; Percent complete: 98.9%; Average loss: 2.6541\n",
            "Returned Loss: 2.533205908117935\n",
            "Done One Timestep\n",
            "Iteration: 3955; Percent complete: 98.9%; Average loss: 2.5332\n",
            "Returned Loss: 2.6064093035486566\n",
            "Done One Timestep\n",
            "Iteration: 3956; Percent complete: 98.9%; Average loss: 2.6064\n",
            "Returned Loss: 2.527615841428303\n",
            "Done One Timestep\n",
            "Iteration: 3957; Percent complete: 98.9%; Average loss: 2.5276\n",
            "Returned Loss: 2.7957490473213165\n",
            "Done One Timestep\n",
            "Iteration: 3958; Percent complete: 99.0%; Average loss: 2.7957\n",
            "Returned Loss: 2.3680893959875298\n",
            "Done One Timestep\n",
            "Iteration: 3959; Percent complete: 99.0%; Average loss: 2.3681\n",
            "Returned Loss: 2.6733571482596523\n",
            "Done One Timestep\n",
            "Iteration: 3960; Percent complete: 99.0%; Average loss: 2.6734\n",
            "Returned Loss: 2.6921454901044655\n",
            "Done One Timestep\n",
            "Iteration: 3961; Percent complete: 99.0%; Average loss: 2.6921\n",
            "Returned Loss: 2.774850681853791\n",
            "Done One Timestep\n",
            "Iteration: 3962; Percent complete: 99.1%; Average loss: 2.7749\n",
            "Returned Loss: 2.5607287479683123\n",
            "Done One Timestep\n",
            "Iteration: 3963; Percent complete: 99.1%; Average loss: 2.5607\n",
            "Returned Loss: 2.8688428520937523\n",
            "Done One Timestep\n",
            "Iteration: 3964; Percent complete: 99.1%; Average loss: 2.8688\n",
            "Returned Loss: 2.592189532764571\n",
            "Done One Timestep\n",
            "Iteration: 3965; Percent complete: 99.1%; Average loss: 2.5922\n",
            "Returned Loss: 2.4679537753801086\n",
            "Done One Timestep\n",
            "Iteration: 3966; Percent complete: 99.2%; Average loss: 2.4680\n",
            "Returned Loss: 2.870435578895824\n",
            "Done One Timestep\n",
            "Iteration: 3967; Percent complete: 99.2%; Average loss: 2.8704\n",
            "Returned Loss: 2.6724350037990567\n",
            "Done One Timestep\n",
            "Iteration: 3968; Percent complete: 99.2%; Average loss: 2.6724\n",
            "Returned Loss: 2.692800961639338\n",
            "Done One Timestep\n",
            "Iteration: 3969; Percent complete: 99.2%; Average loss: 2.6928\n",
            "Returned Loss: 2.499776929298018\n",
            "Done One Timestep\n",
            "Iteration: 3970; Percent complete: 99.2%; Average loss: 2.4998\n",
            "Returned Loss: 2.648066701542567\n",
            "Done One Timestep\n",
            "Iteration: 3971; Percent complete: 99.3%; Average loss: 2.6481\n",
            "Returned Loss: 2.437790834030633\n",
            "Done One Timestep\n",
            "Iteration: 3972; Percent complete: 99.3%; Average loss: 2.4378\n",
            "Returned Loss: 2.4386182165597474\n",
            "Done One Timestep\n",
            "Iteration: 3973; Percent complete: 99.3%; Average loss: 2.4386\n",
            "Returned Loss: 2.6049795200173236\n",
            "Done One Timestep\n",
            "Iteration: 3974; Percent complete: 99.4%; Average loss: 2.6050\n",
            "Returned Loss: 2.7493592959351134\n",
            "Done One Timestep\n",
            "Iteration: 3975; Percent complete: 99.4%; Average loss: 2.7494\n",
            "Returned Loss: 2.6719855692568095\n",
            "Done One Timestep\n",
            "Iteration: 3976; Percent complete: 99.4%; Average loss: 2.6720\n",
            "Returned Loss: 2.774657657541594\n",
            "Done One Timestep\n",
            "Iteration: 3977; Percent complete: 99.4%; Average loss: 2.7747\n",
            "Returned Loss: 2.5124615197411\n",
            "Done One Timestep\n",
            "Iteration: 3978; Percent complete: 99.5%; Average loss: 2.5125\n",
            "Returned Loss: 2.743233385991079\n",
            "Done One Timestep\n",
            "Iteration: 3979; Percent complete: 99.5%; Average loss: 2.7432\n",
            "Returned Loss: 2.5336410018277697\n",
            "Done One Timestep\n",
            "Iteration: 3980; Percent complete: 99.5%; Average loss: 2.5336\n",
            "Returned Loss: 2.7019463240163573\n",
            "Done One Timestep\n",
            "Iteration: 3981; Percent complete: 99.5%; Average loss: 2.7019\n",
            "Returned Loss: 2.40774068996605\n",
            "Done One Timestep\n",
            "Iteration: 3982; Percent complete: 99.6%; Average loss: 2.4077\n",
            "Returned Loss: 2.7818748774898547\n",
            "Done One Timestep\n",
            "Iteration: 3983; Percent complete: 99.6%; Average loss: 2.7819\n",
            "Returned Loss: 2.5229883080526325\n",
            "Done One Timestep\n",
            "Iteration: 3984; Percent complete: 99.6%; Average loss: 2.5230\n",
            "Returned Loss: 2.7572673220764585\n",
            "Done One Timestep\n",
            "Iteration: 3985; Percent complete: 99.6%; Average loss: 2.7573\n",
            "Returned Loss: 2.5360575431383254\n",
            "Done One Timestep\n",
            "Iteration: 3986; Percent complete: 99.7%; Average loss: 2.5361\n",
            "Returned Loss: 2.723110539340981\n",
            "Done One Timestep\n",
            "Iteration: 3987; Percent complete: 99.7%; Average loss: 2.7231\n",
            "Returned Loss: 2.3211368402486205\n",
            "Done One Timestep\n",
            "Iteration: 3988; Percent complete: 99.7%; Average loss: 2.3211\n",
            "Returned Loss: 2.5080321591117025\n",
            "Done One Timestep\n",
            "Iteration: 3989; Percent complete: 99.7%; Average loss: 2.5080\n",
            "Returned Loss: 2.6523246824747497\n",
            "Done One Timestep\n",
            "Iteration: 3990; Percent complete: 99.8%; Average loss: 2.6523\n",
            "Returned Loss: 2.773811203763535\n",
            "Done One Timestep\n",
            "Iteration: 3991; Percent complete: 99.8%; Average loss: 2.7738\n",
            "Returned Loss: 2.366773349742439\n",
            "Done One Timestep\n",
            "Iteration: 3992; Percent complete: 99.8%; Average loss: 2.3668\n",
            "Returned Loss: 2.4645174366166547\n",
            "Done One Timestep\n",
            "Iteration: 3993; Percent complete: 99.8%; Average loss: 2.4645\n",
            "Returned Loss: 2.582626470115837\n",
            "Done One Timestep\n",
            "Iteration: 3994; Percent complete: 99.9%; Average loss: 2.5826\n",
            "Returned Loss: 2.6641010021264724\n",
            "Done One Timestep\n",
            "Iteration: 3995; Percent complete: 99.9%; Average loss: 2.6641\n",
            "Returned Loss: 2.3957925036926815\n",
            "Done One Timestep\n",
            "Iteration: 3996; Percent complete: 99.9%; Average loss: 2.3958\n",
            "Returned Loss: 2.524371384303425\n",
            "Done One Timestep\n",
            "Iteration: 3997; Percent complete: 99.9%; Average loss: 2.5244\n",
            "Returned Loss: 2.5978425952350763\n",
            "Done One Timestep\n",
            "Iteration: 3998; Percent complete: 100.0%; Average loss: 2.5978\n",
            "Returned Loss: 2.4942354078847107\n",
            "Done One Timestep\n",
            "Iteration: 3999; Percent complete: 100.0%; Average loss: 2.4942\n",
            "Returned Loss: 2.684174363846261\n",
            "Done One Timestep\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.6842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfAvTW4e8INy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run evaluation \n",
        "\n",
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Begin chatting \n",
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}